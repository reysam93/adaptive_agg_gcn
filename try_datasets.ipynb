{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script evaluates the performance of different graph-aware architectures in a node classification problem. Several datasets are employed paying special attention to the homophily ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f41ac76ce30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "import utils\n",
    "from gsp_utils.baselines_archs import GCNN_2L, MLP, GAT\n",
    "from gsp_utils.baselines_models import NodeClassModel, GF_NodeClassModel\n",
    "from gsp_utils.data import normalize_gso\n",
    "from src.arch import GFGCN, GFGCNLayer, GFGCN_noh_Layer, GFGCN_Spows  \n",
    "\n",
    "# SEED = 0\n",
    "SEED = 15\n",
    "PATH = 'results/diff_filters/'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full_results(accs, ellapsed_time, datasets, exps):\n",
    "    mean_accs = accs.mean(axis=2)\n",
    "    med_accs = np.median(accs, axis=2)\n",
    "    std_accs = accs.std(axis=2)\n",
    "    mean_t = ellapsed_time.mean(axis=2)\n",
    "\n",
    "    for i, dataset_name in enumerate(datasets):\n",
    "        graph = getattr(dgl.data, dataset_name)(verbose=False)[0]\n",
    "        edge_hom = dgl.edge_homophily(graph, graph.ndata['label'])\n",
    "\n",
    "        print(f'{dataset_name} (homophily ratio: {edge_hom:.3f})')\n",
    "        for j, exp in enumerate(exps):\n",
    "            print(f'\\t- {exp[\"leg\"]}:\\tmean: {mean_accs[j,i]:.3f} - std: {std_accs[j,i]:.4f} - med: {med_accs[j,i]:.3f} - time: {mean_t[j,i]:.2f} mins')\n",
    "        \n",
    "        print()\n",
    "\n",
    "def summary_table(accs, datasets, exps, median=False):\n",
    "    mean_accs = accs.mean(axis=2)\n",
    "    cols_name = []\n",
    "    for dataset_name in datasets:\n",
    "        graph = getattr(dgl.data, dataset_name)(verbose=False)[0]\n",
    "        edge_hom = dgl.edge_homophily(graph, graph.ndata['label'])\n",
    "        cols_name.append(f'{dataset_name} ({edge_hom:.2f})')\n",
    "\n",
    "    index_name = [exp['leg'] for exp in exps]\n",
    "\n",
    "    return DataFrame(mean_accs, columns=cols_name, index=index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['TexasDataset',  'WisconsinDataset', 'CornellDataset', 'ChameleonDataset', 'CiteseerGraphDataset', 'CoraGraphDataset']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 20\n",
    "ACT = nn.LeakyReLU()  # nn.ReLU()\n",
    "LAST_ACT = nn.Softmax(dim=1)\n",
    "LOSS_FN = nn.CrossEntropyLoss() #nn.NLLLoss()\n",
    "\n",
    "EXPS = [{'model': 'Kipf', 'norm': 'both', 'epochs': 200, 'lr': .01, 'wd': 5e-4, 'drop': .5,\n",
    "          'L': 2, 'hid_dim': 16, 'leg': 'Kipf-normA'},\n",
    "        {'model': 'Kipf', 'norm': 'none', 'epochs': 200, 'lr': .01, 'wd': 5e-4, 'drop': .5,\n",
    "          'L': 2, 'hid_dim': 16, 'leg': 'Kipf-A'},\n",
    "\n",
    "        {'model': 'MLP', 'epochs': 200, 'lr': .01, 'wd': 5e-4, 'drop': .5,\n",
    "          'hid_dim': 16, 'leg': 'MLP'},\n",
    "\n",
    "        {'model': 'GAT', 'heads': 2, 'epochs': 200, 'lr': .01, 'wd': 5e-4, 'drop': 0,\n",
    "          'hid_dim': 16, 'leg': 'GAT'},\n",
    "          \n",
    "\n",
    "        {'model': 'GFGCN', 'epochs': 200, 'e_h': 25, 'e_W': 25, 'lr': .005, 'wd': .001, 'drop': .25,\n",
    "         'hid_dim': 32, 'L': 2, 'K': 3, 'h0': 1, 'norm': True, 'leg': 'A-GCN-normA'},\n",
    "\n",
    "        {'model': 'GFGCN', 'epochs': 200, 'e_h': 25, 'e_W': 25, 'lr': .005, 'wd': .001, 'drop': .25,\n",
    "         'hid_dim': 32,'L': 2, 'K': 3, 'h0': 1, 'norm': False, 'leg': 'A-GCN'},\n",
    "\n",
    "        {'model': 'GFGCN', 'epochs': 200, 'e_h': 25, 'e_W': 25, 'lr': .005, 'wd': .001, 'drop': .25,\n",
    "         'hid_dim': 50,'L': 3, 'K': 2, 'h0': 1, 'norm': False, 'leg': 'A-GCN-v2'},\n",
    "\n",
    "        {'model': 'H-GFGCN', 'epochs': 200, 'e_h': 25, 'e_W': 25, 'lr': .005, 'wd': .001, 'drop': .25,\n",
    "         'hid_dim': 16,'L': 3, 'K': 2, 'norm': True, 'leg': 'H-GCN-normH'},\n",
    "\n",
    "        {'model': 'H-GFGCN', 'epochs': 200, 'e_h': 25, 'e_W': 25, 'lr': .005, 'wd': .001, 'drop': .25,\n",
    "         'hid_dim': 32,'L': 2, 'K': 3, 'norm': False, 'leg': 'H-GCN'},\n",
    "\n",
    "        {'model': 'noh-GFGCN', 'epochs': 500, 'lr': .005, 'wd': .01, 'drop': .25,\n",
    "         'hid_dim': 32, 'L': 2, 'K': 2, 'norm': True, 'leg': 'W-GCN-normA'},\n",
    "        {'model': 'noh-GFGCN', 'epochs': 500, 'lr': .005, 'wd': .01, 'drop': .25,\n",
    "         'hid_dim': 32, 'L': 2, 'K': 2, 'norm': False, 'leg': 'W-GCN'},\n",
    "      ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChameleonDataset\n",
      "0: 0.634 (0.654) - 0.344 (0.351) - 0.467 (0.480) - "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.182 (0.182) - 0.430 (0.458) - \n",
      "1: 0.629 (0.654) - 0.353 (0.353) - 0.478 (0.526) - 0.189 (0.189) - 0.469 (0.485) - \n",
      "2: 0.605 (0.610) - 0.375 (0.382) - 0.441 (0.493) - 0.195 (0.195) - 0.377 (0.447) - \n",
      "3: 0.632 (0.640) - 0.357 (0.362) - 0.474 (0.550) - 0.211 (0.211) - 0.454 (0.458) - \n",
      "4: 0.618 (0.638) - 0.292 (0.305) - 0.432 (0.515) - 0.235 (0.235) - 0.414 (0.454) - \n",
      "5: 0.618 (0.625) - "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/srey/Investigacion/robust_minmax_gnn/try_datasets.ipynb Cell 7\u001b[0m line \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/try_datasets.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m exp[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mKipf\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/try_datasets.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     arch \u001b[39m=\u001b[39m GCNN_2L(in_dim, exp[\u001b[39m'\u001b[39m\u001b[39mhid_dim\u001b[39m\u001b[39m'\u001b[39m], out_dim, act\u001b[39m=\u001b[39mACT, last_act\u001b[39m=\u001b[39mLAST_ACT,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/try_datasets.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m                    dropout\u001b[39m=\u001b[39mexp[\u001b[39m'\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m'\u001b[39m], norm\u001b[39m=\u001b[39mexp[\u001b[39m'\u001b[39m\u001b[39mnorm\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/try_datasets.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     S \u001b[39m=\u001b[39m dgl\u001b[39m.\u001b[39;49mfrom_networkx(nx\u001b[39m.\u001b[39;49mfrom_numpy_array(A))\u001b[39m.\u001b[39madd_self_loop()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/try_datasets.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39melif\u001b[39;00m exp[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMLP\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/try_datasets.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     arch \u001b[39m=\u001b[39m MLP(in_dim,  exp[\u001b[39m'\u001b[39m\u001b[39mhid_dim\u001b[39m\u001b[39m'\u001b[39m], out_dim, dropout\u001b[39m=\u001b[39mexp[\u001b[39m'\u001b[39m\u001b[39mdrop\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/dgl/convert.py:1355\u001b[0m, in \u001b[0;36mfrom_networkx\u001b[0;34m(nx_graph, node_attrs, edge_attrs, edge_id_attr_name, idtype, device)\u001b[0m\n\u001b[1;32m   1353\u001b[0m nx_graph \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mconvert_node_labels_to_integers(nx_graph, ordering\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msorted\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nx_graph\u001b[39m.\u001b[39mis_directed():\n\u001b[0;32m-> 1355\u001b[0m     nx_graph \u001b[39m=\u001b[39m nx_graph\u001b[39m.\u001b[39;49mto_directed()\n\u001b[1;32m   1357\u001b[0m (sparse_fmt, arrays), urange, vrange \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mgraphdata2tensors(\n\u001b[1;32m   1358\u001b[0m     nx_graph, idtype, edge_id_attr_name\u001b[39m=\u001b[39medge_id_attr_name\n\u001b[1;32m   1359\u001b[0m )\n\u001b[1;32m   1361\u001b[0m g \u001b[39m=\u001b[39m create_from_edges(sparse_fmt, arrays, \u001b[39m\"\u001b[39m\u001b[39m_N\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_E\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_N\u001b[39m\u001b[39m\"\u001b[39m, urange, vrange)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/classes/graph.py:1597\u001b[0m, in \u001b[0;36mGraph.to_directed\u001b[0;34m(self, as_view)\u001b[0m\n\u001b[1;32m   1595\u001b[0m G\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mupdate(deepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph))\n\u001b[1;32m   1596\u001b[0m G\u001b[39m.\u001b[39madd_nodes_from((n, deepcopy(d)) \u001b[39mfor\u001b[39;00m n, d \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node\u001b[39m.\u001b[39mitems())\n\u001b[0;32m-> 1597\u001b[0m G\u001b[39m.\u001b[39;49madd_edges_from(\n\u001b[1;32m   1598\u001b[0m     (u, v, deepcopy(data))\n\u001b[1;32m   1599\u001b[0m     \u001b[39mfor\u001b[39;49;00m u, nbrs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adj\u001b[39m.\u001b[39;49mitems()\n\u001b[1;32m   1600\u001b[0m     \u001b[39mfor\u001b[39;49;00m v, data \u001b[39min\u001b[39;49;00m nbrs\u001b[39m.\u001b[39;49mitems()\n\u001b[1;32m   1601\u001b[0m )\n\u001b[1;32m   1602\u001b[0m \u001b[39mreturn\u001b[39;00m G\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/networkx/classes/digraph.py:706\u001b[0m, in \u001b[0;36mDiGraph.add_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node[v] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_attr_dict_factory()\n\u001b[1;32m    705\u001b[0m datadict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adj[u]\u001b[39m.\u001b[39mget(v, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_attr_dict_factory())\n\u001b[0;32m--> 706\u001b[0m datadict\u001b[39m.\u001b[39;49mupdate(attr)\n\u001b[1;32m    707\u001b[0m datadict\u001b[39m.\u001b[39mupdate(dd)\n\u001b[1;32m    708\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_succ[u][v] \u001b[39m=\u001b[39m datadict\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_accs = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val2 = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "ellapsed_times = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    for i in range(N_RUNS):\n",
    "        print(f'{i}:', end=' ')\n",
    "        \n",
    "        A, feat, labels, n_class, masks = utils.get_data_dgl(dataset, dev=device, idx=i%10)\n",
    "        N = A.shape[0]\n",
    "        in_dim = feat.shape[1]\n",
    "        out_dim = n_class\n",
    "        \n",
    "        for k, exp in enumerate(EXPS):\n",
    "            t_i = time.time()\n",
    "            if exp['model'] == 'Kipf':\n",
    "                arch = GCNN_2L(in_dim, exp['hid_dim'], out_dim, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=exp['drop'], norm=exp['norm'])\n",
    "                S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "\n",
    "            elif exp['model'] == 'MLP':\n",
    "                arch = MLP(in_dim,  exp['hid_dim'], out_dim, dropout=exp['drop'])\n",
    "\n",
    "            elif exp['model'] == 'GAT':\n",
    "                gat_params = {'attn_drop': exp['drop']}\n",
    "                arch = GAT(in_dim,  exp['hid_dim'], out_dim, exp['heads'], gat_params, act=ACT, last_act=LAST_ACT)\n",
    "\n",
    "            elif exp['model'] == 'GFGCN':\n",
    "                arch = GFGCN(in_dim, exp['hid_dim'], out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=exp['drop'], diff_layer=GFGCNLayer, init_h0=exp['h0'])\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'H-GFGCN':\n",
    "                arch = GFGCN_Spows(in_dim, exp['hid_dim'], out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                                   dropout=exp['drop'], norm=exp['norm'], dev=device)\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'noh-GFGCN':\n",
    "                arch = GFGCN(in_dim, exp['hid_dim'], out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                             dropout=exp['drop'], diff_layer=GFGCN_noh_Layer)\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "            else:\n",
    "                raise Exception(f'ERROR: unknown architecture {exp[\"model\"]}')\n",
    "\n",
    "            if exp['model'] in ['Kipf', 'MLP', 'GAT', 'noh-GFGCN']:\n",
    "                model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "                loss, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'])\n",
    "            else:\n",
    "                model = GF_NodeClassModel(arch, S, exp['K'], masks, LOSS_FN, device=device)\n",
    "                loss, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'],\n",
    "                                        epochs_h=exp['e_h'], epochs_W=exp['e_W'])\n",
    "            ellapsed_t = (time.time()-t_i)/60\n",
    "            \n",
    "            \n",
    "            best_accs[k,j,i] = np.max(acc[\"test\"])\n",
    "            accs_best_val[k,j,i] = model.test(feat, model.S, labels, masks['test'])\n",
    "            accs_best_val2[k,j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "            ellapsed_times[k,j,i] = ellapsed_t\n",
    "\n",
    "            print(f'{accs_best_val[k,j,i]:.3f} ({best_accs[k,j,i]:.3f})', end=' - ')\n",
    "        print()      \n",
    "    print()\n",
    "\n",
    "\n",
    "print_full_results(accs_best_val, ellapsed_times, DATASETS, EXPS)\n",
    "table_acc1 = summary_table(best_accs, DATASETS, EXPS)\n",
    "table_acc_val1 = summary_table(accs_best_val, DATASETS, EXPS)\n",
    "table_acc_val1b = summary_table(accs_best_val2, DATASETS, EXPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TexasDataset (0.11)</th>\n",
       "      <th>WisconsinDataset (0.20)</th>\n",
       "      <th>CornellDataset (0.13)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kipf-normA</th>\n",
       "      <td>0.524324</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.448649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.772973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-default</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.713514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAT</th>\n",
       "      <td>0.535135</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.427027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN</th>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.751351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TexasDataset (0.11)  WisconsinDataset (0.20)  \\\n",
       "Kipf-normA              0.524324                 0.564706   \n",
       "MLP                     0.810811                 0.862745   \n",
       "MLP-default             0.800000                 0.835294   \n",
       "GAT                     0.535135                 0.521569   \n",
       "W-GCN                   0.783784                 0.772549   \n",
       "\n",
       "             CornellDataset (0.13)  \n",
       "Kipf-normA                0.448649  \n",
       "MLP                       0.772973  \n",
       "MLP-default               0.713514  \n",
       "GAT                       0.427027  \n",
       "W-GCN                     0.751351  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_acc_val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc_val1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "## Reaining params\n",
    "N_RUNS = 10\n",
    "N_EPOCHS = 200  # 500\n",
    "LR = .01\n",
    "WD = 5e-4\n",
    "DROPOUT = .5\n",
    "\n",
    "# BEST PARAMETERS\n",
    "## Architecture params\n",
    "N_LAYERS = 2\n",
    "K = 3\n",
    "HID_DIM = 16\n",
    "\n",
    "## Model params\n",
    "h0 = 1\n",
    "ACT = nn.ReLU()\n",
    "LAST_ACT = nn.LogSoftmax(dim=1)\n",
    "LOSS_FN = nn.NLLLoss()\n",
    "\n",
    "EXPS = [{'model': 'Kipf', 'norm': 'both', 'leg': 'Kipf-normA'},\n",
    "        {'model': 'Kipf', 'norm': 'none', 'leg': 'Kipf-A'},\n",
    "        {'model': 'MLP', 'leg': 'MLP-conf1'},\n",
    "        {'model': 'GAT', 'heads': 2, 'hid_dim': 16, 'leg': 'GAT'},\n",
    "        {'model': 'GFGCN', 'L': N_LAYERS, 'K': K, 'h0': h0, 'norm': True, 'leg': 'A-GCN-normA'},\n",
    "        {'model': 'GFGCN', 'L': N_LAYERS, 'K': K, 'h0': h0, 'norm': False, 'leg': 'A-GCN'},\n",
    "        {'model': 'H-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': True, 'leg': 'H-GCN-normH'},\n",
    "        {'model': 'H-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': False, 'leg': 'GCN-H'},\n",
    "        {'model': 'noh-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': True, 'leg': 'W-GCN-normA'},\n",
    "        {'model': 'noh-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': False, 'leg': 'W-GCN'},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TexasDataset\n",
      "0: 0.622 (0.676) - 0.784 (0.784) - 0.595 (0.649) - 0.622 (0.730) - \n",
      "1: 0.568 (0.595) - 0.730 (0.838) - 0.595 (0.595) - 0.649 (0.757) - \n",
      "2: 0.541 (0.541) - 0.757 (0.757) - 0.486 (0.568) - 0.649 (0.676) - \n",
      "3: 0.595 (0.622) - 0.811 (0.865) - 0.595 (0.649) - 0.568 (0.649) - \n",
      "4: 0.514 (0.568) - 0.784 (0.865) - 0.541 (0.595) - 0.514 (0.649) - \n",
      "\n",
      "WisconsinDataset\n",
      "0: 0.510 (0.569) - 0.745 (0.804) - 0.490 (0.549) - 0.373 (0.412) - \n",
      "1: 0.510 (0.627) - 0.843 (0.882) - 0.608 (0.647) - 0.725 (0.784) - \n",
      "2: 0.412 (0.569) - 0.824 (0.902) - 0.588 (0.588) - 0.608 (0.647) - \n",
      "3: 0.412 (0.529) - 0.863 (0.922) - 0.451 (0.529) - 0.627 (0.686) - \n",
      "4: 0.451 (0.549) - 0.784 (0.843) - 0.529 (0.588) - 0.392 (0.588) - \n",
      "\n",
      "CornellDataset\n",
      "0: 0.378 (0.514) - 0.730 (0.730) - 0.378 (0.514) - 0.459 (0.541) - \n",
      "1: 0.351 (0.459) - 0.703 (0.784) - 0.432 (0.459) - 0.622 (0.649) - \n",
      "2: 0.514 (0.568) - 0.730 (0.784) - 0.568 (0.568) - 0.595 (0.757) - \n",
      "3: 0.622 (0.622) - 0.757 (0.811) - 0.459 (0.514) - 0.541 (0.676) - \n",
      "4: 0.514 (0.622) - 0.730 (0.784) - 0.568 (0.676) - 0.541 (0.703) - \n",
      "\n",
      "TexasDataset (homophily ratio: 0.108)\n",
      "\t- Kipf-normA:\tmean: 0.568 - std: 0.0382 - med: 0.568 - time: 0.02 mins\n",
      "\t- MLP-conf1:\tmean: 0.773 - std: 0.0276 - med: 0.784 - time: 0.00 mins\n",
      "\t- GAT:\tmean: 0.562 - std: 0.0432 - med: 0.595 - time: 0.02 mins\n",
      "\t- W-GCN:\tmean: 0.600 - std: 0.0524 - med: 0.622 - time: 0.01 mins\n",
      "\n",
      "WisconsinDataset (homophily ratio: 0.196)\n",
      "\t- Kipf-normA:\tmean: 0.459 - std: 0.0440 - med: 0.451 - time: 0.02 mins\n",
      "\t- MLP-conf1:\tmean: 0.812 - std: 0.0422 - med: 0.824 - time: 0.00 mins\n",
      "\t- GAT:\tmean: 0.533 - std: 0.0587 - med: 0.529 - time: 0.02 mins\n",
      "\t- W-GCN:\tmean: 0.545 - std: 0.1389 - med: 0.608 - time: 0.01 mins\n",
      "\n",
      "CornellDataset (homophily ratio: 0.131)\n",
      "\t- Kipf-normA:\tmean: 0.476 - std: 0.0991 - med: 0.514 - time: 0.02 mins\n",
      "\t- MLP-conf1:\tmean: 0.730 - std: 0.0171 - med: 0.730 - time: 0.00 mins\n",
      "\t- GAT:\tmean: 0.481 - std: 0.0753 - med: 0.459 - time: 0.02 mins\n",
      "\t- W-GCN:\tmean: 0.551 - std: 0.0557 - med: 0.541 - time: 0.01 mins\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_accs = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val2 = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "ellapsed_times = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    for i in range(N_RUNS):\n",
    "        print(f'{i}:', end=' ')\n",
    "        \n",
    "        A, feat, labels, n_class, masks = utils.get_data_dgl(dataset, dev=device, idx=i%10)\n",
    "        N = A.shape[0]\n",
    "        in_dim = feat.shape[1]\n",
    "        out_dim = n_class\n",
    "        \n",
    "        for k, exp in enumerate(EXPS):\n",
    "            t_i = time.time()\n",
    "            if exp['model'] == 'Kipf':\n",
    "                arch = GCNN_2L(in_dim, HID_DIM, out_dim, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=DROPOUT, norm=exp['norm'])\n",
    "                S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "\n",
    "            elif exp['model'] == 'MLP':\n",
    "                arch = MLP(in_dim,  HID_DIM, out_dim, dropout=DROPOUT, act=ACT, last_act=LAST_ACT)\n",
    "            \n",
    "            elif exp['model'] == 'GAT':\n",
    "                gat_params = {'attn_drop': DROPOUT}\n",
    "                arch = GAT(in_dim,  HID_DIM, out_dim, exp['heads'], gat_params, act=ACT, last_act=LAST_ACT)\n",
    "\n",
    "            elif exp['model'] == 'GFGCN':\n",
    "                arch = GFGCN(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=DROPOUT, diff_layer=GFGCNLayer, init_h0=exp['h0'])\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'H-GFGCN':\n",
    "                arch = GFGCN_Spows(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                                   dropout=DROPOUT, norm=exp['norm'], dev=device)\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'noh-GFGCN':\n",
    "                arch = GFGCN(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                             dropout=DROPOUT, diff_layer=GFGCN_noh_Layer)\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "            else:\n",
    "                raise Exception(f'ERROR: unknown architecture {exp[\"model\"]}')\n",
    "\n",
    "            if exp['model'] in ['Kipf', 'MLP', 'GAT', 'noh-GFGCN']:\n",
    "                model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "            else:\n",
    "                model = GF_NodeClassModel(arch, S, exp['K'], masks, LOSS_FN, device=device)\n",
    "\n",
    "            loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "            ellapsed_t = (time.time()-t_i)/60\n",
    "            \n",
    "            \n",
    "            best_accs[k,j,i] = np.max(acc[\"test\"])\n",
    "            accs_best_val[k,j,i] = model.test(feat, model.S, labels, masks['test'])\n",
    "            accs_best_val2[k,j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "            ellapsed_times[k,j,i] = ellapsed_t\n",
    "\n",
    "            print(f'{accs_best_val[k,j,i]:.3f} ({best_accs[k,j,i]:.3f})', end=' - ')\n",
    "        print()      \n",
    "    print()\n",
    "\n",
    "\n",
    "print_full_results(accs_best_val, ellapsed_times, DATASETS, EXPS)\n",
    "table_acc2 = summary_table(best_accs, DATASETS, EXPS)\n",
    "table_acc_val2 = summary_table(accs_best_val, DATASETS, EXPS)\n",
    "table_acc_val2b = summary_table(accs_best_val2, DATASETS, EXPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TexasDataset (0.11)</th>\n",
       "      <th>WisconsinDataset (0.20)</th>\n",
       "      <th>CornellDataset (0.13)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kipf-normA</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.475676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP-conf1</th>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.729730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAT</th>\n",
       "      <td>0.562162</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.481081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.551351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TexasDataset (0.11)  WisconsinDataset (0.20)  \\\n",
       "Kipf-normA             0.567568                 0.458824   \n",
       "MLP-conf1              0.772973                 0.811765   \n",
       "GAT                    0.562162                 0.533333   \n",
       "W-GCN                  0.600000                 0.545098   \n",
       "\n",
       "            CornellDataset (0.13)  \n",
       "Kipf-normA               0.475676  \n",
       "MLP-conf1                0.729730  \n",
       "GAT                      0.481081  \n",
       "W-GCN                    0.551351  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_acc_val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc_val2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best params - GF-GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "N_RUNS = 20\n",
    "N_EPOCHS = 200  # 100\n",
    "EPOCHS_h = 25\n",
    "EPOCHS_W = 25\n",
    "LR = .005\n",
    "WD = .001\n",
    "DROPOUT = .25\n",
    "\n",
    "# BEST PARAMETERS\n",
    "## Architecture params\n",
    "N_LAYERS = 2\n",
    "K = 3  # 2\n",
    "HID_DIM = 32  # 32\n",
    "\n",
    "## Model params\n",
    "h0 = 1  # 1\n",
    "\n",
    "IN_DIM = feat.shape[1]\n",
    "OUT_DIM = n_class\n",
    "\n",
    "ACT = nn.LeakyReLU() \n",
    "LAST_ACT = nn.Softmax(dim=1)\n",
    "LOSS_FN = nn.CrossEntropyLoss()\n",
    "\n",
    "EXPS = [{'model': 'Kipf', 'norm': 'both', 'leg': 'Kipf-normA'},\n",
    "        {'model': 'Kipf', 'norm': 'none', 'leg': 'Kipf-A'},\n",
    "        {'model': 'GFGCN', 'L': N_LAYERS, 'K': K, 'h0': h0, 'norm': True, 'leg': 'A-GCN-normA'},\n",
    "        {'model': 'GFGCN', 'L': N_LAYERS, 'K': K, 'h0': h0, 'norm': False, 'leg': 'A-GCN'},\n",
    "        {'model': 'H-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': True, 'leg': 'H-GCN-normH'},\n",
    "        {'model': 'H-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': False, 'leg': 'GCN-H'},\n",
    "        {'model': 'noh-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': True, 'leg': 'W-GCN-normA'},\n",
    "        {'model': 'noh-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': False, 'leg': 'W-GCN'},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accs = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val2 = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "ellapsed_times = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    for i in range(N_RUNS):\n",
    "        print(f'{i}:', end=' ')\n",
    "        \n",
    "        A, feat, labels, n_class, masks = utils.get_data_dgl(dataset, dev=device, idx=i%10)\n",
    "        N = A.shape[0]\n",
    "        in_dim = feat.shape[1]\n",
    "        out_dim = n_class\n",
    "        \n",
    "        for k, exp in enumerate(EXPS):\n",
    "            t_i = time.time()\n",
    "            if exp['model'] == 'Kipf':\n",
    "                arch = GCNN_2L(in_dim, HID_DIM, out_dim, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=DROPOUT, norm=exp['norm'])\n",
    "                S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "\n",
    "            elif exp['model'] == 'GFGCN':\n",
    "                arch = GFGCN(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=DROPOUT, diff_layer=GFGCNLayer, init_h0=exp['h0'])\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'H-GFGCN':\n",
    "                arch = GFGCN_Spows(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                                   dropout=DROPOUT, norm=exp['norm'], dev=device)\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'noh-GFGCN':\n",
    "                arch = GFGCN(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                             dropout=DROPOUT, diff_layer=GFGCN_noh_Layer)\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "            else:\n",
    "                raise Exception(f'ERROR: unknown architecture {exp[\"model\"]}')\n",
    "\n",
    "            if exp['model'] in ['Kipf', 'noh-GFGCN']:\n",
    "                model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "                loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "            else:\n",
    "                model = GF_NodeClassModel(arch, S, exp['K'], masks, LOSS_FN, device=device)\n",
    "                loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD, epochs_h=EPOCHS_h,\n",
    "                                        epochs_W=EPOCHS_W)\n",
    "            ellapsed_t = (time.time()-t_i)/60\n",
    "            \n",
    "            \n",
    "            best_accs[k,j,i] = np.max(acc[\"test\"])\n",
    "            accs_best_val[k,j,i] = model.test(feat, model.S, labels, masks['test'])\n",
    "            accs_best_val2[k,j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "            ellapsed_times[k,j,i] = ellapsed_t\n",
    "\n",
    "            print(f'{accs_best_val[k,j,i]:.3f} ({best_accs[k,j,i]:.3f})', end=' - ')\n",
    "        print()      \n",
    "    print()\n",
    "\n",
    "\n",
    "print_full_results(accs_best_val, ellapsed_times, DATASETS, EXPS)\n",
    "table_acc2 = summary_table(best_accs, DATASETS, EXPS)\n",
    "table_acc_val2 = summary_table(accs_best_val, DATASETS, EXPS)\n",
    "table_acc_val2b = summary_table(accs_best_val2, DATASETS, EXPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc_val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best params - GF-GNN norm H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "N_RUNS = 20\n",
    "N_EPOCHS = 200  # 5000\n",
    "EPOCHS_h = 25 # 5 # 5\n",
    "EPOCHS_W = 25 # 5 # 25\n",
    "LR = .005\n",
    "WD = .001  # .001\n",
    "DROPOUT = .25\n",
    "\n",
    "# BEST PARAMETERS\n",
    "## Architecture params\n",
    "N_LAYERS = 3\n",
    "K = 2\n",
    "HID_DIM = 50 # 100\n",
    "\n",
    "## Model params\n",
    "NORM = True\n",
    "\n",
    "IN_DIM = feat.shape[1]\n",
    "OUT_DIM = n_class\n",
    "\n",
    "ACT = nn.LeakyReLU()  # nn.ELU()\n",
    "LAST_ACT = nn.Softmax()\n",
    "LOSS_FN = nn.CrossEntropyLoss()  # nn.CrossEntropyLoss()\n",
    "\n",
    "EXPS = [{'model': 'Kipf', 'norm': 'both', 'leg': 'Kipf-normA'},\n",
    "        {'model': 'Kipf', 'norm': 'none', 'leg': 'Kipf-A'},\n",
    "        {'model': 'GFGCN', 'L': N_LAYERS, 'K': K, 'h0': h0, 'norm': True, 'leg': 'A-GCN-normA'},\n",
    "        {'model': 'GFGCN', 'L': N_LAYERS, 'K': K, 'h0': h0, 'norm': False, 'leg': 'A-GCN'},\n",
    "        {'model': 'H-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': True, 'leg': 'H-GCN-normH'},\n",
    "        {'model': 'H-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': False, 'leg': 'GCN-H'},\n",
    "        {'model': 'noh-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': True, 'leg': 'W-GCN-normA'},\n",
    "        {'model': 'noh-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': False, 'leg': 'W-GCN'},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accs = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val2 = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "ellapsed_times = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    for i in range(N_RUNS):\n",
    "        print(f'{i}:', end=' ')\n",
    "        \n",
    "        A, feat, labels, n_class, masks = utils.get_data_dgl(dataset, dev=device, idx=i%10)\n",
    "        N = A.shape[0]\n",
    "        in_dim = feat.shape[1]\n",
    "        out_dim = n_class\n",
    "        \n",
    "        for k, exp in enumerate(EXPS):\n",
    "            t_i = time.time()\n",
    "            if exp['model'] == 'Kipf':\n",
    "                arch = GCNN_2L(in_dim, HID_DIM, out_dim, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=DROPOUT, norm=exp['norm'])\n",
    "                S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "\n",
    "            elif exp['model'] == 'GFGCN':\n",
    "                arch = GFGCN(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=DROPOUT, diff_layer=GFGCNLayer, init_h0=exp['h0'])\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'H-GFGCN':\n",
    "                arch = GFGCN_Spows(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                                   dropout=DROPOUT, norm=exp['norm'], dev=device)\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'noh-GFGCN':\n",
    "                arch = GFGCN(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                             dropout=DROPOUT, diff_layer=GFGCN_noh_Layer)\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "            else:\n",
    "                raise Exception(f'ERROR: unknown architecture {exp[\"model\"]}')\n",
    "\n",
    "            if exp['model'] in ['Kipf', 'noh-GFGCN']:\n",
    "                model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "                loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "            else:\n",
    "                model = GF_NodeClassModel(arch, S, exp['K'], masks, LOSS_FN, device=device)\n",
    "                loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD, epochs_h=EPOCHS_h,\n",
    "                                        epochs_W=EPOCHS_W)\n",
    "            ellapsed_t = (time.time()-t_i)/60\n",
    "            \n",
    "            \n",
    "            best_accs[k,j,i] = np.max(acc[\"test\"])\n",
    "            accs_best_val[k,j,i] = model.test(feat, model.S, labels, masks['test'])\n",
    "            accs_best_val2[k,j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "            ellapsed_times[k,j,i] = ellapsed_t\n",
    "\n",
    "            print(f'{accs_best_val[k,j,i]:.3f} ({best_accs[k,j,i]:.3f})', end=' - ')\n",
    "        print()      \n",
    "    print()\n",
    "\n",
    "\n",
    "print_full_results(accs_best_val, ellapsed_times, DATASETS, EXPS)\n",
    "table_acc2 = summary_table(best_accs, DATASETS, EXPS)\n",
    "table_acc_val2 = summary_table(accs_best_val, DATASETS, EXPS)\n",
    "table_acc_val2b = summary_table(accs_best_val2, DATASETS, EXPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc_val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best params - GF-GNN no h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "N_RUNS = 20\n",
    "N_EPOCHS = 500  # 500\n",
    "LR = .05  # .01\n",
    "WD = .005  # .005\n",
    "DROPOUT = .25\n",
    "\n",
    "# BEST PARAMETERS\n",
    "## Architecture params\n",
    "N_LAYERS = 2\n",
    "K = 3  # 2\n",
    "HID_DIM = 32 # 8\n",
    "\n",
    "## Model params\n",
    "h0 = 1  # 1\n",
    "NORM = False\n",
    "\n",
    "IN_DIM = feat.shape[1]\n",
    "OUT_DIM = n_class\n",
    "\n",
    "ACT = nn.ReLU()\n",
    "LAST_ACT = nn.Softmax(dim=1)\n",
    "LOSS_FN = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "EXPS = [{'model': 'Kipf', 'norm': 'both', 'leg': 'Kipf-normA'},\n",
    "        {'model': 'Kipf', 'norm': 'none', 'leg': 'Kipf-A'},\n",
    "        {'model': 'GFGCN', 'L': N_LAYERS, 'K': K, 'h0': h0, 'norm': True, 'leg': 'A-GCN-normA'},\n",
    "        {'model': 'GFGCN', 'L': N_LAYERS, 'K': K, 'h0': h0, 'norm': False, 'leg': 'A-GCN'},\n",
    "        {'model': 'H-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': True, 'leg': 'H-GCN-normH'},\n",
    "        {'model': 'H-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': False, 'leg': 'GCN-H'},\n",
    "        {'model': 'noh-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': True, 'leg': 'W-GCN-normA'},\n",
    "        {'model': 'noh-GFGCN', 'L': N_LAYERS, 'K': K, 'norm': False, 'leg': 'W-GCN'},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accs = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "accs_best_val2 = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "ellapsed_times = np.zeros((len(EXPS), len(DATASETS), N_RUNS))\n",
    "for j, dataset in enumerate(DATASETS):\n",
    "\n",
    "    print(dataset)\n",
    "\n",
    "    for i in range(N_RUNS):\n",
    "        print(f'{i}:', end=' ')\n",
    "        \n",
    "        A, feat, labels, n_class, masks = utils.get_data_dgl(dataset, dev=device, idx=i%10)\n",
    "        N = A.shape[0]\n",
    "        in_dim = feat.shape[1]\n",
    "        out_dim = n_class\n",
    "        \n",
    "        for k, exp in enumerate(EXPS):\n",
    "            t_i = time.time()\n",
    "            if exp['model'] == 'Kipf':\n",
    "                arch = GCNN_2L(in_dim, HID_DIM, out_dim, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=DROPOUT, norm=exp['norm'])\n",
    "                S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "\n",
    "            elif exp['model'] == 'GFGCN':\n",
    "                arch = GFGCN(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=DROPOUT, diff_layer=GFGCNLayer, init_h0=exp['h0'])\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'H-GFGCN':\n",
    "                arch = GFGCN_Spows(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                                   dropout=DROPOUT, norm=exp['norm'], dev=device)\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "            elif exp['model'] == 'noh-GFGCN':\n",
    "                arch = GFGCN(in_dim, HID_DIM, out_dim, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                             dropout=DROPOUT, diff_layer=GFGCN_noh_Layer)\n",
    "                if exp['norm']:\n",
    "                    S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "                else:\n",
    "                    S = torch.Tensor(A).to(device)\n",
    "            else:\n",
    "                raise Exception(f'ERROR: unknown architecture {exp[\"model\"]}')\n",
    "\n",
    "            if exp['model'] in ['Kipf', 'noh-GFGCN']:\n",
    "                model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "                loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "            else:\n",
    "                model = GF_NodeClassModel(arch, S, exp['K'], masks, LOSS_FN, device=device)\n",
    "                loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD, epochs_h=EPOCHS_h,\n",
    "                                        epochs_W=EPOCHS_W)\n",
    "            ellapsed_t = (time.time()-t_i)/60\n",
    "            \n",
    "            \n",
    "            best_accs[k,j,i] = np.max(acc[\"test\"])\n",
    "            accs_best_val[k,j,i] = model.test(feat, model.S, labels, masks['test'])\n",
    "            accs_best_val2[k,j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "            ellapsed_times[k,j,i] = ellapsed_t\n",
    "\n",
    "            print(f'{accs_best_val[k,j,i]:.3f} ({best_accs[k,j,i]:.3f})', end=' - ')\n",
    "        print()      \n",
    "    print()\n",
    "\n",
    "\n",
    "print_full_results(accs_best_val, ellapsed_times, DATASETS, EXPS)\n",
    "table_acc2 = summary_table(best_accs, DATASETS, EXPS)\n",
    "table_acc_val2 = summary_table(accs_best_val, DATASETS, EXPS)\n",
    "table_acc_val2b = summary_table(accs_best_val2, DATASETS, EXPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc_val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_acc2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

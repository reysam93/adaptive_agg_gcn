{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f735b7cf890>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import utils\n",
    "from gsp_utils.baselines_archs import GCNN_2L\n",
    "from gsp_utils.baselines_models import NodeClassModel, GF_NodeClassModel\n",
    "from gsp_utils.data import normalize_gso\n",
    "from src.arch import GFGCN, GFGCNLayer, GFGCN_noh_Layer, GFGCN_Spows\n",
    "\n",
    "SEED = 15\n",
    "# PATH = 'results/diff_filters/'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def compute_S_pows(S, K, device):\n",
    "    N = S.shape[0]\n",
    "    S_pows = torch.Tensor(torch.empty(K-1, N, N)).to(device)\n",
    "    S_pows[0,:,:] = torch.Tensor(S).to(device)\n",
    "    for k in range(1,K-1):\n",
    "        S_pows[k,:,:] = S_pows[0,:,:] @ S_pows[k-1,:,:]\n",
    "\n",
    "    return S_pows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CornellDataset\n",
      "Number of nodes: 183\n",
      "Number of features: 1703\n",
      "Shape of signals: torch.Size([183, 1703])\n",
      "Number of classes: 5\n",
      "Norm of A: 17.262676239013672\n",
      "Max value of A: 1.0\n",
      "Proportion of validation data: 0.32\n",
      "Proportion of test data: 0.20\n",
      "Node homophily: 0.11\n",
      "Edge homophily: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Dataset must be from DGL\n",
    "dataset_name = 'CornellDataset'\n",
    "\n",
    "A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device,\n",
    "                                                     verb=True)\n",
    "N = A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "## Reaining params\n",
    "N_RUNS = 10\n",
    "N_EPOCHS = 1000  # 500\n",
    "LR = .05\n",
    "WD = .01\n",
    "DROPOUT = 0\n",
    "\n",
    "# BEST PARAMETERS\n",
    "## Architecture params\n",
    "N_LAYERS = 2\n",
    "K = 3\n",
    "HID_DIM = 32\n",
    "\n",
    "## Model params\n",
    "NORM = True\n",
    "\n",
    "IN_DIM = feat.shape[1]\n",
    "OUT_DIM = n_class\n",
    "\n",
    "\n",
    "ACT = nn.ReLU()\n",
    "LAST_ACT = nn.Softmax(dim=1)\n",
    "LOSS_FN = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 500-0.1-0.05: 0.649\n",
      "-1: 500-0.05-0.05: 0.703\n",
      "-1: 500-0.01-0.05: 0.622\n",
      "-1: 500-0.005-0.05: 0.486\n",
      "-1: 500-0.01-0.1: 0.514\n",
      "-1: 500-0.01-0.01: 0.811\n",
      "-1: 500-0.01-0.001: 0.784\n",
      "-1: 500-0.05-0.1: 0.541\n",
      "-1: 500-0.05-0.01: 0.838\n",
      "-1: 500-0.05-0.001: 0.703\n",
      "-1: 1000-0.05-0.01: 0.838\n",
      "-1: 5000-0.01-0.001: 0.811\n",
      "-1: 5000-0.05-0.01: 0.811\n",
      "-2: 500-0.1-0.05: 0.649\n",
      "-2: 500-0.05-0.05: 0.622\n",
      "-2: 500-0.01-0.05: 0.541\n",
      "-2: 500-0.005-0.05: 0.541\n",
      "-2: 500-0.01-0.1: 0.541\n",
      "-2: 500-0.01-0.01: 0.514\n",
      "-2: 500-0.01-0.001: 0.784\n",
      "-2: 500-0.05-0.1: 0.541\n"
     ]
    }
   ],
   "source": [
    "EXPS = [\n",
    "        {'epochs': 500, 'lr': .1, 'wd': 5e-2},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 5e-2},\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 5e-2},\n",
    "        {'epochs': 500, 'lr': .005, 'wd': 5e-2},\n",
    "\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 1e-1},\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 1e-2},\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 1e-3},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-1},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-3},\n",
    "\n",
    "\n",
    "        {'epochs': 1000, 'lr': .05, 'wd': 1e-2},\n",
    "        {'epochs': 5000, 'lr': .01, 'wd': 1e-3},\n",
    "        {'epochs': 5000, 'lr': .05, 'wd': 1e-2},\n",
    "        ]\n",
    "\n",
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):        \n",
    "        arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=NORM, dev=device)\n",
    "        S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'])\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}: {best_accs[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs.mean(axis=1)\n",
    "std_accs = best_accs.std(axis=1)\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}' for exp in EXPS]\n",
    "table1 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500-0.1-0.05</th>\n",
       "      <td>0.628108</td>\n",
       "      <td>0.066326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.05</th>\n",
       "      <td>0.681081</td>\n",
       "      <td>0.086486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.05</th>\n",
       "      <td>0.591351</td>\n",
       "      <td>0.078078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.005-0.05</th>\n",
       "      <td>0.542703</td>\n",
       "      <td>0.062066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.1</th>\n",
       "      <td>0.561081</td>\n",
       "      <td>0.041365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.01</th>\n",
       "      <td>0.722162</td>\n",
       "      <td>0.109055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.001</th>\n",
       "      <td>0.761081</td>\n",
       "      <td>0.084324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.1</th>\n",
       "      <td>0.628108</td>\n",
       "      <td>0.075784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01</th>\n",
       "      <td>0.741622</td>\n",
       "      <td>0.105670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.001</th>\n",
       "      <td>0.682162</td>\n",
       "      <td>0.122377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000-0.05-0.01</th>\n",
       "      <td>0.781622</td>\n",
       "      <td>0.086459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-0.05-0.01</th>\n",
       "      <td>0.806486</td>\n",
       "      <td>0.066061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000-0.05-0.01</th>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.035790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean accs       std\n",
       "500-0.1-0.05     0.628108  0.066326\n",
       "500-0.05-0.05    0.681081  0.086486\n",
       "500-0.01-0.05    0.591351  0.078078\n",
       "500-0.005-0.05   0.542703  0.062066\n",
       "500-0.01-0.1     0.561081  0.041365\n",
       "500-0.01-0.01    0.722162  0.109055\n",
       "500-0.01-0.001   0.761081  0.084324\n",
       "500-0.05-0.1     0.628108  0.075784\n",
       "500-0.05-0.01    0.741622  0.105670\n",
       "500-0.05-0.001   0.682162  0.122377\n",
       "1000-0.05-0.01   0.781622  0.086459\n",
       "2000-0.05-0.01   0.806486  0.066061\n",
       "5000-0.05-0.01   0.840000  0.035790"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 1-1-True: 0.784\n",
      "-1: 1-1-True: 0.757\n",
      "-1: 1-1-False: 0.270\n",
      "-1: 10-1-True: 0.784\n",
      "-1: 1-10-True: 0.811\n",
      "-1: 1-25-True: 0.730\n",
      "-1: 1-50-True: 0.757\n",
      "-1: 10-10-True: 0.784\n",
      "-1: 25-25-True: 0.811\n",
      "-1: 50-50-True: 0.757\n",
      "-2: 1-1-True: 0.811\n",
      "-2: 1-1-True: 0.892\n",
      "-2: 1-1-False: 0.270\n",
      "-2: 10-1-True: 0.622\n",
      "-2: 1-10-True: 0.595\n",
      "-2: 1-25-True: 0.865\n",
      "-2: 1-50-True: 0.730\n",
      "-2: 10-10-True: 0.811\n",
      "-2: 25-25-True: 0.838\n",
      "-2: 50-50-True: 0.784\n",
      "-3: 1-1-True: 0.541\n",
      "-3: 1-1-True: 0.838\n",
      "-3: 1-1-False: 0.270\n",
      "-3: 10-1-True: 0.757\n",
      "-3: 1-10-True: 0.784\n",
      "-3: 1-25-True: 0.811\n",
      "-3: 1-50-True: 0.730\n",
      "-3: 10-10-True: 0.784\n",
      "-3: 25-25-True: 0.757\n",
      "-3: 50-50-True: 0.784\n",
      "-4: 1-1-True: 0.703\n",
      "-4: 1-1-True: 0.757\n",
      "-4: 1-1-False: 0.270\n",
      "-4: 10-1-True: 0.730\n",
      "-4: 1-10-True: 0.649\n",
      "-4: 1-25-True: 0.622\n",
      "-4: 1-50-True: 0.568\n",
      "-4: 10-10-True: 0.838\n",
      "-4: 25-25-True: 0.811\n",
      "-4: 50-50-True: 0.784\n",
      "-5: 1-1-True: 0.838\n",
      "-5: 1-1-True: 0.838\n",
      "-5: 1-1-False: 0.270\n",
      "-5: 10-1-True: 0.730\n",
      "-5: 1-10-True: 0.757\n",
      "-5: 1-25-True: 0.703\n",
      "-5: 1-50-True: 0.568\n",
      "-5: 10-10-True: 0.838\n",
      "-5: 25-25-True: 0.676\n",
      "-5: 50-50-True: 0.811\n",
      "-6: 1-1-True: 0.649\n",
      "-6: 1-1-True: 0.892\n",
      "-6: 1-1-False: 0.270\n",
      "-6: 10-1-True: 0.811\n",
      "-6: 1-10-True: 0.838\n",
      "-6: 1-25-True: 0.514\n",
      "-6: 1-50-True: 0.568\n",
      "-6: 10-10-True: 0.595\n",
      "-6: 25-25-True: 0.838\n",
      "-6: 50-50-True: 0.757\n",
      "-7: 1-1-True: 0.811\n",
      "-7: 1-1-True: 0.892\n",
      "-7: 1-1-False: 0.270\n",
      "-7: 10-1-True: 0.838\n",
      "-7: 1-10-True: 0.730\n",
      "-7: 1-25-True: 0.811\n",
      "-7: 1-50-True: 0.703\n",
      "-7: 10-10-True: 0.811\n",
      "-7: 25-25-True: 0.784\n",
      "-7: 50-50-True: 0.541\n",
      "-8: 1-1-True: 0.486\n",
      "-8: 1-1-True: 0.838\n",
      "-8: 1-1-False: 0.270\n",
      "-8: 10-1-True: 0.622\n",
      "-8: 1-10-True: 0.730\n",
      "-8: 1-25-True: 0.811\n",
      "-8: 1-50-True: 0.568\n",
      "-8: 10-10-True: 0.730\n",
      "-8: 25-25-True: 0.784\n",
      "-8: 50-50-True: 0.865\n",
      "-9: 1-1-True: 0.514\n",
      "-9: 1-1-True: 0.865\n",
      "-9: 1-1-False: 0.270\n",
      "-9: 10-1-True: 0.757\n",
      "-9: 1-10-True: 0.622\n",
      "-9: 1-25-True: 0.649\n",
      "-9: 1-50-True: 0.622\n",
      "-9: 10-10-True: 0.730\n",
      "-9: 25-25-True: 0.811\n",
      "-9: 50-50-True: 0.811\n",
      "-10: 1-1-True: 0.541\n",
      "-10: 1-1-True: 0.703\n",
      "-10: 1-1-False: 0.270\n",
      "-10: 10-1-True: 0.595\n",
      "-10: 1-10-True: 0.838\n",
      "-10: 1-25-True: 0.811\n",
      "-10: 1-50-True: 0.514\n",
      "-10: 10-10-True: 0.838\n",
      "-10: 25-25-True: 0.811\n",
      "-10: 50-50-True: 0.649\n",
      "-11: 1-1-True: 0.568\n",
      "-11: 1-1-True: 0.838\n",
      "-11: 1-1-False: 0.270\n",
      "-11: 10-1-True: 0.784\n",
      "-11: 1-10-True: 0.838\n",
      "-11: 1-25-True: 0.703\n",
      "-11: 1-50-True: 0.568\n",
      "-11: 10-10-True: 0.757\n",
      "-11: 25-25-True: 0.757\n",
      "-11: 50-50-True: 0.757\n",
      "-12: 1-1-True: 0.676\n",
      "-12: 1-1-True: 0.838\n",
      "-12: 1-1-False: 0.270\n",
      "-12: 10-1-True: 0.459\n",
      "-12: 1-10-True: 0.595\n",
      "-12: 1-25-True: 0.541\n",
      "-12: 1-50-True: 0.622\n",
      "-12: 10-10-True: 0.568\n",
      "-12: 25-25-True: 0.730\n",
      "-12: 50-50-True: 0.703\n",
      "-13: 1-1-True: 0.703\n",
      "-13: 1-1-True: 0.838\n",
      "-13: 1-1-False: 0.270\n",
      "-13: 10-1-True: 0.730\n",
      "-13: 1-10-True: 0.811\n",
      "-13: 1-25-True: 0.811\n",
      "-13: 1-50-True: 0.811\n",
      "-13: 10-10-True: 0.730\n",
      "-13: 25-25-True: 0.622\n",
      "-13: 50-50-True: 0.595\n",
      "-14: 1-1-True: 0.784\n",
      "-14: 1-1-True: 0.838\n",
      "-14: 1-1-False: 0.270\n",
      "-14: 10-1-True: 0.838\n",
      "-14: 1-10-True: 0.784\n",
      "-14: 1-25-True: 0.568\n",
      "-14: 1-50-True: 0.730\n",
      "-14: 10-10-True: 0.838\n",
      "-14: 25-25-True: 0.838\n",
      "-14: 50-50-True: 0.757\n",
      "-15: 1-1-True: 0.757\n",
      "-15: 1-1-True: 0.865\n",
      "-15: 1-1-False: 0.270\n",
      "-15: 10-1-True: 0.838\n",
      "-15: 1-10-True: 0.649\n",
      "-15: 1-25-True: 0.595\n",
      "-15: 1-50-True: 0.595\n",
      "-15: 10-10-True: 0.865\n",
      "-15: 25-25-True: 0.730\n",
      "-15: 50-50-True: 0.757\n",
      "-16: 1-1-True: 0.811\n",
      "-16: 1-1-True: 0.838\n",
      "-16: 1-1-False: 0.270\n",
      "-16: 10-1-True: 0.811\n",
      "-16: 1-10-True: 0.703\n",
      "-16: 1-25-True: 0.568\n",
      "-16: 1-50-True: 0.730\n",
      "-16: 10-10-True: 0.541\n",
      "-16: 25-25-True: 0.838\n",
      "-16: 50-50-True: 0.541\n",
      "-17: 1-1-True: 0.514\n",
      "-17: 1-1-True: 0.838\n",
      "-17: 1-1-False: 0.270\n",
      "-17: 10-1-True: 0.649\n",
      "-17: 1-10-True: 0.541\n",
      "-17: 1-25-True: 0.838\n",
      "-17: 1-50-True: 0.541\n",
      "-17: 10-10-True: 0.703\n",
      "-17: 25-25-True: 0.838\n",
      "-17: 50-50-True: 0.514\n",
      "-18: 1-1-True: 0.757\n",
      "-18: 1-1-True: 0.865\n",
      "-18: 1-1-False: 0.270\n",
      "-18: 10-1-True: 0.784\n",
      "-18: 1-10-True: 0.649\n",
      "-18: 1-25-True: 0.568\n",
      "-18: 1-50-True: 0.757\n",
      "-18: 10-10-True: 0.757\n",
      "-18: 25-25-True: 0.568\n",
      "-18: 50-50-True: 0.730\n",
      "-19: 1-1-True: 0.838\n",
      "-19: 1-1-True: 0.865\n",
      "-19: 1-1-False: 0.270\n",
      "-19: 10-1-True: 0.784\n",
      "-19: 1-10-True: 0.811\n",
      "-19: 1-25-True: 0.541\n",
      "-19: 1-50-True: 0.838\n",
      "-19: 10-10-True: 0.811\n",
      "-19: 25-25-True: 0.811\n",
      "-19: 50-50-True: 0.811\n",
      "-20: 1-1-True: 0.784\n",
      "-20: 1-1-True: 0.838\n",
      "-20: 1-1-False: 0.270\n",
      "-20: 10-1-True: 0.514\n",
      "-20: 1-10-True: 0.703\n",
      "-20: 1-25-True: 0.811\n",
      "-20: 1-50-True: 0.514\n",
      "-20: 10-10-True: 0.676\n",
      "-20: 25-25-True: 0.703\n",
      "-20: 50-50-True: 0.784\n",
      "-21: 1-1-True: 0.784\n",
      "-21: 1-1-True: 0.865\n",
      "-21: 1-1-False: 0.270\n",
      "-21: 10-1-True: 0.838\n",
      "-21: 1-10-True: 0.541\n",
      "-21: 1-25-True: 0.514\n",
      "-21: 1-50-True: 0.784\n",
      "-21: 10-10-True: 0.757\n",
      "-21: 25-25-True: 0.811\n",
      "-21: 50-50-True: 0.838\n",
      "-22: 1-1-True: 0.838\n",
      "-22: 1-1-True: 0.865\n",
      "-22: 1-1-False: 0.270\n",
      "-22: 10-1-True: 0.649\n",
      "-22: 1-10-True: 0.703\n",
      "-22: 1-25-True: 0.811\n",
      "-22: 1-50-True: 0.784\n",
      "-22: 10-10-True: 0.730\n",
      "-22: 25-25-True: 0.865\n",
      "-22: 50-50-True: 0.811\n",
      "-23: 1-1-True: 0.838\n",
      "-23: 1-1-True: 0.865\n",
      "-23: 1-1-False: 0.270\n",
      "-23: 10-1-True: 0.541\n",
      "-23: 1-10-True: 0.568\n",
      "-23: 1-25-True: 0.541\n",
      "-23: 1-50-True: 0.838\n",
      "-23: 10-10-True: 0.784\n",
      "-23: 25-25-True: 0.811\n",
      "-23: 50-50-True: 0.730\n",
      "-24: 1-1-True: 0.811\n",
      "-24: 1-1-True: 0.892\n",
      "-24: 1-1-False: 0.270\n",
      "-24: 10-1-True: 0.730\n",
      "-24: 1-10-True: 0.622\n",
      "-24: 1-25-True: 0.811\n",
      "-24: 1-50-True: 0.595\n",
      "-24: 10-10-True: 0.838\n",
      "-24: 25-25-True: 0.811\n",
      "-24: 50-50-True: 0.838\n",
      "-25: 1-1-True: 0.595\n",
      "-25: 1-1-True: 0.757\n",
      "-25: 1-1-False: 0.270\n",
      "-25: 10-1-True: 0.865\n",
      "-25: 1-10-True: 0.811\n",
      "-25: 1-25-True: 0.838\n",
      "-25: 1-50-True: 0.730\n",
      "-25: 10-10-True: 0.811\n",
      "-25: 25-25-True: 0.784\n",
      "-25: 50-50-True: 0.676\n",
      "----- 67.85 mins -----\n"
     ]
    }
   ],
   "source": [
    "# h0, norm (norm, not norm, norm H), sep vs joint training, optimizers iters (W vs h)\n",
    "EXPS = [{'epochs': 500, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'epochs': 2000, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},        \n",
    "        {'epochs': 500, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "\n",
    "        {'epochs': 500, 'epochs_h': 10, 'epochs_W': 1, 'alt': True},\n",
    "        {'epochs': 500, 'epochs_h': 25, 'epochs_W': 1, 'alt': True},\n",
    "        {'epochs': 500, 'epochs_h': 1, 'epochs_W': 10, 'alt': True},\n",
    "        {'epochs': 500, 'epochs_h': 1, 'epochs_W': 25, 'alt': True},\n",
    "        {'epochs': 200, 'epochs_h': 1, 'epochs_W': 50, 'alt': True},\n",
    "\n",
    "        {'epochs': 500, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'epochs': 500, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        {'epochs': 100, 'epochs_h': 50, 'epochs_W': 50, 'alt': True},]\n",
    "\n",
    "\n",
    "best_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=NORM, dev=device)\n",
    "        S = torch.Tensor(A).to(device)\n",
    "\n",
    "        if not exp['alt']:\n",
    "            S_pows = compute_S_pows(A, K, device)\n",
    "            model = NodeClassModel(arch, S_pows, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S,  K, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD, epochs_h=exp['epochs_h'],\n",
    "                                 epochs_W=exp['epochs_W'])\n",
    "\n",
    "        best_accs2[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}: {best_accs2[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs2.mean(axis=1)\n",
    "std_accs = best_accs2.std(axis=1)\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}' for exp in EXPS]\n",
    "table2 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-1-1-True</th>\n",
       "      <td>0.709189</td>\n",
       "      <td>0.119233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000-1-1-True</th>\n",
       "      <td>0.838919</td>\n",
       "      <td>0.046800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-False</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-10-1-True</th>\n",
       "      <td>0.722162</td>\n",
       "      <td>0.109590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-True</th>\n",
       "      <td>0.707027</td>\n",
       "      <td>0.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-True</th>\n",
       "      <td>0.695135</td>\n",
       "      <td>0.123622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100-1-50-True</th>\n",
       "      <td>0.670270</td>\n",
       "      <td>0.103975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-10-10-True</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.084780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-25-25-True</th>\n",
       "      <td>0.777297</td>\n",
       "      <td>0.070594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100-50-50-True</th>\n",
       "      <td>0.735135</td>\n",
       "      <td>0.095784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean accs       std\n",
       "200-1-1-True     0.709189  0.119233\n",
       "5000-1-1-True    0.838919  0.046800\n",
       "200-1-1-False    0.270270  0.000000\n",
       "200-10-1-True    0.722162  0.109590\n",
       "200-1-10-True    0.707027  0.096900\n",
       "200-1-25-True    0.695135  0.123622\n",
       "100-1-50-True    0.670270  0.103975\n",
       "200-10-10-True   0.756757  0.084780\n",
       "200-25-25-True   0.777297  0.070594\n",
       "100-50-50-True   0.735135  0.095784"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 2-2-16: 0.892\n",
      "-1: 2-3-16: 0.784\n",
      "-1: 2-4-16: 0.595\n",
      "-1: 3-2-16: 0.865\n",
      "-1: 4-2-16: 0.568\n",
      "-1: 3-3-16: 0.541\n",
      "-1: 4-3-16: 0.541\n",
      "-1: 2-2-8: 0.892\n",
      "-1: 2-2-32: 0.838\n",
      "-1: 2-2-50: 0.865\n",
      "-1: 2-3-8: 0.811\n",
      "-1: 2-3-32: 0.784\n",
      "-1: 2-3-50: 0.568\n",
      "-1: 3-2-8: 0.703\n",
      "-1: 3-2-32: 0.865\n",
      "-1: 3-2-50: 0.838\n",
      "-1: 3-3-8: 0.784\n",
      "-1: 3-3-32: 0.541\n",
      "-1: 3-3-50: 0.892\n",
      "-2: 2-2-16: 0.865\n",
      "-2: 2-3-16: 0.838\n",
      "-2: 2-4-16: 0.622\n",
      "-2: 3-2-16: 0.892\n",
      "-2: 4-2-16: 0.703\n",
      "-2: 3-3-16: 0.703\n",
      "-2: 4-3-16: 0.568\n",
      "-2: 2-2-8: 0.865\n",
      "-2: 2-2-32: 0.730\n",
      "-2: 2-2-50: 0.865\n",
      "-2: 2-3-8: 0.757\n",
      "-2: 2-3-32: 0.865\n",
      "-2: 2-3-50: 0.649\n",
      "-2: 3-2-8: 0.811\n",
      "-2: 3-2-32: 0.811\n",
      "-2: 3-2-50: 0.865\n",
      "-2: 3-3-8: 0.730\n",
      "-2: 3-3-32: 0.811\n",
      "-2: 3-3-50: 0.595\n",
      "-3: 2-2-16: 0.892\n",
      "-3: 2-3-16: 0.757\n",
      "-3: 2-4-16: 0.730\n",
      "-3: 3-2-16: 0.865\n",
      "-3: 4-2-16: 0.838\n",
      "-3: 3-3-16: 0.595\n",
      "-3: 4-3-16: 0.541\n",
      "-3: 2-2-8: 0.838\n",
      "-3: 2-2-32: 0.892\n",
      "-3: 2-2-50: 0.892\n",
      "-3: 2-3-8: 0.676\n",
      "-3: 2-3-32: 0.649\n",
      "-3: 2-3-50: 0.784\n",
      "-3: 3-2-8: 0.649\n",
      "-3: 3-2-32: 0.919\n",
      "-3: 3-2-50: 0.676\n",
      "-3: 3-3-8: 0.730\n",
      "-3: 3-3-32: 0.541\n",
      "-3: 3-3-50: 0.784\n",
      "-4: 2-2-16: 0.865\n",
      "-4: 2-3-16: 0.568\n",
      "-4: 2-4-16: 0.757\n",
      "-4: 3-2-16: 0.892\n",
      "-4: 4-2-16: 0.676\n",
      "-4: 3-3-16: 0.649\n",
      "-4: 4-3-16: 0.595\n",
      "-4: 2-2-8: 0.838\n",
      "-4: 2-2-32: 0.892\n",
      "-4: 2-2-50: 0.865\n",
      "-4: 2-3-8: 0.676\n",
      "-4: 2-3-32: 0.568\n",
      "-4: 2-3-50: 0.757\n",
      "-4: 3-2-8: 0.730\n",
      "-4: 3-2-32: 0.865\n",
      "-4: 3-2-50: 0.865\n",
      "-4: 3-3-8: 0.784\n",
      "-4: 3-3-32: 0.703\n",
      "-4: 3-3-50: 0.568\n",
      "-5: 2-2-16: 0.865\n",
      "-5: 2-3-16: 0.838\n",
      "-5: 2-4-16: 0.838\n",
      "-5: 3-2-16: 0.595\n",
      "-5: 4-2-16: 0.649\n",
      "-5: 3-3-16: 0.865\n",
      "-5: 4-3-16: 0.676\n",
      "-5: 2-2-8: 0.865\n",
      "-5: 2-2-32: 0.865\n",
      "-5: 2-2-50: 0.892\n",
      "-5: 2-3-8: 0.838\n",
      "-5: 2-3-32: 0.568\n",
      "-5: 2-3-50: 0.838\n",
      "-5: 3-2-8: 0.865\n",
      "-5: 3-2-32: 0.838\n",
      "-5: 3-2-50: 0.838\n",
      "-5: 3-3-8: 0.595\n",
      "-5: 3-3-32: 0.703\n",
      "-5: 3-3-50: 0.811\n",
      "-6: 2-2-16: 0.811\n",
      "-6: 2-3-16: 0.784\n",
      "-6: 2-4-16: 0.730\n",
      "-6: 3-2-16: 0.784\n",
      "-6: 4-2-16: 0.649\n",
      "-6: 3-3-16: 0.622\n",
      "-6: 4-3-16: 0.541\n",
      "-6: 2-2-8: 0.838\n",
      "-6: 2-2-32: 0.865\n",
      "-6: 2-2-50: 0.838\n",
      "-6: 2-3-8: 0.838\n",
      "-6: 2-3-32: 0.784\n",
      "-6: 2-3-50: 0.784\n",
      "-6: 3-2-8: 0.730\n",
      "-6: 3-2-32: 0.865\n",
      "-6: 3-2-50: 0.622\n",
      "-6: 3-3-8: 0.568\n",
      "-6: 3-3-32: 0.514\n",
      "-6: 3-3-50: 0.541\n",
      "-7: 2-2-16: 0.838\n",
      "-7: 2-3-16: 0.784\n",
      "-7: 2-4-16: 0.541\n",
      "-7: 3-2-16: 0.865\n",
      "-7: 4-2-16: 0.622\n",
      "-7: 3-3-16: 0.595\n",
      "-7: 4-3-16: 0.568\n",
      "-7: 2-2-8: 0.865\n",
      "-7: 2-2-32: 0.865\n",
      "-7: 2-2-50: 0.865\n",
      "-7: 2-3-8: 0.676\n",
      "-7: 2-3-32: 0.865\n",
      "-7: 2-3-50: 0.838\n",
      "-7: 3-2-8: 0.865\n",
      "-7: 3-2-32: 0.892\n",
      "-7: 3-2-50: 0.865\n",
      "-7: 3-3-8: 0.568\n",
      "-7: 3-3-32: 0.622\n",
      "-7: 3-3-50: 0.595\n",
      "-8: 2-2-16: 0.811\n",
      "-8: 2-3-16: 0.838\n",
      "-8: 2-4-16: 0.595\n",
      "-8: 3-2-16: 0.730\n",
      "-8: 4-2-16: 0.649\n",
      "-8: 3-3-16: 0.703\n",
      "-8: 4-3-16: 0.541\n",
      "-8: 2-2-8: 0.892\n",
      "-8: 2-2-32: 0.838\n",
      "-8: 2-2-50: 0.784\n",
      "-8: 2-3-8: 0.703\n",
      "-8: 2-3-32: 0.784\n",
      "-8: 2-3-50: 0.865\n",
      "-8: 3-2-8: 0.703\n",
      "-8: 3-2-32: 0.838\n",
      "-8: 3-2-50: 0.838\n",
      "-8: 3-3-8: 0.649\n",
      "-8: 3-3-32: 0.568\n",
      "-8: 3-3-50: 0.784\n",
      "-9: 2-2-16: 0.838\n",
      "-9: 2-3-16: 0.838\n",
      "-9: 2-4-16: 0.595\n",
      "-9: 3-2-16: 0.811\n",
      "-9: 4-2-16: 0.811\n",
      "-9: 3-3-16: 0.568\n",
      "-9: 4-3-16: 0.568\n",
      "-9: 2-2-8: 0.838\n",
      "-9: 2-2-32: 0.892\n",
      "-9: 2-2-50: 0.838\n",
      "-9: 2-3-8: 0.757\n",
      "-9: 2-3-32: 0.811\n",
      "-9: 2-3-50: 0.811\n",
      "-9: 3-2-8: 0.622\n",
      "-9: 3-2-32: 0.838\n",
      "-9: 3-2-50: 0.838\n",
      "-9: 3-3-8: 0.568\n",
      "-9: 3-3-32: 0.730\n",
      "-9: 3-3-50: 0.568\n",
      "-10: 2-2-16: 0.865\n",
      "-10: 2-3-16: 0.541\n",
      "-10: 2-4-16: 0.784\n",
      "-10: 3-2-16: 0.865\n",
      "-10: 4-2-16: 0.676\n",
      "-10: 3-3-16: 0.595\n",
      "-10: 4-3-16: 0.568\n",
      "-10: 2-2-8: 0.865\n",
      "-10: 2-2-32: 0.838\n",
      "-10: 2-2-50: 0.676\n",
      "-10: 2-3-8: 0.865\n",
      "-10: 2-3-32: 0.838\n",
      "-10: 2-3-50: 0.811\n",
      "-10: 3-2-8: 0.865\n",
      "-10: 3-2-32: 0.865\n",
      "-10: 3-2-50: 0.865\n",
      "-10: 3-3-8: 0.595\n",
      "-10: 3-3-32: 0.595\n",
      "-10: 3-3-50: 0.568\n",
      "----- 33.11 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'L': 2, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 4, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 3, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 50},\n",
    "        ]\n",
    "\n",
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN_Spows(IN_DIM, exp['hid_dim'], OUT_DIM, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=NORM, dev=device)\n",
    "        S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  exp['K'], masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}: {best_accs[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs.mean(axis=1)\n",
    "std_accs = best_accs.std(axis=1)\n",
    "index_name = [f'{exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}' for exp in EXPS]\n",
    "table3 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-2-16</th>\n",
       "      <td>0.858378</td>\n",
       "      <td>0.019157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-16</th>\n",
       "      <td>0.859459</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-4-16</th>\n",
       "      <td>0.848649</td>\n",
       "      <td>0.026481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-16</th>\n",
       "      <td>0.851892</td>\n",
       "      <td>0.018911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2-16</th>\n",
       "      <td>0.787027</td>\n",
       "      <td>0.093099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-16</th>\n",
       "      <td>0.838919</td>\n",
       "      <td>0.066852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-3-16</th>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.092998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-8</th>\n",
       "      <td>0.835676</td>\n",
       "      <td>0.021513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-32</th>\n",
       "      <td>0.862703</td>\n",
       "      <td>0.015135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-50</th>\n",
       "      <td>0.869189</td>\n",
       "      <td>0.018219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-8</th>\n",
       "      <td>0.841081</td>\n",
       "      <td>0.065009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-32</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.017093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-50</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.020907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-8</th>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.035855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-32</th>\n",
       "      <td>0.817297</td>\n",
       "      <td>0.079178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-50</th>\n",
       "      <td>0.819459</td>\n",
       "      <td>0.089384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-8</th>\n",
       "      <td>0.812973</td>\n",
       "      <td>0.067044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-32</th>\n",
       "      <td>0.829189</td>\n",
       "      <td>0.075180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-50</th>\n",
       "      <td>0.734054</td>\n",
       "      <td>0.138800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean accs       std\n",
       "2-2-16   0.858378  0.019157\n",
       "2-3-16   0.859459  0.021622\n",
       "2-4-16   0.848649  0.026481\n",
       "3-2-16   0.851892  0.018911\n",
       "4-2-16   0.787027  0.093099\n",
       "3-3-16   0.838919  0.066852\n",
       "4-3-16   0.805405  0.092998\n",
       "2-2-8    0.835676  0.021513\n",
       "2-2-32   0.862703  0.015135\n",
       "2-2-50   0.869189  0.018219\n",
       "2-3-8    0.841081  0.065009\n",
       "2-3-32   0.864865  0.017093\n",
       "2-3-50   0.863784  0.020907\n",
       "3-2-8    0.837838  0.035855\n",
       "3-2-32   0.817297  0.079178\n",
       "3-2-50   0.819459  0.089384\n",
       "3-3-8    0.812973  0.067044\n",
       "3-3-32   0.829189  0.075180\n",
       "3-3-50   0.734054  0.138800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearities and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-1: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-1: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.730\n",
      "-1: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730\n",
      "-1: ReLU()-Identity()-CrossEntropyLoss(): 0.811\n",
      "-1: ReLU()-Identity()-NLLLoss(): 0.541\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.649\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.703\n",
      "-1: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.541\n",
      "-1: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-1: Identity()-Identity()-CrossEntropyLoss(): 0.838\n",
      "-2: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-2: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-2: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.730\n",
      "-2: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.703\n",
      "-2: ReLU()-Identity()-CrossEntropyLoss(): 0.811\n",
      "-2: ReLU()-Identity()-NLLLoss(): 0.514\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-2: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-2: Identity()-Softmax(dim=1)-NLLLoss(): 0.703\n",
      "-2: Identity()-Identity()-CrossEntropyLoss(): 0.730\n",
      "-3: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-3: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-3: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-3: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.811\n",
      "-3: ReLU()-Identity()-CrossEntropyLoss(): 0.757\n",
      "-3: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.757\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.703\n",
      "-3: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-3: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-3: Identity()-Identity()-CrossEntropyLoss(): 0.730\n",
      "-4: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-4: ReLU()-Softmax(dim=1)-NLLLoss(): 0.649\n",
      "-4: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-4: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.757\n",
      "-4: ReLU()-Identity()-CrossEntropyLoss(): 0.730\n",
      "-4: ReLU()-Identity()-NLLLoss(): 0.378\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.595\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.703\n",
      "-4: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.676\n",
      "-4: Identity()-Softmax(dim=1)-NLLLoss(): 0.568\n",
      "-4: Identity()-Identity()-CrossEntropyLoss(): 0.784\n",
      "-5: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-5: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-5: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.730\n",
      "-5: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.757\n",
      "-5: ReLU()-Identity()-CrossEntropyLoss(): 0.784\n",
      "-5: ReLU()-Identity()-NLLLoss(): 0.514\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.676\n",
      "-5: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.622\n",
      "-5: Identity()-Softmax(dim=1)-NLLLoss(): 0.730\n",
      "-5: Identity()-Identity()-CrossEntropyLoss(): 0.784\n",
      "-6: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-6: ReLU()-Softmax(dim=1)-NLLLoss(): 0.649\n",
      "-6: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-6: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.865\n",
      "-6: ReLU()-Identity()-CrossEntropyLoss(): 0.838\n",
      "-6: ReLU()-Identity()-NLLLoss(): 0.351\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.622\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-6: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-6: Identity()-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-6: Identity()-Identity()-CrossEntropyLoss(): 0.757\n",
      "-7: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-7: ReLU()-Softmax(dim=1)-NLLLoss(): 0.676\n",
      "-7: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-7: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.784\n",
      "-7: ReLU()-Identity()-CrossEntropyLoss(): 0.838\n",
      "-7: ReLU()-Identity()-NLLLoss(): 0.514\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.757\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-7: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-7: Identity()-Softmax(dim=1)-NLLLoss(): 0.703\n",
      "-7: Identity()-Identity()-CrossEntropyLoss(): 0.811\n",
      "-8: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-8: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-8: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-8: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730\n",
      "-8: ReLU()-Identity()-CrossEntropyLoss(): 0.784\n",
      "-8: ReLU()-Identity()-NLLLoss(): 0.514\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.703\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.757\n",
      "-8: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.676\n",
      "-8: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-8: Identity()-Identity()-CrossEntropyLoss(): 0.757\n",
      "-9: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.676\n",
      "-9: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-9: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-9: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.838\n",
      "-9: ReLU()-Identity()-CrossEntropyLoss(): 0.757\n",
      "-9: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.486\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-9: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-9: Identity()-Softmax(dim=1)-NLLLoss(): 0.703\n",
      "-9: Identity()-Identity()-CrossEntropyLoss(): 0.784\n",
      "-10: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-10: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-10: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-10: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.757\n",
      "-10: ReLU()-Identity()-CrossEntropyLoss(): 0.649\n",
      "-10: ReLU()-Identity()-NLLLoss(): 0.459\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.622\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-10: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-10: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-10: Identity()-Identity()-CrossEntropyLoss(): 0.784\n",
      "----- 35.84 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},]\n",
    "\n",
    "best_accs4 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=exp['act'], last_act=exp['lact'],\n",
    "                           dropout=DROPOUT, norm=NORM, dev=device)\n",
    "        S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  K, masks, exp['loss'], device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs4[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}: {best_accs4[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs4.mean(axis=1)\n",
    "std_accs = best_accs4.std(axis=1)\n",
    "index_name = [f'{exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}' for exp in EXPS]\n",
    "table4 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.802703</td>\n",
       "      <td>0.049909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.794595</td>\n",
       "      <td>0.092209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.040088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.048649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.775676</td>\n",
       "      <td>0.054122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-NLLLoss()</th>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.065090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.821622</td>\n",
       "      <td>0.055652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.748649</td>\n",
       "      <td>0.126219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.098935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.781081</td>\n",
       "      <td>0.077817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.721622</td>\n",
       "      <td>0.114059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.086317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.775676</td>\n",
       "      <td>0.032093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean accs       std\n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()             0.802703  0.049909\n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                      0.794595  0.092209\n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()          0.783784  0.040088\n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                   0.772973  0.048649\n",
       "ReLU()-Identity()-CrossEntropyLoss()                 0.775676  0.054122\n",
       "ReLU()-Identity()-NLLLoss()                          0.459459  0.065090\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()     0.821622  0.055652\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()              0.748649  0.126219\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...   0.756757  0.098935\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...   0.781081  0.077817\n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()         0.721622  0.114059\n",
       "Identity()-Softmax(dim=1)-NLLLoss()                  0.756757  0.086317\n",
       "Identity()-Identity()-CrossEntropyLoss()             0.775676  0.032093"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPS = [\n",
    "        {'name': 'Kipf', 'norm': 'none'},\n",
    "        {'name': 'Kipf', 'norm': 'both'},\n",
    "\n",
    "        {'name': 'A-GCNN', 'norm': False},\n",
    "        {'name': 'A-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'H-GCNN', 'norm': False},\n",
    "        {'name': 'H-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'W-GCN-A', 'norm': False},\n",
    "        {'name': 'W-GCN-A', 'norm': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RUN: 1\n",
      "\tKipf-none: acc = 0.459\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.838\n",
      "\tH-GCNN-True: acc = 0.892\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 2\n",
      "\tKipf-none: acc = 0.405\n"
     ]
    }
   ],
   "source": [
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "for i in range(N_RUNS):\n",
    "    print(f'- RUN: {i+1}')\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        # t_i = time.time()\n",
    "        if exp['name'] == 'Kipf':\n",
    "            arch = GCNN_2L(IN_DIM, HID_DIM, OUT_DIM, act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=exp['norm'])\n",
    "            S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "            \n",
    "        elif exp['name'] == 'A-GCNN':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "            dropout=DROPOUT, diff_layer=GFGCNLayer, init_h0=h0)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'H-GCNN':\n",
    "            arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=DROPOUT, norm=exp['norm'], dev=device)\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'W-GCN-A':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=DROPOUT, diff_layer=GFGCN_noh_Layer)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)  \n",
    "            \n",
    "        else:\n",
    "            raise Exception(f'ERROR: Unknown architecture: {exp[\"name\"]}')\n",
    "\n",
    "        if exp['name'] in ['Kipf', 'W-GCN-A']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "\n",
    "        loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'\\t{exp[\"name\"]}-{exp[\"norm\"]}: acc = {best_accs[j,i]:.3f}')\n",
    "\n",
    "\n",
    "# Print results\n",
    "mean_accs = best_accs.mean(axis=1)\n",
    "med_accs = np.median(best_accs, axis=1)\n",
    "std_accs = best_accs.std(axis=1)\n",
    "\n",
    "index_name = [f'{exp[\"name\"]}-{exp[\"norm\"]}' for exp in EXPS]\n",
    "data = np.vstack((mean_accs, med_accs, std_accs)).T\n",
    "table_comp2 = DataFrame(data, columns=['mean accs', 'med accs', 'std'], index=index_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kipf-none</th>\n",
       "      <td>0.436757</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.036405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kipf-both</th>\n",
       "      <td>0.628108</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.015815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-False</th>\n",
       "      <td>0.855135</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.016887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-False</th>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.020682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-True</th>\n",
       "      <td>0.796757</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.060250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-False</th>\n",
       "      <td>0.836757</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.029089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean accs  med accs       std\n",
       "Kipf-none       0.436757  0.432432  0.036405\n",
       "Kipf-both       0.628108  0.621622  0.015815\n",
       "A-GCNN-False    0.855135  0.864865  0.016887\n",
       "A-GCNN-True     0.270270  0.270270  0.000000\n",
       "H-GCNN-False    0.861622  0.864865  0.020682\n",
       "H-GCNN-True     0.796757  0.810811  0.060250\n",
       "W-GCN-A-False   0.836757  0.837838  0.029089\n",
       "W-GCN-A-True    0.270270  0.270270  0.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_comp2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

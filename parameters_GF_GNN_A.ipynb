{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1e90185e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import utils\n",
    "from gsp_utils.baselines_archs import GCNN_2L\n",
    "from gsp_utils.baselines_models import NodeClassModel, GF_NodeClassModel\n",
    "from gsp_utils.data import normalize_gso\n",
    "from src.arch import GFGCN, GFGCNLayer, GFGCN_noh_Layer, GFGCN_Spows\n",
    "\n",
    "SEED = 15\n",
    "# PATH = 'results/diff_filters/'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def summary_table(acc, index_name):\n",
    "    mean_accs = acc.mean(axis=1)\n",
    "    med_accs = np.median(acc, axis=1)\n",
    "    std_accs = acc.std(axis=1)\n",
    "    return DataFrame(np.vstack((mean_accs, med_accs, std_accs)).T, columns=['mean accs', 'med', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CornellDataset\n",
      "Number of nodes: 183\n",
      "Number of features: 1703\n",
      "Shape of signals: torch.Size([183, 1703])\n",
      "Number of classes: 5\n",
      "Norm of A: 17.262676239013672\n",
      "Max value of A: 1.0\n",
      "Proportion of validation data: 0.32\n",
      "Proportion of test data: 0.20\n",
      "Node homophily: 0.11\n",
      "Edge homophily: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Dataset must be from DGL\n",
    "dataset_name = 'CornellDataset'\n",
    "\n",
    "A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device,\n",
    "                                                     verb=True)\n",
    "N = A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without normalizing the GSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "## Reaining params\n",
    "N_RUNS = 25\n",
    "N_EPOCHS = 200  # 500\n",
    "LR = .05\n",
    "WD = .01\n",
    "DROPOUT = 0\n",
    "\n",
    "# BEST PARAMETERS\n",
    "## Architecture params\n",
    "N_LAYERS = 2\n",
    "K = 3\n",
    "HID_DIM = 50\n",
    "\n",
    "## Model params\n",
    "h0 = .1  # 1\n",
    "NORM = False\n",
    "\n",
    "IN_DIM = feat.shape[1]\n",
    "OUT_DIM = n_class\n",
    "\n",
    "\n",
    "ACT = nn.ReLU()\n",
    "LAST_ACT = nn.Softmax(dim=1)\n",
    "LOSS_FN = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting eval/test acc/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val acc: 0.881\n",
      "Test acc at best val: 0.811\n",
      "Best test acc: 0.865\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "epochs = N_EPOCHS\n",
    "epochs_h = 1\n",
    "epochs_W = 1\n",
    "lr = LR\n",
    "wd = WD\n",
    "drop = 0\n",
    "L = N_LAYERS\n",
    "K_aux = K\n",
    "hid_dim = HID_DIM\n",
    "h0_aux = 1  # 1\n",
    "norm = False\n",
    "act = ACT\n",
    "lact = LAST_ACT\n",
    "loss = LOSS_FN\n",
    "\n",
    "# Create model\n",
    "arch = GFGCN(IN_DIM, hid_dim, OUT_DIM, L, K_aux, act=act, last_act=lact,\n",
    "             dropout=drop, init_h0=h0_aux)\n",
    "S = torch.Tensor(A).to(device)\n",
    "model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "loss, acc = model.train(feat, labels, epochs, lr, wd, epochs_h=epochs_h, epochs_W=epochs_W)\n",
    "\n",
    "idx_max_acc = np.argmax(acc[\"val\"])\n",
    "print(f'Best val acc: {acc[\"val\"][idx_max_acc]:.3f}')\n",
    "print(f'Test acc at best val: {acc[\"test\"][idx_max_acc]:.3f}')\n",
    "print(f'Best test acc: {np.max(acc[\"test\"]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1e70060df0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(acc['train'], 'b-', label='Acc train')\n",
    "plt.plot(acc['val'], 'g-', label='Acc val')\n",
    "plt.plot(acc['test'], 'r-', label='Acc test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.plot(loss['train'], 'b-', label='Loss train')\n",
    "plt.plot(loss['val'], 'g-', label='Loss val')\n",
    "plt.plot(loss['test'], 'r-', label='Loss test')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 200-0.1-0.0005-0: 0.514 (0.514)\n",
      "-1: 200-0.05-0.0005-0: 0.541 (0.541)\n",
      "-1: 200-0.01-0.0005-0: 0.378 (0.459)\n",
      "-1: 200-0.005-0.0005-0: 0.351 (0.459)\n",
      "-1: 200-0.001-0.0005-0: 0.378 (0.459)\n",
      "-1: 200-0.05-0.001-0: 0.703 (0.730)\n",
      "-1: 200-0.01-0.001-0: 0.405 (0.514)\n",
      "-1: 200-0.05-0.01-0: 0.757 (0.892)\n",
      "-1: 200-0.01-0.01-0: 0.568 (0.649)\n",
      "-1: 200-0.05-0.05-0: 0.514 (0.514)\n",
      "-1: 200-0.01-0.05-0: 0.703 (0.757)\n",
      "-1: 500-0.05-0.0005-0: 0.676 (0.730)\n",
      "-1: 500-0.01-0.0005-0: 0.405 (0.459)\n",
      "-1: 500-0.05-0.01-0: 0.784 (0.865)\n",
      "-1: 500-0.01-0.01-0: 0.784 (0.784)\n",
      "-1: 200-0.05-0.0005-0.25: 0.378 (0.514)\n",
      "-1: 200-0.05-0.0005-0.5: 0.514 (0.568)\n",
      "-1: 500-0.05-0.01-0.25: 0.784 (0.892)\n",
      "-1: 500-0.05-0.01-0.5: 0.811 (0.838)\n",
      "-2: 200-0.1-0.0005-0: 0.649 (0.649)\n",
      "-2: 200-0.05-0.0005-0: 0.486 (0.568)\n",
      "-2: 200-0.01-0.0005-0: 0.459 (0.459)\n",
      "-2: 200-0.005-0.0005-0: 0.378 (0.459)\n",
      "-2: 200-0.001-0.0005-0: 0.378 (0.432)\n",
      "-2: 200-0.05-0.001-0: 0.378 (0.459)\n",
      "-2: 200-0.01-0.001-0: 0.189 (0.297)\n",
      "-2: 200-0.05-0.01-0: 0.757 (0.892)\n",
      "-2: 200-0.01-0.01-0: 0.622 (0.676)\n",
      "-2: 200-0.05-0.05-0: 0.838 (0.865)\n",
      "-2: 200-0.01-0.05-0: 0.649 (0.649)\n",
      "-2: 500-0.05-0.0005-0: 0.459 (0.622)\n",
      "-2: 500-0.01-0.0005-0: 0.405 (0.459)\n",
      "-2: 500-0.05-0.01-0: 0.703 (0.892)\n",
      "-2: 500-0.01-0.01-0: 0.730 (0.811)\n",
      "-2: 200-0.05-0.0005-0.25: 0.541 (0.595)\n",
      "-2: 200-0.05-0.0005-0.5: 0.405 (0.486)\n",
      "-2: 500-0.05-0.01-0.25: 0.811 (0.865)\n",
      "-2: 500-0.05-0.01-0.5: 0.649 (0.838)\n",
      "-3: 200-0.1-0.0005-0: 0.568 (0.568)\n",
      "-3: 200-0.05-0.0005-0: 0.486 (0.595)\n",
      "-3: 200-0.01-0.0005-0: 0.486 (0.514)\n",
      "-3: 200-0.005-0.0005-0: 0.351 (0.432)\n",
      "-3: 200-0.001-0.0005-0: 0.162 (0.270)\n",
      "-3: 200-0.05-0.001-0: 0.568 (0.703)\n",
      "-3: 200-0.01-0.001-0: 0.459 (0.486)\n",
      "-3: 200-0.05-0.01-0: 0.784 (0.865)\n",
      "-3: 200-0.01-0.01-0: 0.514 (0.568)\n",
      "-3: 200-0.05-0.05-0: 0.730 (0.865)\n",
      "-3: 200-0.01-0.05-0: 0.459 (0.514)\n",
      "-3: 500-0.05-0.0005-0: 0.459 (0.486)\n",
      "-3: 500-0.01-0.0005-0: 0.649 (0.703)\n",
      "-3: 500-0.05-0.01-0: 0.757 (0.865)\n",
      "-3: 500-0.01-0.01-0: 0.703 (0.811)\n",
      "-3: 200-0.05-0.0005-0.25: 0.541 (0.541)\n",
      "-3: 200-0.05-0.0005-0.5: 0.351 (0.486)\n",
      "-3: 500-0.05-0.01-0.25: 0.757 (0.865)\n",
      "-3: 500-0.05-0.01-0.5: 0.676 (0.838)\n",
      "-4: 200-0.1-0.0005-0: 0.514 (0.541)\n",
      "-4: 200-0.05-0.0005-0: 0.595 (0.703)\n",
      "-4: 200-0.01-0.0005-0: 0.405 (0.459)\n",
      "-4: 200-0.005-0.0005-0: 0.351 (0.405)\n",
      "-4: 200-0.001-0.0005-0: 0.324 (0.351)\n",
      "-4: 200-0.05-0.001-0: 0.649 (0.703)\n",
      "-4: 200-0.01-0.001-0: 0.324 (0.432)\n",
      "-4: 200-0.05-0.01-0: 0.649 (0.919)\n",
      "-4: 200-0.01-0.01-0: 0.676 (0.730)\n",
      "-4: 200-0.05-0.05-0: 0.838 (0.838)\n",
      "-4: 200-0.01-0.05-0: 0.676 (0.703)\n",
      "-4: 500-0.05-0.0005-0: 0.649 (0.757)\n",
      "-4: 500-0.01-0.0005-0: 0.405 (0.459)\n",
      "-4: 500-0.05-0.01-0: 0.730 (0.865)\n",
      "-4: 500-0.01-0.01-0: 0.730 (0.730)\n",
      "-4: 200-0.05-0.0005-0.25: 0.405 (0.486)\n",
      "-4: 200-0.05-0.0005-0.5: 0.541 (0.541)\n",
      "-4: 500-0.05-0.01-0.25: 0.784 (0.865)\n",
      "-4: 500-0.05-0.01-0.5: 0.757 (0.892)\n",
      "-5: 200-0.1-0.0005-0: 0.514 (0.595)\n",
      "-5: 200-0.05-0.0005-0: 0.405 (0.486)\n",
      "-5: 200-0.01-0.0005-0: 0.378 (0.459)\n",
      "-5: 200-0.005-0.0005-0: 0.378 (0.486)\n",
      "-5: 200-0.001-0.0005-0: 0.162 (0.243)\n",
      "-5: 200-0.05-0.001-0: 0.703 (0.757)\n",
      "-5: 200-0.01-0.001-0: 0.676 (0.730)\n",
      "-5: 200-0.05-0.01-0: 0.784 (0.838)\n",
      "-5: 200-0.01-0.01-0: 0.703 (0.730)\n",
      "-5: 200-0.05-0.05-0: 0.784 (0.892)\n",
      "-5: 200-0.01-0.05-0: 0.649 (0.676)\n",
      "-5: 500-0.05-0.0005-0: 0.568 (0.622)\n",
      "-5: 500-0.01-0.0005-0: 0.378 (0.459)\n",
      "-5: 500-0.05-0.01-0: 0.838 (0.865)\n",
      "-5: 500-0.01-0.01-0: 0.757 (0.784)\n",
      "-5: 200-0.05-0.0005-0.25: 0.676 (0.703)\n",
      "-5: 200-0.05-0.0005-0.5: 0.514 (0.541)\n",
      "-5: 500-0.05-0.01-0.25: 0.784 (0.892)\n",
      "-5: 500-0.05-0.01-0.5: 0.811 (0.838)\n",
      "-6: 200-0.1-0.0005-0: 0.514 (0.622)\n",
      "-6: 200-0.05-0.0005-0: 0.541 (0.595)\n",
      "-6: 200-0.01-0.0005-0: 0.351 (0.432)\n",
      "-6: 200-0.005-0.0005-0: 0.432 (0.459)\n",
      "-6: 200-0.001-0.0005-0: 0.378 (0.486)\n",
      "-6: 200-0.05-0.001-0: 0.432 (0.649)\n",
      "-6: 200-0.01-0.001-0: 0.514 (0.595)\n",
      "-6: 200-0.05-0.01-0: 0.784 (0.892)\n",
      "-6: 200-0.01-0.01-0: 0.676 (0.703)\n",
      "-6: 200-0.05-0.05-0: 0.378 (0.514)\n",
      "-6: 200-0.01-0.05-0: 0.703 (0.730)\n",
      "-6: 500-0.05-0.0005-0: 0.622 (0.730)\n",
      "-6: 500-0.01-0.0005-0: 0.351 (0.459)\n",
      "-6: 500-0.05-0.01-0: 0.784 (0.892)\n",
      "-6: 500-0.01-0.01-0: 0.703 (0.838)\n",
      "-6: 200-0.05-0.0005-0.25: 0.514 (0.595)\n",
      "-6: 200-0.05-0.0005-0.5: 0.541 (0.622)\n",
      "-6: 500-0.05-0.01-0.25: 0.757 (0.865)\n",
      "-6: 500-0.05-0.01-0.5: 0.784 (0.919)\n",
      "-7: 200-0.1-0.0005-0: 0.514 (0.568)\n",
      "-7: 200-0.05-0.0005-0: 0.622 (0.784)\n",
      "-7: 200-0.01-0.0005-0: 0.405 (0.432)\n",
      "-7: 200-0.005-0.0005-0: 0.405 (0.432)\n",
      "-7: 200-0.001-0.0005-0: 0.405 (0.432)\n",
      "-7: 200-0.05-0.001-0: 0.649 (0.703)\n",
      "-7: 200-0.01-0.001-0: 0.405 (0.459)\n",
      "-7: 200-0.05-0.01-0: 0.865 (0.892)\n",
      "-7: 200-0.01-0.01-0: 0.730 (0.757)\n",
      "-7: 200-0.05-0.05-0: 0.405 (0.514)\n",
      "-7: 200-0.01-0.05-0: 0.703 (0.703)\n",
      "-7: 500-0.05-0.0005-0: 0.649 (0.676)\n",
      "-7: 500-0.01-0.0005-0: 0.378 (0.432)\n",
      "-7: 500-0.05-0.01-0: 0.757 (0.892)\n",
      "-7: 500-0.01-0.01-0: 0.703 (0.784)\n",
      "-7: 200-0.05-0.0005-0.25: 0.459 (0.486)\n",
      "-7: 200-0.05-0.0005-0.5: 0.595 (0.595)\n",
      "-7: 500-0.05-0.01-0.25: 0.811 (0.892)\n",
      "-7: 500-0.05-0.01-0.5: 0.784 (0.865)\n",
      "-8: 200-0.1-0.0005-0: 0.541 (0.568)\n",
      "-8: 200-0.05-0.0005-0: 0.514 (0.568)\n",
      "-8: 200-0.01-0.0005-0: 0.378 (0.459)\n",
      "-8: 200-0.005-0.0005-0: 0.405 (0.405)\n",
      "-8: 200-0.001-0.0005-0: 0.297 (0.324)\n",
      "-8: 200-0.05-0.001-0: 0.649 (0.757)\n",
      "-8: 200-0.01-0.001-0: 0.378 (0.432)\n",
      "-8: 200-0.05-0.01-0: 0.811 (0.865)\n",
      "-8: 200-0.01-0.01-0: 0.730 (0.730)\n",
      "-8: 200-0.05-0.05-0: 0.514 (0.514)\n",
      "-8: 200-0.01-0.05-0: 0.486 (0.541)\n",
      "-8: 500-0.05-0.0005-0: 0.730 (0.784)\n",
      "-8: 500-0.01-0.0005-0: 0.351 (0.459)\n",
      "-8: 500-0.05-0.01-0: 0.838 (0.892)\n",
      "-8: 500-0.01-0.01-0: 0.703 (0.838)\n",
      "-8: 200-0.05-0.0005-0.25: 0.514 (0.595)\n",
      "-8: 200-0.05-0.0005-0.5: 0.486 (0.514)\n",
      "-8: 500-0.05-0.01-0.25: 0.784 (0.892)\n",
      "-8: 500-0.05-0.01-0.5: 0.784 (0.892)\n",
      "-9: 200-0.1-0.0005-0: 0.514 (0.541)\n",
      "-9: 200-0.05-0.0005-0: 0.459 (0.459)\n",
      "-9: 200-0.01-0.0005-0: 0.351 (0.459)\n",
      "-9: 200-0.005-0.0005-0: 0.378 (0.432)\n",
      "-9: 200-0.001-0.0005-0: 0.243 (0.351)\n",
      "-9: 200-0.05-0.001-0: 0.622 (0.649)\n",
      "-9: 200-0.01-0.001-0: 0.676 (0.703)\n",
      "-9: 200-0.05-0.01-0: 0.784 (0.892)\n",
      "-9: 200-0.01-0.01-0: 0.649 (0.730)\n",
      "-9: 200-0.05-0.05-0: 0.514 (0.514)\n",
      "-9: 200-0.01-0.05-0: 0.541 (0.541)\n",
      "-9: 500-0.05-0.0005-0: 0.541 (0.568)\n",
      "-9: 500-0.01-0.0005-0: 0.622 (0.676)\n",
      "-9: 500-0.05-0.01-0: 0.757 (0.865)\n",
      "-9: 500-0.01-0.01-0: 0.676 (0.811)\n",
      "-9: 200-0.05-0.0005-0.25: 0.486 (0.541)\n",
      "-9: 200-0.05-0.0005-0.5: 0.514 (0.568)\n",
      "-9: 500-0.05-0.01-0.25: 0.703 (0.865)\n",
      "-9: 500-0.05-0.01-0.5: 0.757 (0.892)\n",
      "-10: 200-0.1-0.0005-0: 0.541 (0.541)\n",
      "-10: 200-0.05-0.0005-0: 0.486 (0.514)\n",
      "-10: 200-0.01-0.0005-0: 0.243 (0.270)\n",
      "-10: 200-0.005-0.0005-0: 0.432 (0.459)\n",
      "-10: 200-0.001-0.0005-0: 0.405 (0.459)\n",
      "-10: 200-0.05-0.001-0: 0.622 (0.730)\n",
      "-10: 200-0.01-0.001-0: 0.541 (0.595)\n",
      "-10: 200-0.05-0.01-0: 0.784 (0.865)\n",
      "-10: 200-0.01-0.01-0: 0.730 (0.757)\n",
      "-10: 200-0.05-0.05-0: 0.865 (0.865)\n",
      "-10: 200-0.01-0.05-0: 0.676 (0.730)\n",
      "-10: 500-0.05-0.0005-0: 0.622 (0.622)\n",
      "-10: 500-0.01-0.0005-0: 0.757 (0.784)\n",
      "-10: 500-0.05-0.01-0: 0.703 (0.892)\n",
      "-10: 500-0.01-0.01-0: 0.703 (0.730)\n",
      "-10: 200-0.05-0.0005-0.25: 0.514 (0.541)\n",
      "-10: 200-0.05-0.0005-0.5: 0.784 (0.784)\n",
      "-10: 500-0.05-0.01-0.25: 0.811 (0.919)\n",
      "-10: 500-0.05-0.01-0.5: 0.811 (0.865)\n",
      "-11: 200-0.1-0.0005-0: 0.514 (0.541)\n",
      "-11: 200-0.05-0.0005-0: 0.514 (0.514)\n",
      "-11: 200-0.01-0.0005-0: 0.243 (0.297)\n",
      "-11: 200-0.005-0.0005-0: 0.378 (0.432)\n",
      "-11: 200-0.001-0.0005-0: 0.378 (0.486)\n",
      "-11: 200-0.05-0.001-0: 0.676 (0.703)\n",
      "-11: 200-0.01-0.001-0: 0.486 (0.486)\n",
      "-11: 200-0.05-0.01-0: 0.784 (0.892)\n",
      "-11: 200-0.01-0.01-0: 0.676 (0.676)\n",
      "-11: 200-0.05-0.05-0: 0.378 (0.514)\n",
      "-11: 200-0.01-0.05-0: 0.703 (0.730)\n",
      "-11: 500-0.05-0.0005-0: 0.459 (0.486)\n",
      "-11: 500-0.01-0.0005-0: 0.676 (0.703)\n",
      "-11: 500-0.05-0.01-0: 0.811 (0.892)\n",
      "-11: 500-0.01-0.01-0: 0.703 (0.838)\n",
      "-11: 200-0.05-0.0005-0.25: 0.514 (0.514)\n",
      "-11: 200-0.05-0.0005-0.5: 0.459 (0.514)\n",
      "-11: 500-0.05-0.01-0.25: 0.784 (0.892)\n",
      "-11: 500-0.05-0.01-0.5: 0.730 (0.838)\n",
      "-12: 200-0.1-0.0005-0: 0.622 (0.622)\n",
      "-12: 200-0.05-0.0005-0: 0.514 (0.541)\n",
      "-12: 200-0.01-0.0005-0: 0.270 (0.297)\n",
      "-12: 200-0.005-0.0005-0: 0.297 (0.297)\n",
      "-12: 200-0.001-0.0005-0: 0.432 (0.459)\n",
      "-12: 200-0.05-0.001-0: 0.514 (0.514)\n",
      "-12: 200-0.01-0.001-0: 0.432 (0.486)\n",
      "-12: 200-0.05-0.01-0: 0.784 (0.892)\n",
      "-12: 200-0.01-0.01-0: 0.676 (0.730)\n",
      "-12: 200-0.05-0.05-0: 0.757 (0.838)\n",
      "-12: 200-0.01-0.05-0: 0.703 (0.703)\n",
      "-12: 500-0.05-0.0005-0: 0.568 (0.649)\n",
      "-12: 500-0.01-0.0005-0: 0.378 (0.432)\n",
      "-12: 500-0.05-0.01-0: 0.730 (0.892)\n",
      "-12: 500-0.01-0.01-0: 0.811 (0.838)\n",
      "-12: 200-0.05-0.0005-0.25: 0.541 (0.541)\n",
      "-12: 200-0.05-0.0005-0.5: 0.514 (0.595)\n",
      "-12: 500-0.05-0.01-0.25: 0.811 (0.892)\n",
      "-12: 500-0.05-0.01-0.5: 0.703 (0.838)\n",
      "-13: 200-0.1-0.0005-0: 0.459 (0.514)\n",
      "-13: 200-0.05-0.0005-0: 0.649 (0.649)\n",
      "-13: 200-0.01-0.0005-0: 0.432 (0.459)\n",
      "-13: 200-0.005-0.0005-0: 0.378 (0.378)\n",
      "-13: 200-0.001-0.0005-0: 0.405 (0.432)\n",
      "-13: 200-0.05-0.001-0: 0.459 (0.622)\n",
      "-13: 200-0.01-0.001-0: 0.378 (0.486)\n",
      "-13: 200-0.05-0.01-0: 0.811 (0.892)\n",
      "-13: 200-0.01-0.01-0: 0.486 (0.514)\n",
      "-13: 200-0.05-0.05-0: 0.514 (0.514)\n",
      "-13: 200-0.01-0.05-0: 0.486 (0.541)\n",
      "-13: 500-0.05-0.0005-0: 0.541 (0.541)\n",
      "-13: 500-0.01-0.0005-0: 0.378 (0.432)\n",
      "-13: 500-0.05-0.01-0: 0.757 (0.919)\n",
      "-13: 500-0.01-0.01-0: 0.703 (0.811)\n",
      "-13: 200-0.05-0.0005-0.25: 0.405 (0.649)\n",
      "-13: 200-0.05-0.0005-0.5: 0.486 (0.514)\n",
      "-13: 500-0.05-0.01-0.25: 0.757 (0.892)\n",
      "-13: 500-0.05-0.01-0.5: 0.757 (0.865)\n",
      "-14: 200-0.1-0.0005-0: 0.595 (0.595)\n",
      "-14: 200-0.05-0.0005-0: 0.378 (0.378)\n",
      "-14: 200-0.01-0.0005-0: 0.378 (0.459)\n",
      "-14: 200-0.005-0.0005-0: 0.216 (0.270)\n",
      "-14: 200-0.001-0.0005-0: 0.297 (0.378)\n",
      "-14: 200-0.05-0.001-0: 0.595 (0.595)\n",
      "-14: 200-0.01-0.001-0: 0.405 (0.459)\n",
      "-14: 200-0.05-0.01-0: 0.811 (0.865)\n",
      "-14: 200-0.01-0.01-0: 0.703 (0.730)\n",
      "-14: 200-0.05-0.05-0: 0.730 (0.838)\n",
      "-14: 200-0.01-0.05-0: 0.622 (0.676)\n",
      "-14: 500-0.05-0.0005-0: 0.622 (0.811)\n",
      "-14: 500-0.01-0.0005-0: 0.730 (0.757)\n",
      "-14: 500-0.05-0.01-0: 0.784 (0.865)\n",
      "-14: 500-0.01-0.01-0: 0.676 (0.757)\n",
      "-14: 200-0.05-0.0005-0.25: 0.595 (0.622)\n",
      "-14: 200-0.05-0.0005-0.5: 0.514 (0.514)\n",
      "-14: 500-0.05-0.01-0.25: 0.757 (0.865)\n",
      "-14: 500-0.05-0.01-0.5: 0.784 (0.865)\n",
      "-15: 200-0.1-0.0005-0: 0.486 (0.541)\n",
      "-15: 200-0.05-0.0005-0: 0.514 (0.595)\n",
      "-15: 200-0.01-0.0005-0: 0.216 (0.324)\n",
      "-15: 200-0.005-0.0005-0: 0.270 (0.324)\n",
      "-15: 200-0.001-0.0005-0: 0.405 (0.459)\n",
      "-15: 200-0.05-0.001-0: 0.784 (0.838)\n",
      "-15: 200-0.01-0.001-0: 0.486 (0.486)\n",
      "-15: 200-0.05-0.01-0: 0.811 (0.892)\n",
      "-15: 200-0.01-0.01-0: 0.703 (0.730)\n",
      "-15: 200-0.05-0.05-0: 0.405 (0.514)\n",
      "-15: 200-0.01-0.05-0: 0.649 (0.649)\n",
      "-15: 500-0.05-0.0005-0: 0.622 (0.622)\n",
      "-15: 500-0.01-0.0005-0: 0.324 (0.432)\n",
      "-15: 500-0.05-0.01-0: 0.811 (0.865)\n",
      "-15: 500-0.01-0.01-0: 0.703 (0.730)\n",
      "-15: 200-0.05-0.0005-0.25: 0.486 (0.595)\n",
      "-15: 200-0.05-0.0005-0.5: 0.514 (0.541)\n",
      "-15: 500-0.05-0.01-0.25: 0.757 (0.865)\n",
      "-15: 500-0.05-0.01-0.5: 0.730 (0.865)\n",
      "-16: 200-0.1-0.0005-0: 0.676 (0.676)\n",
      "-16: 200-0.05-0.0005-0: 0.622 (0.649)\n",
      "-16: 200-0.01-0.0005-0: 0.405 (0.514)\n",
      "-16: 200-0.005-0.0005-0: 0.378 (0.378)\n",
      "-16: 200-0.001-0.0005-0: 0.378 (0.432)\n",
      "-16: 200-0.05-0.001-0: 0.595 (0.649)\n",
      "-16: 200-0.01-0.001-0: 0.378 (0.405)\n",
      "-16: 200-0.05-0.01-0: 0.784 (0.865)\n",
      "-16: 200-0.01-0.01-0: 0.676 (0.757)\n",
      "-16: 200-0.05-0.05-0: 0.811 (0.892)\n",
      "-16: 200-0.01-0.05-0: 0.595 (0.595)\n",
      "-16: 500-0.05-0.0005-0: 0.486 (0.541)\n",
      "-16: 500-0.01-0.0005-0: 0.595 (0.730)\n",
      "-16: 500-0.05-0.01-0: 0.757 (0.865)\n",
      "-16: 500-0.01-0.01-0: 0.703 (0.784)\n",
      "-16: 200-0.05-0.0005-0.25: 0.514 (0.568)\n",
      "-16: 200-0.05-0.0005-0.5: 0.459 (0.514)\n",
      "-16: 500-0.05-0.01-0.25: 0.730 (0.865)\n",
      "-16: 500-0.05-0.01-0.5: 0.784 (0.838)\n",
      "-17: 200-0.1-0.0005-0: 0.514 (0.568)\n",
      "-17: 200-0.05-0.0005-0: 0.541 (0.541)\n",
      "-17: 200-0.01-0.0005-0: 0.459 (0.514)\n",
      "-17: 200-0.005-0.0005-0: 0.459 (0.459)\n",
      "-17: 200-0.001-0.0005-0: 0.378 (0.405)\n",
      "-17: 200-0.05-0.001-0: 0.486 (0.676)\n",
      "-17: 200-0.01-0.001-0: 0.405 (0.486)\n",
      "-17: 200-0.05-0.01-0: 0.811 (0.838)\n",
      "-17: 200-0.01-0.01-0: 0.730 (0.730)\n",
      "-17: 200-0.05-0.05-0: 0.784 (0.865)\n",
      "-17: 200-0.01-0.05-0: 0.676 (0.676)\n",
      "-17: 500-0.05-0.0005-0: 0.730 (0.730)\n",
      "-17: 500-0.01-0.0005-0: 0.730 (0.784)\n",
      "-17: 500-0.05-0.01-0: 0.811 (0.892)\n",
      "-17: 500-0.01-0.01-0: 0.730 (0.730)\n",
      "-17: 200-0.05-0.0005-0.25: 0.459 (0.514)\n",
      "-17: 200-0.05-0.0005-0.5: 0.514 (0.514)\n",
      "-17: 500-0.05-0.01-0.25: 0.757 (0.865)\n",
      "-17: 500-0.05-0.01-0.5: 0.784 (0.892)\n",
      "-18: 200-0.1-0.0005-0: 0.514 (0.595)\n",
      "-18: 200-0.05-0.0005-0: 0.432 (0.514)\n",
      "-18: 200-0.01-0.0005-0: 0.432 (0.459)\n",
      "-18: 200-0.005-0.0005-0: 0.378 (0.405)\n",
      "-18: 200-0.001-0.0005-0: 0.378 (0.405)\n",
      "-18: 200-0.05-0.001-0: 0.649 (0.676)\n",
      "-18: 200-0.01-0.001-0: 0.351 (0.459)\n",
      "-18: 200-0.05-0.01-0: 0.784 (0.892)\n",
      "-18: 200-0.01-0.01-0: 0.568 (0.703)\n",
      "-18: 200-0.05-0.05-0: 0.514 (0.568)\n",
      "-18: 200-0.01-0.05-0: 0.676 (0.757)\n",
      "-18: 500-0.05-0.0005-0: 0.649 (0.730)\n",
      "-18: 500-0.01-0.0005-0: 0.730 (0.757)\n",
      "-18: 500-0.05-0.01-0: 0.838 (0.865)\n",
      "-18: 500-0.01-0.01-0: 0.730 (0.757)\n",
      "-18: 200-0.05-0.0005-0.25: 0.405 (0.432)\n",
      "-18: 200-0.05-0.0005-0.5: 0.541 (0.541)\n",
      "-18: 500-0.05-0.01-0.25: 0.730 (0.892)\n",
      "-18: 500-0.05-0.01-0.5: 0.757 (0.865)\n",
      "-19: 200-0.1-0.0005-0: 0.514 (0.514)\n",
      "-19: 200-0.05-0.0005-0: 0.541 (0.568)\n",
      "-19: 200-0.01-0.0005-0: 0.486 (0.486)\n",
      "-19: 200-0.005-0.0005-0: 0.351 (0.486)\n",
      "-19: 200-0.001-0.0005-0: 0.378 (0.432)\n",
      "-19: 200-0.05-0.001-0: 0.514 (0.676)\n",
      "-19: 200-0.01-0.001-0: 0.432 (0.486)\n",
      "-19: 200-0.05-0.01-0: 0.811 (0.919)\n",
      "-19: 200-0.01-0.01-0: 0.676 (0.757)\n",
      "-19: 200-0.05-0.05-0: 0.757 (0.865)\n",
      "-19: 200-0.01-0.05-0: 0.595 (0.622)\n",
      "-19: 500-0.05-0.0005-0: 0.622 (0.622)\n",
      "-19: 500-0.01-0.0005-0: 0.676 (0.730)\n",
      "-19: 500-0.05-0.01-0: 0.811 (0.892)\n",
      "-19: 500-0.01-0.01-0: 0.622 (0.784)\n",
      "-19: 200-0.05-0.0005-0.25: 0.541 (0.541)\n",
      "-19: 200-0.05-0.0005-0.5: 0.514 (0.514)\n",
      "-19: 500-0.05-0.01-0.25: 0.784 (0.892)\n",
      "-19: 500-0.05-0.01-0.5: 0.811 (0.865)\n",
      "-20: 200-0.1-0.0005-0: 0.514 (0.622)\n",
      "-20: 200-0.05-0.0005-0: 0.324 (0.351)\n",
      "-20: 200-0.01-0.0005-0: 0.486 (0.486)\n",
      "-20: 200-0.005-0.0005-0: 0.297 (0.405)\n",
      "-20: 200-0.001-0.0005-0: 0.405 (0.459)\n",
      "-20: 200-0.05-0.001-0: 0.703 (0.865)\n",
      "-20: 200-0.01-0.001-0: 0.351 (0.432)\n",
      "-20: 200-0.05-0.01-0: 0.730 (0.892)\n",
      "-20: 200-0.01-0.01-0: 0.703 (0.703)\n",
      "-20: 200-0.05-0.05-0: 0.703 (0.892)\n",
      "-20: 200-0.01-0.05-0: 0.703 (0.757)\n",
      "-20: 500-0.05-0.0005-0: 0.595 (0.838)\n",
      "-20: 500-0.01-0.0005-0: 0.351 (0.459)\n",
      "-20: 500-0.05-0.01-0: 0.838 (0.865)\n",
      "-20: 500-0.01-0.01-0: 0.703 (0.838)\n",
      "-20: 200-0.05-0.0005-0.25: 0.405 (0.486)\n",
      "-20: 200-0.05-0.0005-0.5: 0.757 (0.811)\n",
      "-20: 500-0.05-0.01-0.25: 0.811 (0.919)\n",
      "-20: 500-0.05-0.01-0.5: 0.784 (0.838)\n",
      "-21: 200-0.1-0.0005-0: 0.432 (0.486)\n",
      "-21: 200-0.05-0.0005-0: 0.649 (0.676)\n",
      "-21: 200-0.01-0.0005-0: 0.351 (0.378)\n",
      "-21: 200-0.005-0.0005-0: 0.378 (0.432)\n",
      "-21: 200-0.001-0.0005-0: 0.405 (0.459)\n",
      "-21: 200-0.05-0.001-0: 0.541 (0.595)\n",
      "-21: 200-0.01-0.001-0: 0.405 (0.459)\n",
      "-21: 200-0.05-0.01-0: 0.811 (0.865)\n",
      "-21: 200-0.01-0.01-0: 0.730 (0.757)\n",
      "-21: 200-0.05-0.05-0: 0.541 (0.541)\n",
      "-21: 200-0.01-0.05-0: 0.703 (0.730)\n",
      "-21: 500-0.05-0.0005-0: 0.703 (0.757)\n",
      "-21: 500-0.01-0.0005-0: 0.432 (0.459)\n",
      "-21: 500-0.05-0.01-0: 0.784 (0.865)\n",
      "-21: 500-0.01-0.01-0: 0.676 (0.757)\n",
      "-21: 200-0.05-0.0005-0.25: 0.514 (0.541)\n",
      "-21: 200-0.05-0.0005-0.5: 0.351 (0.486)\n",
      "-21: 500-0.05-0.01-0.25: 0.811 (0.865)\n",
      "-21: 500-0.05-0.01-0.5: 0.757 (0.865)\n",
      "-22: 200-0.1-0.0005-0: 0.459 (0.514)\n",
      "-22: 200-0.05-0.0005-0: 0.297 (0.324)\n",
      "-22: 200-0.01-0.0005-0: 0.514 (0.595)\n",
      "-22: 200-0.005-0.0005-0: 0.270 (0.297)\n",
      "-22: 200-0.001-0.0005-0: 0.432 (0.459)\n",
      "-22: 200-0.05-0.001-0: 0.703 (0.838)\n",
      "-22: 200-0.01-0.001-0: 0.405 (0.459)\n",
      "-22: 200-0.05-0.01-0: 0.865 (0.919)\n",
      "-22: 200-0.01-0.01-0: 0.703 (0.703)\n",
      "-22: 200-0.05-0.05-0: 0.514 (0.514)\n",
      "-22: 200-0.01-0.05-0: 0.622 (0.649)\n",
      "-22: 500-0.05-0.0005-0: 0.568 (0.568)\n",
      "-22: 500-0.01-0.0005-0: 0.378 (0.486)\n",
      "-22: 500-0.05-0.01-0: 0.811 (0.892)\n",
      "-22: 500-0.01-0.01-0: 0.703 (0.838)\n",
      "-22: 200-0.05-0.0005-0.25: 0.514 (0.541)\n",
      "-22: 200-0.05-0.0005-0.5: 0.541 (0.649)\n",
      "-22: 500-0.05-0.01-0.25: 0.757 (0.892)\n",
      "-22: 500-0.05-0.01-0.5: 0.730 (0.865)\n",
      "-23: 200-0.1-0.0005-0: 0.514 (0.568)\n",
      "-23: 200-0.05-0.0005-0: 0.514 (0.622)\n",
      "-23: 200-0.01-0.0005-0: 0.459 (0.459)\n",
      "-23: 200-0.005-0.0005-0: 0.270 (0.270)\n",
      "-23: 200-0.001-0.0005-0: 0.351 (0.432)\n",
      "-23: 200-0.05-0.001-0: 0.622 (0.730)\n",
      "-23: 200-0.01-0.001-0: 0.405 (0.486)\n",
      "-23: 200-0.05-0.01-0: 0.811 (0.865)\n",
      "-23: 200-0.01-0.01-0: 0.676 (0.703)\n",
      "-23: 200-0.05-0.05-0: 0.757 (0.892)\n",
      "-23: 200-0.01-0.05-0: 0.541 (0.568)\n",
      "-23: 500-0.05-0.0005-0: 0.514 (0.568)\n",
      "-23: 500-0.01-0.0005-0: 0.568 (0.595)\n",
      "-23: 500-0.05-0.01-0: 0.757 (0.892)\n",
      "-23: 500-0.01-0.01-0: 0.703 (0.865)\n",
      "-23: 200-0.05-0.0005-0.25: 0.514 (0.595)\n",
      "-23: 200-0.05-0.0005-0.5: 0.514 (0.541)\n",
      "-23: 500-0.05-0.01-0.25: 0.811 (0.865)\n",
      "-23: 500-0.05-0.01-0.5: 0.811 (0.865)\n",
      "-24: 200-0.1-0.0005-0: 0.595 (0.649)\n",
      "-24: 200-0.05-0.0005-0: 0.595 (0.730)\n",
      "-24: 200-0.01-0.0005-0: 0.568 (0.622)\n",
      "-24: 200-0.005-0.0005-0: 0.405 (0.459)\n",
      "-24: 200-0.001-0.0005-0: 0.351 (0.405)\n",
      "-24: 200-0.05-0.001-0: 0.595 (0.595)\n",
      "-24: 200-0.01-0.001-0: 0.378 (0.405)\n",
      "-24: 200-0.05-0.01-0: 0.784 (0.892)\n",
      "-24: 200-0.01-0.01-0: 0.649 (0.730)\n",
      "-24: 200-0.05-0.05-0: 0.514 (0.514)\n",
      "-24: 200-0.01-0.05-0: 0.730 (0.730)\n",
      "-24: 500-0.05-0.0005-0: 0.703 (0.784)\n",
      "-24: 500-0.01-0.0005-0: 0.405 (0.459)\n",
      "-24: 500-0.05-0.01-0: 0.811 (0.892)\n",
      "-24: 500-0.01-0.01-0: 0.649 (0.703)\n",
      "-24: 200-0.05-0.0005-0.25: 0.568 (0.730)\n",
      "-24: 200-0.05-0.0005-0.5: 0.541 (0.541)\n",
      "-24: 500-0.05-0.01-0.25: 0.703 (0.865)\n",
      "-24: 500-0.05-0.01-0.5: 0.757 (0.865)\n",
      "-25: 200-0.1-0.0005-0: 0.514 (0.514)\n",
      "-25: 200-0.05-0.0005-0: 0.568 (0.703)\n",
      "-25: 200-0.01-0.0005-0: 0.351 (0.405)\n",
      "-25: 200-0.005-0.0005-0: 0.378 (0.432)\n",
      "-25: 200-0.001-0.0005-0: 0.243 (0.324)\n",
      "-25: 200-0.05-0.001-0: 0.757 (0.811)\n",
      "-25: 200-0.01-0.001-0: 0.351 (0.459)\n",
      "-25: 200-0.05-0.01-0: 0.703 (0.865)\n",
      "-25: 200-0.01-0.01-0: 0.378 (0.541)\n",
      "-25: 200-0.05-0.05-0: 0.784 (0.838)\n",
      "-25: 200-0.01-0.05-0: 0.703 (0.703)\n",
      "-25: 500-0.05-0.0005-0: 0.730 (0.811)\n",
      "-25: 500-0.01-0.0005-0: 0.432 (0.486)\n",
      "-25: 500-0.05-0.01-0: 0.730 (0.865)\n",
      "-25: 500-0.01-0.01-0: 0.676 (0.784)\n",
      "-25: 200-0.05-0.0005-0.25: 0.568 (0.595)\n",
      "-25: 200-0.05-0.0005-0.5: 0.486 (0.541)\n",
      "-25: 500-0.05-0.01-0.25: 0.784 (0.865)\n",
      "-25: 500-0.05-0.01-0.5: 0.703 (0.919)\n",
      "----- 14.44 mins -----\n"
     ]
    }
   ],
   "source": [
    "EXPS = [{'epochs': 200, 'lr': 1, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .5, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .1, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .001, 'wd': 5e-4, 'drop': 0},\n",
    "        \n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-3, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-2, 'drop': 0},\n",
    "\n",
    "        {'epochs': 200, 'lr': .1, 'wd': 1e-3, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .1, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .1, 'wd': 5e-2, 'drop': 0},\n",
    "        \n",
    "        {'epochs': 500, 'lr': .1, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 1e-2, 'drop': 0},\n",
    "\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .25},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .5},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .75},\n",
    "        ]\n",
    "\n",
    "best_accs1 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs1 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=exp['drop'], init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'])\n",
    "\n",
    "        best_accs1[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs1[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}: {best_val_accs1[j,i]:.3f} ({best_accs1[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}' for exp in EXPS]\n",
    "table_over1 = summary_table(best_accs1, index_name)\n",
    "table1 = summary_table(best_val_accs1, index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.0005-0</th>\n",
       "      <td>0.531892</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.056029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0</th>\n",
       "      <td>0.511351</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.090100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.0005-0</th>\n",
       "      <td>0.395676</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.086446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.0005-0</th>\n",
       "      <td>0.358919</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.057470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.001-0.0005-0</th>\n",
       "      <td>0.350270</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.074304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.001-0</th>\n",
       "      <td>0.606486</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.099106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.001-0</th>\n",
       "      <td>0.424865</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.099823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0</th>\n",
       "      <td>0.785946</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.043860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.01-0</th>\n",
       "      <td>0.652973</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.085699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.05-0</th>\n",
       "      <td>0.633514</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.161092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.05-0</th>\n",
       "      <td>0.637838</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.077205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.0005-0</th>\n",
       "      <td>0.603243</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.083991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.0005-0</th>\n",
       "      <td>0.499459</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.148648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0</th>\n",
       "      <td>0.779459</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.040939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.01-0</th>\n",
       "      <td>0.707027</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.037977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0.25</th>\n",
       "      <td>0.502703</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.066642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0.5</th>\n",
       "      <td>0.517838</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.092582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.25</th>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.032432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.5</th>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.042781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean accs       med       std\n",
       "200-0.1-0.0005-0       0.531892  0.513514  0.056029\n",
       "200-0.05-0.0005-0      0.511351  0.513514  0.090100\n",
       "200-0.01-0.0005-0      0.395676  0.405405  0.086446\n",
       "200-0.005-0.0005-0     0.358919  0.378378  0.057470\n",
       "200-0.001-0.0005-0     0.350270  0.378378  0.074304\n",
       "200-0.05-0.001-0       0.606486  0.621622  0.099106\n",
       "200-0.01-0.001-0       0.424865  0.405405  0.099823\n",
       "200-0.05-0.01-0        0.785946  0.783784  0.043860\n",
       "200-0.01-0.01-0        0.652973  0.675676  0.085699\n",
       "200-0.05-0.05-0        0.633514  0.702703  0.161092\n",
       "200-0.01-0.05-0        0.637838  0.675676  0.077205\n",
       "500-0.05-0.0005-0      0.603243  0.621622  0.083991\n",
       "500-0.01-0.0005-0      0.499459  0.405405  0.148648\n",
       "500-0.05-0.01-0        0.779459  0.783784  0.040939\n",
       "500-0.01-0.01-0        0.707027  0.702703  0.037977\n",
       "200-0.05-0.0005-0.25   0.502703  0.513514  0.066642\n",
       "200-0.05-0.0005-0.5    0.517838  0.513514  0.092582\n",
       "500-0.05-0.01-0.25     0.772973  0.783784  0.032432\n",
       "500-0.05-0.01-0.5      0.760000  0.756757  0.042781"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.0005-0</th>\n",
       "      <td>0.568649</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.049234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0</th>\n",
       "      <td>0.566486</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.111430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.0005-0</th>\n",
       "      <td>0.446486</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.082020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.0005-0</th>\n",
       "      <td>0.406486</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.064177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.001-0.0005-0</th>\n",
       "      <td>0.409730</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.063811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.001-0</th>\n",
       "      <td>0.688649</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.094901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.001-0</th>\n",
       "      <td>0.487568</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.087654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0</th>\n",
       "      <td>0.882162</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.021459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.01-0</th>\n",
       "      <td>0.699459</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.065009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.05-0</th>\n",
       "      <td>0.699459</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.173196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.05-0</th>\n",
       "      <td>0.664865</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.074508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.0005-0</th>\n",
       "      <td>0.665946</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.103378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.0005-0</th>\n",
       "      <td>0.562162</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.135243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.015441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.01-0</th>\n",
       "      <td>0.789189</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.043243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0.25</th>\n",
       "      <td>0.562162</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.066202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0.5</th>\n",
       "      <td>0.561081</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.080277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.25</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.017230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.5</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.024174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean accs       med       std\n",
       "200-0.1-0.0005-0       0.568649  0.567568  0.049234\n",
       "200-0.05-0.0005-0      0.566486  0.567568  0.111430\n",
       "200-0.01-0.0005-0      0.446486  0.459459  0.082020\n",
       "200-0.005-0.0005-0     0.406486  0.432432  0.064177\n",
       "200-0.001-0.0005-0     0.409730  0.432432  0.063811\n",
       "200-0.05-0.001-0       0.688649  0.702703  0.094901\n",
       "200-0.01-0.001-0       0.487568  0.486486  0.087654\n",
       "200-0.05-0.01-0        0.882162  0.891892  0.021459\n",
       "200-0.01-0.01-0        0.699459  0.729730  0.065009\n",
       "200-0.05-0.05-0        0.699459  0.837838  0.173196\n",
       "200-0.01-0.05-0        0.664865  0.675676  0.074508\n",
       "500-0.05-0.0005-0      0.665946  0.648649  0.103378\n",
       "500-0.01-0.0005-0      0.562162  0.459459  0.135243\n",
       "500-0.05-0.01-0        0.880000  0.891892  0.015441\n",
       "500-0.01-0.01-0        0.789189  0.783784  0.043243\n",
       "200-0.05-0.0005-0.25   0.562162  0.540541  0.066202\n",
       "200-0.05-0.0005-0.5    0.561081  0.540541  0.080277\n",
       "500-0.05-0.01-0.25     0.880000  0.864865  0.017230\n",
       "500-0.05-0.01-0.5      0.864865  0.864865  0.024174"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_over1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 0.001-1-1-True: 0.865\n",
      "-1: 0.01-1-1-True: 0.865\n",
      "-1: 0.1-1-1-True: 0.838\n",
      "-1: 1-1-1-True: 0.892\n",
      "-1: 0.01-1-1-False: 0.892\n",
      "-1: 1-1-1-False: 0.838\n",
      "-1: 1-10-1-True: 0.892\n",
      "-1: 1-1-10-True: 0.892\n",
      "-1: 0.01-10-10-True: 0.865\n",
      "-1: 1-10-10-True: 0.865\n",
      "-1: 1-25-25-True: 0.838\n",
      "-1: 1-50-50-True: 0.838\n",
      "-2: 0.001-1-1-True: 0.865\n",
      "-2: 0.01-1-1-True: 0.865\n",
      "-2: 0.1-1-1-True: 0.892\n",
      "-2: 1-1-1-True: 0.865\n",
      "-2: 0.01-1-1-False: 0.865\n",
      "-2: 1-1-1-False: 0.919\n",
      "-2: 1-10-1-True: 0.892\n",
      "-2: 1-1-10-True: 0.865\n",
      "-2: 0.01-10-10-True: 0.865\n",
      "-2: 1-10-10-True: 0.919\n",
      "-2: 1-25-25-True: 0.865\n",
      "-2: 1-50-50-True: 0.838\n",
      "-3: 0.001-1-1-True: 0.865\n",
      "-3: 0.01-1-1-True: 0.865\n",
      "-3: 0.1-1-1-True: 0.838\n",
      "-3: 1-1-1-True: 0.838\n",
      "-3: 0.01-1-1-False: 0.865\n",
      "-3: 1-1-1-False: 0.892\n",
      "-3: 1-10-1-True: 0.865\n",
      "-3: 1-1-10-True: 0.865\n",
      "-3: 0.01-10-10-True: 0.838\n",
      "-3: 1-10-10-True: 0.865\n",
      "-3: 1-25-25-True: 0.865\n",
      "-3: 1-50-50-True: 0.838\n",
      "-4: 0.001-1-1-True: 0.892\n",
      "-4: 0.01-1-1-True: 0.865\n",
      "-4: 0.1-1-1-True: 0.865\n",
      "-4: 1-1-1-True: 0.865\n",
      "-4: 0.01-1-1-False: 0.892\n",
      "-4: 1-1-1-False: 0.892\n",
      "-4: 1-10-1-True: 0.838\n",
      "-4: 1-1-10-True: 0.838\n",
      "-4: 0.01-10-10-True: 0.865\n",
      "-4: 1-10-10-True: 0.865\n",
      "-4: 1-25-25-True: 0.865\n",
      "-4: 1-50-50-True: 0.838\n",
      "-5: 0.001-1-1-True: 0.811\n",
      "-5: 0.01-1-1-True: 0.838\n",
      "-5: 0.1-1-1-True: 0.865\n",
      "-5: 1-1-1-True: 0.811\n",
      "-5: 0.01-1-1-False: 0.865\n",
      "-5: 1-1-1-False: 0.838\n",
      "-5: 1-10-1-True: 0.865\n",
      "-5: 1-1-10-True: 0.865\n",
      "-5: 0.01-10-10-True: 0.865\n",
      "-5: 1-10-10-True: 0.892\n",
      "-5: 1-25-25-True: 0.892\n",
      "-5: 1-50-50-True: 0.865\n",
      "-6: 0.001-1-1-True: 0.919\n",
      "-6: 0.01-1-1-True: 0.568\n",
      "-6: 0.1-1-1-True: 0.892\n",
      "-6: 1-1-1-True: 0.838\n",
      "-6: 0.01-1-1-False: 0.865\n",
      "-6: 1-1-1-False: 0.892\n",
      "-6: 1-10-1-True: 0.892\n",
      "-6: 1-1-10-True: 0.865\n",
      "-6: 0.01-10-10-True: 0.865\n",
      "-6: 1-10-10-True: 0.919\n",
      "-6: 1-25-25-True: 0.892\n",
      "-6: 1-50-50-True: 0.838\n",
      "-7: 0.001-1-1-True: 0.865\n",
      "-7: 0.01-1-1-True: 0.892\n",
      "-7: 0.1-1-1-True: 0.865\n",
      "-7: 1-1-1-True: 0.892\n",
      "-7: 0.01-1-1-False: 0.865\n",
      "-7: 1-1-1-False: 0.865\n",
      "-7: 1-10-1-True: 0.892\n",
      "-7: 1-1-10-True: 0.838\n",
      "-7: 0.01-10-10-True: 0.892\n",
      "-7: 1-10-10-True: 0.865\n",
      "-7: 1-25-25-True: 0.865\n",
      "-7: 1-50-50-True: 0.892\n",
      "-8: 0.001-1-1-True: 0.892\n",
      "-8: 0.01-1-1-True: 0.865\n",
      "-8: 0.1-1-1-True: 0.892\n",
      "-8: 1-1-1-True: 0.838\n",
      "-8: 0.01-1-1-False: 0.865\n",
      "-8: 1-1-1-False: 0.865\n",
      "-8: 1-10-1-True: 0.892\n",
      "-8: 1-1-10-True: 0.892\n",
      "-8: 0.01-10-10-True: 0.865\n",
      "-8: 1-10-10-True: 0.865\n",
      "-8: 1-25-25-True: 0.838\n",
      "-8: 1-50-50-True: 0.838\n",
      "-9: 0.001-1-1-True: 0.892\n",
      "-9: 0.01-1-1-True: 0.865\n",
      "-9: 0.1-1-1-True: 0.865\n",
      "-9: 1-1-1-True: 0.865\n",
      "-9: 0.01-1-1-False: 0.838\n",
      "-9: 1-1-1-False: 0.892\n",
      "-9: 1-10-1-True: 0.892\n",
      "-9: 1-1-10-True: 0.865\n",
      "-9: 0.01-10-10-True: 0.865\n",
      "-9: 1-10-10-True: 0.838\n",
      "-9: 1-25-25-True: 0.838\n",
      "-9: 1-50-50-True: 0.865\n",
      "-10: 0.001-1-1-True: 0.865\n",
      "-10: 0.01-1-1-True: 0.865\n",
      "-10: 0.1-1-1-True: 0.892\n",
      "-10: 1-1-1-True: 0.892\n",
      "-10: 0.01-1-1-False: 0.892\n",
      "-10: 1-1-1-False: 0.865\n",
      "-10: 1-10-1-True: 0.865\n",
      "-10: 1-1-10-True: 0.865\n",
      "-10: 0.01-10-10-True: 0.865\n",
      "-10: 1-10-10-True: 0.838\n",
      "-10: 1-25-25-True: 0.865\n",
      "-10: 1-50-50-True: 0.865\n",
      "-11: 0.001-1-1-True: 0.865\n",
      "-11: 0.01-1-1-True: 0.892\n",
      "-11: 0.1-1-1-True: 0.892\n",
      "-11: 1-1-1-True: 0.865\n",
      "-11: 0.01-1-1-False: 0.892\n",
      "-11: 1-1-1-False: 0.865\n",
      "-11: 1-10-1-True: 0.865\n",
      "-11: 1-1-10-True: 0.865\n",
      "-11: 0.01-10-10-True: 0.865\n",
      "-11: 1-10-10-True: 0.892\n",
      "-11: 1-25-25-True: 0.892\n",
      "-11: 1-50-50-True: 0.838\n",
      "-12: 0.001-1-1-True: 0.892\n",
      "-12: 0.01-1-1-True: 0.865\n",
      "-12: 0.1-1-1-True: 0.919\n",
      "-12: 1-1-1-True: 0.838\n",
      "-12: 0.01-1-1-False: 0.757\n",
      "-12: 1-1-1-False: 0.865\n",
      "-12: 1-10-1-True: 0.865\n",
      "-12: 1-1-10-True: 0.865\n",
      "-12: 0.01-10-10-True: 0.865\n",
      "-12: 1-10-10-True: 0.892\n",
      "-12: 1-25-25-True: 0.865\n",
      "-12: 1-50-50-True: 0.838\n",
      "-13: 0.001-1-1-True: 0.892\n",
      "-13: 0.01-1-1-True: 0.892\n",
      "-13: 0.1-1-1-True: 0.838\n",
      "-13: 1-1-1-True: 0.865\n",
      "-13: 0.01-1-1-False: 0.892\n",
      "-13: 1-1-1-False: 0.865\n",
      "-13: 1-10-1-True: 0.865\n",
      "-13: 1-1-10-True: 0.865\n",
      "-13: 0.01-10-10-True: 0.865\n",
      "-13: 1-10-10-True: 0.865\n",
      "-13: 1-25-25-True: 0.865\n",
      "-13: 1-50-50-True: 0.865\n",
      "-14: 0.001-1-1-True: 0.865\n",
      "-14: 0.01-1-1-True: 0.865\n",
      "-14: 0.1-1-1-True: 0.838\n",
      "-14: 1-1-1-True: 0.838\n",
      "-14: 0.01-1-1-False: 0.865\n",
      "-14: 1-1-1-False: 0.865\n",
      "-14: 1-10-1-True: 0.865\n",
      "-14: 1-1-10-True: 0.838\n",
      "-14: 0.01-10-10-True: 0.892\n",
      "-14: 1-10-10-True: 0.865\n",
      "-14: 1-25-25-True: 0.865\n",
      "-14: 1-50-50-True: 0.838\n",
      "-15: 0.001-1-1-True: 0.892\n",
      "-15: 0.01-1-1-True: 0.865\n",
      "-15: 0.1-1-1-True: 0.865\n",
      "-15: 1-1-1-True: 0.838\n",
      "-15: 0.01-1-1-False: 0.838\n",
      "-15: 1-1-1-False: 0.892\n",
      "-15: 1-10-1-True: 0.865\n",
      "-15: 1-1-10-True: 0.865\n",
      "-15: 0.01-10-10-True: 0.892\n",
      "-15: 1-10-10-True: 0.865\n",
      "-15: 1-25-25-True: 0.865\n",
      "-15: 1-50-50-True: 0.865\n",
      "-16: 0.001-1-1-True: 0.892\n",
      "-16: 0.01-1-1-True: 0.865\n",
      "-16: 0.1-1-1-True: 0.865\n",
      "-16: 1-1-1-True: 0.865\n",
      "-16: 0.01-1-1-False: 0.865\n",
      "-16: 1-1-1-False: 0.865\n",
      "-16: 1-10-1-True: 0.838\n",
      "-16: 1-1-10-True: 0.865\n",
      "-16: 0.01-10-10-True: 0.919\n",
      "-16: 1-10-10-True: 0.865\n",
      "-16: 1-25-25-True: 0.865\n",
      "-16: 1-50-50-True: 0.838\n",
      "-17: 0.001-1-1-True: 0.865\n",
      "-17: 0.01-1-1-True: 0.892\n",
      "-17: 0.1-1-1-True: 0.865\n",
      "-17: 1-1-1-True: 0.865\n",
      "-17: 0.01-1-1-False: 0.865\n",
      "-17: 1-1-1-False: 0.892\n",
      "-17: 1-10-1-True: 0.892\n",
      "-17: 1-1-10-True: 0.865\n",
      "-17: 0.01-10-10-True: 0.865\n",
      "-17: 1-10-10-True: 0.865\n",
      "-17: 1-25-25-True: 0.865\n",
      "-17: 1-50-50-True: 0.838\n",
      "-18: 0.001-1-1-True: 0.865\n",
      "-18: 0.01-1-1-True: 0.838\n",
      "-18: 0.1-1-1-True: 0.865\n",
      "-18: 1-1-1-True: 0.865\n",
      "-18: 0.01-1-1-False: 0.838\n",
      "-18: 1-1-1-False: 0.865\n",
      "-18: 1-10-1-True: 0.865\n",
      "-18: 1-1-10-True: 0.838\n",
      "-18: 0.01-10-10-True: 0.865\n",
      "-18: 1-10-10-True: 0.865\n",
      "-18: 1-25-25-True: 0.865\n",
      "-18: 1-50-50-True: 0.865\n",
      "-19: 0.001-1-1-True: 0.865\n",
      "-19: 0.01-1-1-True: 0.838\n",
      "-19: 0.1-1-1-True: 0.865\n",
      "-19: 1-1-1-True: 0.892\n",
      "-19: 0.01-1-1-False: 0.865\n",
      "-19: 1-1-1-False: 0.865\n",
      "-19: 1-10-1-True: 0.892\n",
      "-19: 1-1-10-True: 0.838\n",
      "-19: 0.01-10-10-True: 0.838\n",
      "-19: 1-10-10-True: 0.865\n",
      "-19: 1-25-25-True: 0.892\n",
      "-19: 1-50-50-True: 0.865\n",
      "-20: 0.001-1-1-True: 0.703\n",
      "-20: 0.01-1-1-True: 0.865\n",
      "-20: 0.1-1-1-True: 0.865\n",
      "-20: 1-1-1-True: 0.838\n",
      "-20: 0.01-1-1-False: 0.865\n",
      "-20: 1-1-1-False: 0.865\n",
      "-20: 1-10-1-True: 0.865\n",
      "-20: 1-1-10-True: 0.838\n",
      "-20: 0.01-10-10-True: 0.892\n",
      "-20: 1-10-10-True: 0.838\n",
      "-20: 1-25-25-True: 0.865\n",
      "-20: 1-50-50-True: 0.865\n",
      "-21: 0.001-1-1-True: 0.919\n",
      "-21: 0.01-1-1-True: 0.865\n",
      "-21: 0.1-1-1-True: 0.865\n",
      "-21: 1-1-1-True: 0.838\n",
      "-21: 0.01-1-1-False: 0.865\n",
      "-21: 1-1-1-False: 0.865\n",
      "-21: 1-10-1-True: 0.865\n",
      "-21: 1-1-10-True: 0.865\n",
      "-21: 0.01-10-10-True: 0.865\n",
      "-21: 1-10-10-True: 0.865\n",
      "-21: 1-25-25-True: 0.838\n",
      "-21: 1-50-50-True: 0.838\n",
      "-22: 0.001-1-1-True: 0.865\n",
      "-22: 0.01-1-1-True: 0.892\n",
      "-22: 0.1-1-1-True: 0.838\n",
      "-22: 1-1-1-True: 0.865\n",
      "-22: 0.01-1-1-False: 0.865\n",
      "-22: 1-1-1-False: 0.865\n",
      "-22: 1-10-1-True: 0.892\n",
      "-22: 1-1-10-True: 0.865\n",
      "-22: 0.01-10-10-True: 0.865\n",
      "-22: 1-10-10-True: 0.865\n",
      "-22: 1-25-25-True: 0.865\n",
      "-22: 1-50-50-True: 0.838\n",
      "-23: 0.001-1-1-True: 0.892\n",
      "-23: 0.01-1-1-True: 0.865\n",
      "-23: 0.1-1-1-True: 0.865\n",
      "-23: 1-1-1-True: 0.865\n",
      "-23: 0.01-1-1-False: 0.892\n",
      "-23: 1-1-1-False: 0.865\n",
      "-23: 1-10-1-True: 0.892\n",
      "-23: 1-1-10-True: 0.892\n",
      "-23: 0.01-10-10-True: 0.865\n",
      "-23: 1-10-10-True: 0.865\n",
      "-23: 1-25-25-True: 0.838\n",
      "-23: 1-50-50-True: 0.838\n",
      "-24: 0.001-1-1-True: 0.838\n",
      "-24: 0.01-1-1-True: 0.865\n",
      "-24: 0.1-1-1-True: 0.892\n",
      "-24: 1-1-1-True: 0.865\n",
      "-24: 0.01-1-1-False: 0.865\n",
      "-24: 1-1-1-False: 0.865\n",
      "-24: 1-10-1-True: 0.838\n",
      "-24: 1-1-10-True: 0.865\n",
      "-24: 0.01-10-10-True: 0.865\n",
      "-24: 1-10-10-True: 0.865\n",
      "-24: 1-25-25-True: 0.865\n",
      "-24: 1-50-50-True: 0.838\n",
      "-25: 0.001-1-1-True: 0.838\n",
      "-25: 0.01-1-1-True: 0.865\n",
      "-25: 0.1-1-1-True: 0.892\n",
      "-25: 1-1-1-True: 0.811\n",
      "-25: 0.01-1-1-False: 0.784\n",
      "-25: 1-1-1-False: 0.865\n",
      "-25: 1-10-1-True: 0.838\n",
      "-25: 1-1-10-True: 0.838\n",
      "-25: 0.01-10-10-True: 0.865\n",
      "-25: 1-10-10-True: 0.865\n",
      "-25: 1-25-25-True: 0.892\n",
      "-25: 1-50-50-True: 0.865\n",
      "----- 23.94 mins -----\n"
     ]
    }
   ],
   "source": [
    "# h0, norm (norm, not norm, norm H), sep vs joint training, optimizers iters (W vs h)\n",
    "EXPS = [{'h0': .001, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        \n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 50, 'epochs_h': 50, 'epochs_W': 50, 'alt': True},]\n",
    "\n",
    "\n",
    "best_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=exp['h0'])\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        if not exp['alt']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S,  K, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD, epochs_h=exp['epochs_h'],\n",
    "                                 epochs_W=exp['epochs_W'])\n",
    "\n",
    "        best_accs2[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs2[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}: {best_val_accs2[j,i]:.3f} ({best_accs2[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}' for exp in EXPS]\n",
    "table_over2 = summary_table(best_accs2, index_name)\n",
    "table2 = summary_table(best_val_accs2, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/srey/Investigacion/robust_minmax_gnn/parameters_GF_GNN_A.ipynb Cell 15\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/parameters_GF_GNN_A.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m table2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'table2' is not defined"
     ]
    }
   ],
   "source": [
    "table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_over2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 2-2-16: 0.865\n",
      "-1: 2-3-16: 0.865\n",
      "-1: 2-4-16: 0.865\n",
      "-1: 3-2-16: 0.865\n",
      "-1: 4-2-16: 0.811\n",
      "-1: 3-3-16: 0.811\n",
      "-1: 4-3-16: 0.865\n",
      "-1: 2-2-8: 0.838\n",
      "-1: 2-2-32: 0.838\n",
      "-1: 2-2-50: 0.865\n",
      "-1: 2-3-8: 0.865\n",
      "-1: 2-3-32: 0.865\n",
      "-1: 2-3-50: 0.865\n",
      "-1: 3-2-8: 0.865\n",
      "-1: 3-2-32: 0.838\n",
      "-1: 3-2-50: 0.811\n",
      "-1: 3-3-8: 0.811\n",
      "-1: 3-3-32: 0.865\n",
      "-1: 3-3-50: 0.838\n",
      "-2: 2-2-16: 0.865\n",
      "-2: 2-3-16: 0.838\n",
      "-2: 2-4-16: 0.838\n",
      "-2: 3-2-16: 0.865\n",
      "-2: 4-2-16: 0.757\n",
      "-2: 3-3-16: 0.865\n",
      "-2: 4-3-16: 0.865\n",
      "-2: 2-2-8: 0.811\n",
      "-2: 2-2-32: 0.865\n",
      "-2: 2-2-50: 0.838\n",
      "-2: 2-3-8: 0.838\n",
      "-2: 2-3-32: 0.892\n",
      "-2: 2-3-50: 0.838\n",
      "-2: 3-2-8: 0.838\n",
      "-2: 3-2-32: 0.865\n",
      "-2: 3-2-50: 0.865\n",
      "-2: 3-3-8: 0.838\n",
      "-2: 3-3-32: 0.892\n",
      "-2: 3-3-50: 0.514\n",
      "-3: 2-2-16: 0.838\n",
      "-3: 2-3-16: 0.865\n",
      "-3: 2-4-16: 0.838\n",
      "-3: 3-2-16: 0.865\n",
      "-3: 4-2-16: 0.784\n",
      "-3: 3-3-16: 0.865\n",
      "-3: 4-3-16: 0.784\n",
      "-3: 2-2-8: 0.811\n",
      "-3: 2-2-32: 0.865\n",
      "-3: 2-2-50: 0.865\n",
      "-3: 2-3-8: 0.865\n",
      "-3: 2-3-32: 0.865\n",
      "-3: 2-3-50: 0.865\n",
      "-3: 3-2-8: 0.838\n",
      "-3: 3-2-32: 0.838\n",
      "-3: 3-2-50: 0.892\n",
      "-3: 3-3-8: 0.784\n",
      "-3: 3-3-32: 0.865\n",
      "-3: 3-3-50: 0.568\n",
      "-4: 2-2-16: 0.838\n",
      "-4: 2-3-16: 0.865\n",
      "-4: 2-4-16: 0.865\n",
      "-4: 3-2-16: 0.865\n",
      "-4: 4-2-16: 0.865\n",
      "-4: 3-3-16: 0.892\n",
      "-4: 4-3-16: 0.865\n",
      "-4: 2-2-8: 0.811\n",
      "-4: 2-2-32: 0.865\n",
      "-4: 2-2-50: 0.838\n",
      "-4: 2-3-8: 0.541\n",
      "-4: 2-3-32: 0.838\n",
      "-4: 2-3-50: 0.838\n",
      "-4: 3-2-8: 0.811\n",
      "-4: 3-2-32: 0.811\n",
      "-4: 3-2-50: 0.865\n",
      "-4: 3-3-8: 0.811\n",
      "-4: 3-3-32: 0.784\n",
      "-4: 3-3-50: 0.703\n",
      "-5: 2-2-16: 0.865\n",
      "-5: 2-3-16: 0.865\n",
      "-5: 2-4-16: 0.892\n",
      "-5: 3-2-16: 0.811\n",
      "-5: 4-2-16: 0.838\n",
      "-5: 3-3-16: 0.541\n",
      "-5: 4-3-16: 0.892\n",
      "-5: 2-2-8: 0.811\n",
      "-5: 2-2-32: 0.865\n",
      "-5: 2-2-50: 0.865\n",
      "-5: 2-3-8: 0.865\n",
      "-5: 2-3-32: 0.865\n",
      "-5: 2-3-50: 0.838\n",
      "-5: 3-2-8: 0.838\n",
      "-5: 3-2-32: 0.892\n",
      "-5: 3-2-50: 0.865\n",
      "-5: 3-3-8: 0.811\n",
      "-5: 3-3-32: 0.838\n",
      "-5: 3-3-50: 0.865\n",
      "-6: 2-2-16: 0.838\n",
      "-6: 2-3-16: 0.865\n",
      "-6: 2-4-16: 0.811\n",
      "-6: 3-2-16: 0.865\n",
      "-6: 4-2-16: 0.784\n",
      "-6: 3-3-16: 0.838\n",
      "-6: 4-3-16: 0.838\n",
      "-6: 2-2-8: 0.838\n",
      "-6: 2-2-32: 0.865\n",
      "-6: 2-2-50: 0.865\n",
      "-6: 2-3-8: 0.865\n",
      "-6: 2-3-32: 0.865\n",
      "-6: 2-3-50: 0.892\n",
      "-6: 3-2-8: 0.838\n",
      "-6: 3-2-32: 0.838\n",
      "-6: 3-2-50: 0.703\n",
      "-6: 3-3-8: 0.811\n",
      "-6: 3-3-32: 0.838\n",
      "-6: 3-3-50: 0.892\n",
      "-7: 2-2-16: 0.865\n",
      "-7: 2-3-16: 0.838\n",
      "-7: 2-4-16: 0.811\n",
      "-7: 3-2-16: 0.892\n",
      "-7: 4-2-16: 0.784\n",
      "-7: 3-3-16: 0.865\n",
      "-7: 4-3-16: 0.865\n",
      "-7: 2-2-8: 0.811\n",
      "-7: 2-2-32: 0.865\n",
      "-7: 2-2-50: 0.865\n",
      "-7: 2-3-8: 0.838\n",
      "-7: 2-3-32: 0.865\n",
      "-7: 2-3-50: 0.838\n",
      "-7: 3-2-8: 0.838\n",
      "-7: 3-2-32: 0.622\n",
      "-7: 3-2-50: 0.541\n",
      "-7: 3-3-8: 0.757\n",
      "-7: 3-3-32: 0.514\n",
      "-7: 3-3-50: 0.838\n",
      "-8: 2-2-16: 0.865\n",
      "-8: 2-3-16: 0.892\n",
      "-8: 2-4-16: 0.838\n",
      "-8: 3-2-16: 0.838\n",
      "-8: 4-2-16: 0.892\n",
      "-8: 3-3-16: 0.838\n",
      "-8: 4-3-16: 0.838\n",
      "-8: 2-2-8: 0.838\n",
      "-8: 2-2-32: 0.865\n",
      "-8: 2-2-50: 0.865\n",
      "-8: 2-3-8: 0.865\n",
      "-8: 2-3-32: 0.865\n",
      "-8: 2-3-50: 0.838\n",
      "-8: 3-2-8: 0.757\n",
      "-8: 3-2-32: 0.865\n",
      "-8: 3-2-50: 0.865\n",
      "-8: 3-3-8: 0.838\n",
      "-8: 3-3-32: 0.865\n",
      "-8: 3-3-50: 0.865\n",
      "-9: 2-2-16: 0.838\n",
      "-9: 2-3-16: 0.865\n",
      "-9: 2-4-16: 0.838\n",
      "-9: 3-2-16: 0.838\n",
      "-9: 4-2-16: 0.838\n",
      "-9: 3-3-16: 0.865\n",
      "-9: 4-3-16: 0.811\n",
      "-9: 2-2-8: 0.838\n",
      "-9: 2-2-32: 0.865\n",
      "-9: 2-2-50: 0.865\n",
      "-9: 2-3-8: 0.811\n",
      "-9: 2-3-32: 0.865\n",
      "-9: 2-3-50: 0.865\n",
      "-9: 3-2-8: 0.865\n",
      "-9: 3-2-32: 0.838\n",
      "-9: 3-2-50: 0.865\n",
      "-9: 3-3-8: 0.865\n",
      "-9: 3-3-32: 0.838\n",
      "-9: 3-3-50: 0.811\n",
      "-10: 2-2-16: 0.865\n",
      "-10: 2-3-16: 0.892\n",
      "-10: 2-4-16: 0.865\n",
      "-10: 3-2-16: 0.865\n",
      "-10: 4-2-16: 0.541\n",
      "-10: 3-3-16: 0.865\n",
      "-10: 4-3-16: 0.568\n",
      "-10: 2-2-8: 0.811\n",
      "-10: 2-2-32: 0.838\n",
      "-10: 2-2-50: 0.865\n",
      "-10: 2-3-8: 0.838\n",
      "-10: 2-3-32: 0.865\n",
      "-10: 2-3-50: 0.865\n",
      "-10: 3-2-8: 0.865\n",
      "-10: 3-2-32: 0.865\n",
      "-10: 3-2-50: 0.838\n",
      "-10: 3-3-8: 0.919\n",
      "-10: 3-3-32: 0.865\n",
      "-10: 3-3-50: 0.892\n",
      "-11: 2-2-16: 0.892\n",
      "-11: 2-3-16: 0.838\n",
      "-11: 2-4-16: 0.865\n",
      "-11: 3-2-16: 0.838\n",
      "-11: 4-2-16: 0.811\n",
      "-11: 3-3-16: 0.838\n",
      "-11: 4-3-16: 0.892\n",
      "-11: 2-2-8: 0.865\n",
      "-11: 2-2-32: 0.865\n",
      "-11: 2-2-50: 0.865\n",
      "-11: 2-3-8: 0.892\n",
      "-11: 2-3-32: 0.865\n",
      "-11: 2-3-50: 0.838\n",
      "-11: 3-2-8: 0.865\n",
      "-11: 3-2-32: 0.838\n",
      "-11: 3-2-50: 0.865\n",
      "-11: 3-3-8: 0.838\n",
      "-11: 3-3-32: 0.757\n",
      "-11: 3-3-50: 0.541\n",
      "-12: 2-2-16: 0.892\n",
      "-12: 2-3-16: 0.838\n",
      "-12: 2-4-16: 0.865\n",
      "-12: 3-2-16: 0.865\n",
      "-12: 4-2-16: 0.730\n",
      "-12: 3-3-16: 0.811\n",
      "-12: 4-3-16: 0.757\n",
      "-12: 2-2-8: 0.838\n",
      "-12: 2-2-32: 0.838\n",
      "-12: 2-2-50: 0.865\n",
      "-12: 2-3-8: 0.865\n",
      "-12: 2-3-32: 0.865\n",
      "-12: 2-3-50: 0.865\n",
      "-12: 3-2-8: 0.865\n",
      "-12: 3-2-32: 0.865\n",
      "-12: 3-2-50: 0.568\n",
      "-12: 3-3-8: 0.865\n",
      "-12: 3-3-32: 0.838\n",
      "-12: 3-3-50: 0.838\n",
      "-13: 2-2-16: 0.865\n",
      "-13: 2-3-16: 0.865\n",
      "-13: 2-4-16: 0.865\n",
      "-13: 3-2-16: 0.838\n",
      "-13: 4-2-16: 0.730\n",
      "-13: 3-3-16: 0.865\n",
      "-13: 4-3-16: 0.730\n",
      "-13: 2-2-8: 0.865\n",
      "-13: 2-2-32: 0.865\n",
      "-13: 2-2-50: 0.865\n",
      "-13: 2-3-8: 0.838\n",
      "-13: 2-3-32: 0.865\n",
      "-13: 2-3-50: 0.865\n",
      "-13: 3-2-8: 0.865\n",
      "-13: 3-2-32: 0.784\n",
      "-13: 3-2-50: 0.865\n",
      "-13: 3-3-8: 0.811\n",
      "-13: 3-3-32: 0.892\n",
      "-13: 3-3-50: 0.757\n",
      "-14: 2-2-16: 0.838\n",
      "-14: 2-3-16: 0.865\n",
      "-14: 2-4-16: 0.811\n",
      "-14: 3-2-16: 0.865\n",
      "-14: 4-2-16: 0.649\n",
      "-14: 3-3-16: 0.865\n",
      "-14: 4-3-16: 0.811\n",
      "-14: 2-2-8: 0.865\n",
      "-14: 2-2-32: 0.865\n",
      "-14: 2-2-50: 0.865\n",
      "-14: 2-3-8: 0.838\n",
      "-14: 2-3-32: 0.892\n",
      "-14: 2-3-50: 0.892\n",
      "-14: 3-2-8: 0.730\n",
      "-14: 3-2-32: 0.838\n",
      "-14: 3-2-50: 0.865\n",
      "-14: 3-3-8: 0.730\n",
      "-14: 3-3-32: 0.892\n",
      "-14: 3-3-50: 0.514\n",
      "-15: 2-2-16: 0.838\n",
      "-15: 2-3-16: 0.865\n",
      "-15: 2-4-16: 0.892\n",
      "-15: 3-2-16: 0.865\n",
      "-15: 4-2-16: 0.838\n",
      "-15: 3-3-16: 0.865\n",
      "-15: 4-3-16: 0.838\n",
      "-15: 2-2-8: 0.865\n",
      "-15: 2-2-32: 0.838\n",
      "-15: 2-2-50: 0.892\n",
      "-15: 2-3-8: 0.865\n",
      "-15: 2-3-32: 0.865\n",
      "-15: 2-3-50: 0.892\n",
      "-15: 3-2-8: 0.838\n",
      "-15: 3-2-32: 0.865\n",
      "-15: 3-2-50: 0.811\n",
      "-15: 3-3-8: 0.892\n",
      "-15: 3-3-32: 0.838\n",
      "-15: 3-3-50: 0.595\n",
      "-16: 2-2-16: 0.865\n",
      "-16: 2-3-16: 0.865\n",
      "-16: 2-4-16: 0.838\n",
      "-16: 3-2-16: 0.865\n",
      "-16: 4-2-16: 0.784\n",
      "-16: 3-3-16: 0.865\n",
      "-16: 4-3-16: 0.865\n",
      "-16: 2-2-8: 0.838\n",
      "-16: 2-2-32: 0.838\n",
      "-16: 2-2-50: 0.838\n",
      "-16: 2-3-8: 0.811\n",
      "-16: 2-3-32: 0.865\n",
      "-16: 2-3-50: 0.892\n",
      "-16: 3-2-8: 0.838\n",
      "-16: 3-2-32: 0.892\n",
      "-16: 3-2-50: 0.838\n",
      "-16: 3-3-8: 0.838\n",
      "-16: 3-3-32: 0.865\n",
      "-16: 3-3-50: 0.838\n",
      "-17: 2-2-16: 0.838\n",
      "-17: 2-3-16: 0.865\n",
      "-17: 2-4-16: 0.838\n",
      "-17: 3-2-16: 0.838\n",
      "-17: 4-2-16: 0.811\n",
      "-17: 3-3-16: 0.892\n",
      "-17: 4-3-16: 0.595\n",
      "-17: 2-2-8: 0.838\n",
      "-17: 2-2-32: 0.865\n",
      "-17: 2-2-50: 0.919\n",
      "-17: 2-3-8: 0.865\n",
      "-17: 2-3-32: 0.865\n",
      "-17: 2-3-50: 0.865\n",
      "-17: 3-2-8: 0.892\n",
      "-17: 3-2-32: 0.865\n",
      "-17: 3-2-50: 0.838\n",
      "-17: 3-3-8: 0.865\n",
      "-17: 3-3-32: 0.865\n",
      "-17: 3-3-50: 0.541\n",
      "-18: 2-2-16: 0.865\n",
      "-18: 2-3-16: 0.838\n",
      "-18: 2-4-16: 0.865\n",
      "-18: 3-2-16: 0.838\n",
      "-18: 4-2-16: 0.514\n",
      "-18: 3-3-16: 0.811\n",
      "-18: 4-3-16: 0.838\n",
      "-18: 2-2-8: 0.838\n",
      "-18: 2-2-32: 0.865\n",
      "-18: 2-2-50: 0.865\n",
      "-18: 2-3-8: 0.838\n",
      "-18: 2-3-32: 0.865\n",
      "-18: 2-3-50: 0.838\n",
      "-18: 3-2-8: 0.784\n",
      "-18: 3-2-32: 0.541\n",
      "-18: 3-2-50: 0.811\n",
      "-18: 3-3-8: 0.838\n",
      "-18: 3-3-32: 0.865\n",
      "-18: 3-3-50: 0.865\n",
      "-19: 2-2-16: 0.865\n",
      "-19: 2-3-16: 0.919\n",
      "-19: 2-4-16: 0.838\n",
      "-19: 3-2-16: 0.838\n",
      "-19: 4-2-16: 0.838\n",
      "-19: 3-3-16: 0.838\n",
      "-19: 4-3-16: 0.865\n",
      "-19: 2-2-8: 0.784\n",
      "-19: 2-2-32: 0.892\n",
      "-19: 2-2-50: 0.892\n",
      "-19: 2-3-8: 0.838\n",
      "-19: 2-3-32: 0.865\n",
      "-19: 2-3-50: 0.865\n",
      "-19: 3-2-8: 0.811\n",
      "-19: 3-2-32: 0.757\n",
      "-19: 3-2-50: 0.919\n",
      "-19: 3-3-8: 0.838\n",
      "-19: 3-3-32: 0.811\n",
      "-19: 3-3-50: 0.703\n",
      "-20: 2-2-16: 0.892\n",
      "-20: 2-3-16: 0.838\n",
      "-20: 2-4-16: 0.892\n",
      "-20: 3-2-16: 0.865\n",
      "-20: 4-2-16: 0.865\n",
      "-20: 3-3-16: 0.811\n",
      "-20: 4-3-16: 0.865\n",
      "-20: 2-2-8: 0.838\n",
      "-20: 2-2-32: 0.892\n",
      "-20: 2-2-50: 0.865\n",
      "-20: 2-3-8: 0.892\n",
      "-20: 2-3-32: 0.892\n",
      "-20: 2-3-50: 0.892\n",
      "-20: 3-2-8: 0.865\n",
      "-20: 3-2-32: 0.838\n",
      "-20: 3-2-50: 0.892\n",
      "-20: 3-3-8: 0.757\n",
      "-20: 3-3-32: 0.838\n",
      "-20: 3-3-50: 0.838\n",
      "-21: 2-2-16: 0.838\n",
      "-21: 2-3-16: 0.838\n",
      "-21: 2-4-16: 0.838\n",
      "-21: 3-2-16: 0.865\n",
      "-21: 4-2-16: 0.811\n",
      "-21: 3-3-16: 0.865\n",
      "-21: 4-3-16: 0.568\n",
      "-21: 2-2-8: 0.838\n",
      "-21: 2-2-32: 0.892\n",
      "-21: 2-2-50: 0.892\n",
      "-21: 2-3-8: 0.838\n",
      "-21: 2-3-32: 0.892\n",
      "-21: 2-3-50: 0.865\n",
      "-21: 3-2-8: 0.838\n",
      "-21: 3-2-32: 0.892\n",
      "-21: 3-2-50: 0.757\n",
      "-21: 3-3-8: 0.838\n",
      "-21: 3-3-32: 0.838\n",
      "-21: 3-3-50: 0.838\n",
      "-22: 2-2-16: 0.892\n",
      "-22: 2-3-16: 0.838\n",
      "-22: 2-4-16: 0.784\n",
      "-22: 3-2-16: 0.838\n",
      "-22: 4-2-16: 0.838\n",
      "-22: 3-3-16: 0.919\n",
      "-22: 4-3-16: 0.838\n",
      "-22: 2-2-8: 0.865\n",
      "-22: 2-2-32: 0.865\n",
      "-22: 2-2-50: 0.865\n",
      "-22: 2-3-8: 0.865\n",
      "-22: 2-3-32: 0.865\n",
      "-22: 2-3-50: 0.865\n",
      "-22: 3-2-8: 0.865\n",
      "-22: 3-2-32: 0.811\n",
      "-22: 3-2-50: 0.838\n",
      "-22: 3-3-8: 0.568\n",
      "-22: 3-3-32: 0.811\n",
      "-22: 3-3-50: 0.784\n",
      "-23: 2-2-16: 0.838\n",
      "-23: 2-3-16: 0.838\n",
      "-23: 2-4-16: 0.865\n",
      "-23: 3-2-16: 0.865\n",
      "-23: 4-2-16: 0.838\n",
      "-23: 3-3-16: 0.838\n",
      "-23: 4-3-16: 0.784\n",
      "-23: 2-2-8: 0.838\n",
      "-23: 2-2-32: 0.865\n",
      "-23: 2-2-50: 0.892\n",
      "-23: 2-3-8: 0.865\n",
      "-23: 2-3-32: 0.838\n",
      "-23: 2-3-50: 0.892\n",
      "-23: 3-2-8: 0.838\n",
      "-23: 3-2-32: 0.757\n",
      "-23: 3-2-50: 0.811\n",
      "-23: 3-3-8: 0.838\n",
      "-23: 3-3-32: 0.865\n",
      "-23: 3-3-50: 0.838\n",
      "-24: 2-2-16: 0.838\n",
      "-24: 2-3-16: 0.838\n",
      "-24: 2-4-16: 0.865\n",
      "-24: 3-2-16: 0.838\n",
      "-24: 4-2-16: 0.892\n",
      "-24: 3-3-16: 0.811\n",
      "-24: 4-3-16: 0.838\n",
      "-24: 2-2-8: 0.838\n",
      "-24: 2-2-32: 0.865\n",
      "-24: 2-2-50: 0.892\n",
      "-24: 2-3-8: 0.892\n",
      "-24: 2-3-32: 0.811\n",
      "-24: 2-3-50: 0.892\n",
      "-24: 3-2-8: 0.865\n",
      "-24: 3-2-32: 0.811\n",
      "-24: 3-2-50: 0.865\n",
      "-24: 3-3-8: 0.838\n",
      "-24: 3-3-32: 0.730\n",
      "-24: 3-3-50: 0.541\n",
      "-25: 2-2-16: 0.865\n",
      "-25: 2-3-16: 0.892\n",
      "-25: 2-4-16: 0.838\n",
      "-25: 3-2-16: 0.811\n",
      "-25: 4-2-16: 0.838\n",
      "-25: 3-3-16: 0.838\n",
      "-25: 4-3-16: 0.865\n",
      "-25: 2-2-8: 0.865\n",
      "-25: 2-2-32: 0.865\n",
      "-25: 2-2-50: 0.865\n",
      "-25: 2-3-8: 0.838\n",
      "-25: 2-3-32: 0.865\n",
      "-25: 2-3-50: 0.838\n",
      "-25: 3-2-8: 0.838\n",
      "-25: 3-2-32: 0.811\n",
      "-25: 3-2-50: 0.838\n",
      "-25: 3-3-8: 0.730\n",
      "-25: 3-3-32: 0.865\n",
      "-25: 3-3-50: 0.541\n",
      "----- 9.18 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'L': 2, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 4, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 3, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 50},\n",
    "        ]\n",
    "\n",
    "best_accs3 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs3 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, exp['hid_dim'], OUT_DIM, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  exp['K'], masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs3[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs3[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}: {best_val_accs3[j,i]:.3f} ({best_accs3[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}' for exp in EXPS]\n",
    "table_over3 = summary_table(best_accs3, index_name)\n",
    "table3 = summary_table(best_val_accs3, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-2-16</th>\n",
       "      <td>0.858378</td>\n",
       "      <td>0.019157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-16</th>\n",
       "      <td>0.859459</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-4-16</th>\n",
       "      <td>0.848649</td>\n",
       "      <td>0.026481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-16</th>\n",
       "      <td>0.851892</td>\n",
       "      <td>0.018911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2-16</th>\n",
       "      <td>0.787027</td>\n",
       "      <td>0.093099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-16</th>\n",
       "      <td>0.838919</td>\n",
       "      <td>0.066852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-3-16</th>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.092998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-8</th>\n",
       "      <td>0.835676</td>\n",
       "      <td>0.021513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-32</th>\n",
       "      <td>0.862703</td>\n",
       "      <td>0.015135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-50</th>\n",
       "      <td>0.869189</td>\n",
       "      <td>0.018219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-8</th>\n",
       "      <td>0.841081</td>\n",
       "      <td>0.065009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-32</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.017093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-50</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.020907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-8</th>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.035855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-32</th>\n",
       "      <td>0.817297</td>\n",
       "      <td>0.079178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-50</th>\n",
       "      <td>0.819459</td>\n",
       "      <td>0.089384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-8</th>\n",
       "      <td>0.812973</td>\n",
       "      <td>0.067044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-32</th>\n",
       "      <td>0.829189</td>\n",
       "      <td>0.075180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-50</th>\n",
       "      <td>0.734054</td>\n",
       "      <td>0.138800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean accs       std\n",
       "2-2-16   0.858378  0.019157\n",
       "2-3-16   0.859459  0.021622\n",
       "2-4-16   0.848649  0.026481\n",
       "3-2-16   0.851892  0.018911\n",
       "4-2-16   0.787027  0.093099\n",
       "3-3-16   0.838919  0.066852\n",
       "4-3-16   0.805405  0.092998\n",
       "2-2-8    0.835676  0.021513\n",
       "2-2-32   0.862703  0.015135\n",
       "2-2-50   0.869189  0.018219\n",
       "2-3-8    0.841081  0.065009\n",
       "2-3-32   0.864865  0.017093\n",
       "2-3-50   0.863784  0.020907\n",
       "3-2-8    0.837838  0.035855\n",
       "3-2-32   0.817297  0.079178\n",
       "3-2-50   0.819459  0.089384\n",
       "3-3-8    0.812973  0.067044\n",
       "3-3-32   0.829189  0.075180\n",
       "3-3-50   0.734054  0.138800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_over3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearities and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-1: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-1: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.622\n",
      "-1: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-1: ReLU()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-1: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-1: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-1: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-1: Identity()-Identity()-CrossEntropyLoss(): 0.459\n",
      "-2: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-2: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-2: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-2: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.676\n",
      "-2: ReLU()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-2: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-2: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-2: Identity()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-2: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-3: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-3: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-3: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-3: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.541\n",
      "-3: ReLU()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-3: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.919\n",
      "-3: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-3: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-3: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-4: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-4: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-4: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.514\n",
      "-4: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.486\n",
      "-4: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-4: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-4: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-4: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-4: Identity()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-5: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-5: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-5: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-5: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649\n",
      "-5: ReLU()-Identity()-CrossEntropyLoss(): 0.676\n",
      "-5: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-5: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-5: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-5: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-6: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-6: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-6: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.676\n",
      "-6: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.595\n",
      "-6: ReLU()-Identity()-CrossEntropyLoss(): 0.730\n",
      "-6: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-6: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-6: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-6: Identity()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-7: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-7: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-7: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.541\n",
      "-7: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-7: ReLU()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-7: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-7: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-7: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-7: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-8: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-8: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-8: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.541\n",
      "-8: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-8: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-8: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-8: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-8: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-8: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-9: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-9: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-9: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.649\n",
      "-9: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649\n",
      "-9: ReLU()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-9: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-9: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-9: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-9: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-10: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-10: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-10: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-10: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.622\n",
      "-10: ReLU()-Identity()-CrossEntropyLoss(): 0.730\n",
      "-10: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-10: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-10: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-10: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-11: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-11: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-11: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.459\n",
      "-11: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.703\n",
      "-11: ReLU()-Identity()-CrossEntropyLoss(): 0.730\n",
      "-11: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-11: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-11: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-11: Identity()-Identity()-CrossEntropyLoss(): 0.432\n",
      "-12: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-12: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-12: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.541\n",
      "-12: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.541\n",
      "-12: ReLU()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-12: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-12: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-12: Identity()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-12: Identity()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-13: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-13: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-13: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.676\n",
      "-13: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-13: ReLU()-Identity()-CrossEntropyLoss(): 0.676\n",
      "-13: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-13: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.676\n",
      "-13: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-13: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-14: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-14: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-14: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.514\n",
      "-14: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.595\n",
      "-14: ReLU()-Identity()-CrossEntropyLoss(): 0.622\n",
      "-14: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-14: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-14: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-14: Identity()-Identity()-CrossEntropyLoss(): 0.622\n",
      "-15: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-15: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-15: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-15: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-15: ReLU()-Identity()-CrossEntropyLoss(): 0.676\n",
      "-15: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-15: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-15: Identity()-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-15: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-16: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-16: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-16: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.486\n",
      "-16: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.595\n",
      "-16: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-16: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-16: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-16: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-16: Identity()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-17: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-17: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-17: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.622\n",
      "-17: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-17: ReLU()-Identity()-CrossEntropyLoss(): 0.649\n",
      "-17: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-17: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.703\n",
      "-17: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-17: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-18: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-18: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-18: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-18: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-18: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-18: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-18: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-18: Identity()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-18: Identity()-Identity()-CrossEntropyLoss(): 0.459\n",
      "-19: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.757\n",
      "-19: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-19: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.459\n",
      "-19: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-19: ReLU()-Identity()-CrossEntropyLoss(): 0.649\n",
      "-19: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-19: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-19: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-19: Identity()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-20: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-20: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-20: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-20: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.676\n",
      "-20: ReLU()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-20: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-20: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-20: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-20: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-21: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-21: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-21: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-21: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649\n",
      "-21: ReLU()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-21: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-21: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-21: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-21: Identity()-Identity()-CrossEntropyLoss(): 0.432\n",
      "-22: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-22: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-22: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-22: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.676\n",
      "-22: ReLU()-Identity()-CrossEntropyLoss(): 0.405\n",
      "-22: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-22: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-22: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-22: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-23: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-23: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-23: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.541\n",
      "-23: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-23: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-23: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-23: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-23: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-23: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-24: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-24: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-24: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-24: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649\n",
      "-24: ReLU()-Identity()-CrossEntropyLoss(): 0.622\n",
      "-24: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-24: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-24: Identity()-Softmax(dim=1)-NLLLoss(): 0.919\n",
      "-24: Identity()-Identity()-CrossEntropyLoss(): 0.486\n",
      "-25: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-25: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-25: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.514\n",
      "-25: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-25: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-25: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-25: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-25: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-25: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "----- 5.59 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},]\n",
    "\n",
    "best_accs4 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs4 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=exp['act'], last_act=exp['lact'],\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  K, masks, exp['loss'], device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs4[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs4[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}: {best_val_accs4[j,i]:.3f} ({best_accs4[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}' for exp in EXPS]\n",
    "table_over4 = summary_table(best_accs4, index_name)\n",
    "table4 = summary_table(best_val_accs4, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.028603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.019459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.057205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.588108</td>\n",
       "      <td>0.062235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.602162</td>\n",
       "      <td>0.074712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-NLLLoss()</th>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.872432</td>\n",
       "      <td>0.025946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.022261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.022933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.871351</td>\n",
       "      <td>0.020626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.842162</td>\n",
       "      <td>0.051098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.852973</td>\n",
       "      <td>0.024270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.527568</td>\n",
       "      <td>0.045302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean accs       std\n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()             0.864865  0.028603\n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                      0.863784  0.019459\n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()          0.567568  0.057205\n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                   0.588108  0.062235\n",
       "ReLU()-Identity()-CrossEntropyLoss()                 0.602162  0.074712\n",
       "ReLU()-Identity()-NLLLoss()                          0.405405  0.000000\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()     0.872432  0.025946\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()              0.863784  0.022261\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...   0.864865  0.022933\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...   0.871351  0.020626\n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()         0.842162  0.051098\n",
       "Identity()-Softmax(dim=1)-NLLLoss()                  0.852973  0.024270\n",
       "Identity()-Identity()-CrossEntropyLoss()             0.527568  0.045302"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the GSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 3\n",
    "NORM = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 200-0.1-0.0005: 0.270\n",
      "-1: 200-0.05-0.0005: 0.270\n",
      "-1: 200-0.01-0.0005: 0.270\n",
      "-1: 200-0.005-0.0005: 0.270\n",
      "-1: 200-0.05-0.001: 0.270\n",
      "-1: 200-0.01-0.001: 0.270\n",
      "-1: 200-0.05-0.01: 0.270\n",
      "-1: 200-0.01-0.01: 0.270\n",
      "-1: 200-0.05-0.05: 0.270\n",
      "-1: 200-0.01-0.05: 0.270\n",
      "-1: 500-0.05-0.0005: 0.270\n",
      "-1: 500-0.01-0.0005: 0.270\n",
      "-1: 500-0.05-0.01: 0.270\n",
      "-1: 500-0.01-0.01: 0.270\n",
      "-2: 200-0.1-0.0005: 0.270\n",
      "-2: 200-0.05-0.0005: 0.270\n",
      "-2: 200-0.01-0.0005: 0.270\n",
      "-2: 200-0.005-0.0005: 0.270\n",
      "-2: 200-0.05-0.001: 0.270\n",
      "-2: 200-0.01-0.001: 0.270\n",
      "-2: 200-0.05-0.01: 0.270\n",
      "-2: 200-0.01-0.01: 0.270\n",
      "-2: 200-0.05-0.05: 0.270\n",
      "-2: 200-0.01-0.05: 0.270\n",
      "-2: 500-0.05-0.0005: 0.270\n",
      "-2: 500-0.01-0.0005: 0.270\n",
      "-2: 500-0.05-0.01: 0.270\n",
      "-2: 500-0.01-0.01: 0.270\n",
      "-3: 200-0.1-0.0005: 0.270\n",
      "-3: 200-0.05-0.0005: 0.270\n",
      "-3: 200-0.01-0.0005: 0.270\n",
      "-3: 200-0.005-0.0005: 0.270\n",
      "-3: 200-0.05-0.001: 0.270\n",
      "-3: 200-0.01-0.001: 0.270\n",
      "-3: 200-0.05-0.01: 0.270\n",
      "-3: 200-0.01-0.01: 0.270\n",
      "-3: 200-0.05-0.05: 0.270\n",
      "-3: 200-0.01-0.05: 0.270\n",
      "-3: 500-0.05-0.0005: 0.270\n",
      "-3: 500-0.01-0.0005: 0.270\n",
      "-3: 500-0.05-0.01: 0.270\n",
      "-3: 500-0.01-0.01: 0.270\n",
      "-4: 200-0.1-0.0005: 0.270\n",
      "-4: 200-0.05-0.0005: 0.270\n",
      "-4: 200-0.01-0.0005: 0.270\n",
      "-4: 200-0.005-0.0005: 0.270\n",
      "-4: 200-0.05-0.001: 0.270\n",
      "-4: 200-0.01-0.001: 0.270\n",
      "-4: 200-0.05-0.01: 0.270\n",
      "-4: 200-0.01-0.01: 0.270\n",
      "-4: 200-0.05-0.05: 0.270\n",
      "-4: 200-0.01-0.05: 0.270\n",
      "-4: 500-0.05-0.0005: 0.270\n",
      "-4: 500-0.01-0.0005: 0.270\n",
      "-4: 500-0.05-0.01: 0.270\n",
      "-4: 500-0.01-0.01: 0.270\n",
      "-5: 200-0.1-0.0005: 0.270\n",
      "-5: 200-0.05-0.0005: 0.270\n",
      "-5: 200-0.01-0.0005: 0.270\n",
      "-5: 200-0.005-0.0005: 0.270\n",
      "-5: 200-0.05-0.001: 0.270\n",
      "-5: 200-0.01-0.001: 0.270\n",
      "-5: 200-0.05-0.01: 0.270\n",
      "-5: 200-0.01-0.01: 0.270\n",
      "-5: 200-0.05-0.05: 0.270\n",
      "-5: 200-0.01-0.05: 0.270\n",
      "-5: 500-0.05-0.0005: 0.270\n",
      "-5: 500-0.01-0.0005: 0.270\n",
      "-5: 500-0.05-0.01: 0.270\n",
      "-5: 500-0.01-0.01: 0.270\n",
      "-6: 200-0.1-0.0005: 0.270\n",
      "-6: 200-0.05-0.0005: 0.270\n",
      "-6: 200-0.01-0.0005: 0.270\n",
      "-6: 200-0.005-0.0005: 0.270\n",
      "-6: 200-0.05-0.001: 0.270\n",
      "-6: 200-0.01-0.001: 0.270\n",
      "-6: 200-0.05-0.01: 0.270\n",
      "-6: 200-0.01-0.01: 0.270\n",
      "-6: 200-0.05-0.05: 0.270\n",
      "-6: 200-0.01-0.05: 0.270\n",
      "-6: 500-0.05-0.0005: 0.270\n",
      "-6: 500-0.01-0.0005: 0.270\n",
      "-6: 500-0.05-0.01: 0.270\n",
      "-6: 500-0.01-0.01: 0.270\n",
      "-7: 200-0.1-0.0005: 0.270\n",
      "-7: 200-0.05-0.0005: 0.270\n",
      "-7: 200-0.01-0.0005: 0.270\n",
      "-7: 200-0.005-0.0005: 0.270\n",
      "-7: 200-0.05-0.001: 0.270\n",
      "-7: 200-0.01-0.001: 0.270\n",
      "-7: 200-0.05-0.01: 0.270\n",
      "-7: 200-0.01-0.01: 0.270\n",
      "-7: 200-0.05-0.05: 0.270\n",
      "-7: 200-0.01-0.05: 0.270\n",
      "-7: 500-0.05-0.0005: 0.270\n",
      "-7: 500-0.01-0.0005: 0.270\n",
      "-7: 500-0.05-0.01: 0.270\n",
      "-7: 500-0.01-0.01: 0.270\n",
      "-8: 200-0.1-0.0005: 0.270\n",
      "-8: 200-0.05-0.0005: 0.270\n",
      "-8: 200-0.01-0.0005: 0.270\n",
      "-8: 200-0.005-0.0005: 0.270\n",
      "-8: 200-0.05-0.001: 0.270\n",
      "-8: 200-0.01-0.001: 0.270\n",
      "-8: 200-0.05-0.01: 0.270\n",
      "-8: 200-0.01-0.01: 0.270\n",
      "-8: 200-0.05-0.05: 0.270\n",
      "-8: 200-0.01-0.05: 0.270\n",
      "-8: 500-0.05-0.0005: 0.270\n",
      "-8: 500-0.01-0.0005: 0.270\n",
      "-8: 500-0.05-0.01: 0.270\n",
      "-8: 500-0.01-0.01: 0.270\n",
      "-9: 200-0.1-0.0005: 0.270\n",
      "-9: 200-0.05-0.0005: 0.270\n",
      "-9: 200-0.01-0.0005: 0.270\n",
      "-9: 200-0.005-0.0005: 0.270\n",
      "-9: 200-0.05-0.001: 0.270\n",
      "-9: 200-0.01-0.001: 0.270\n",
      "-9: 200-0.05-0.01: 0.270\n",
      "-9: 200-0.01-0.01: 0.270\n",
      "-9: 200-0.05-0.05: 0.270\n",
      "-9: 200-0.01-0.05: 0.270\n",
      "-9: 500-0.05-0.0005: 0.270\n",
      "-9: 500-0.01-0.0005: 0.270\n",
      "-9: 500-0.05-0.01: 0.270\n",
      "-9: 500-0.01-0.01: 0.270\n",
      "-10: 200-0.1-0.0005: 0.270\n",
      "-10: 200-0.05-0.0005: 0.270\n",
      "-10: 200-0.01-0.0005: 0.270\n",
      "-10: 200-0.005-0.0005: 0.270\n",
      "-10: 200-0.05-0.001: 0.270\n",
      "-10: 200-0.01-0.001: 0.270\n",
      "-10: 200-0.05-0.01: 0.270\n",
      "-10: 200-0.01-0.01: 0.270\n",
      "-10: 200-0.05-0.05: 0.270\n",
      "-10: 200-0.01-0.05: 0.270\n",
      "-10: 500-0.05-0.0005: 0.270\n",
      "-10: 500-0.01-0.0005: 0.270\n",
      "-10: 500-0.05-0.01: 0.270\n",
      "-10: 500-0.01-0.01: 0.270\n",
      "-11: 200-0.1-0.0005: 0.270\n",
      "-11: 200-0.05-0.0005: 0.270\n",
      "-11: 200-0.01-0.0005: 0.270\n",
      "-11: 200-0.005-0.0005: 0.270\n",
      "-11: 200-0.05-0.001: 0.270\n",
      "-11: 200-0.01-0.001: 0.270\n",
      "-11: 200-0.05-0.01: 0.270\n",
      "-11: 200-0.01-0.01: 0.270\n",
      "-11: 200-0.05-0.05: 0.270\n",
      "-11: 200-0.01-0.05: 0.270\n",
      "-11: 500-0.05-0.0005: 0.270\n",
      "-11: 500-0.01-0.0005: 0.270\n",
      "-11: 500-0.05-0.01: 0.270\n",
      "-11: 500-0.01-0.01: 0.270\n",
      "-12: 200-0.1-0.0005: 0.270\n",
      "-12: 200-0.05-0.0005: 0.270\n",
      "-12: 200-0.01-0.0005: 0.270\n",
      "-12: 200-0.005-0.0005: 0.270\n",
      "-12: 200-0.05-0.001: 0.270\n",
      "-12: 200-0.01-0.001: 0.270\n",
      "-12: 200-0.05-0.01: 0.270\n",
      "-12: 200-0.01-0.01: 0.270\n",
      "-12: 200-0.05-0.05: 0.270\n",
      "-12: 200-0.01-0.05: 0.270\n",
      "-12: 500-0.05-0.0005: 0.270\n",
      "-12: 500-0.01-0.0005: 0.270\n",
      "-12: 500-0.05-0.01: 0.270\n",
      "-12: 500-0.01-0.01: 0.270\n",
      "-13: 200-0.1-0.0005: 0.270\n",
      "-13: 200-0.05-0.0005: 0.270\n",
      "-13: 200-0.01-0.0005: 0.270\n",
      "-13: 200-0.005-0.0005: 0.270\n",
      "-13: 200-0.05-0.001: 0.270\n",
      "-13: 200-0.01-0.001: 0.270\n",
      "-13: 200-0.05-0.01: 0.270\n",
      "-13: 200-0.01-0.01: 0.270\n",
      "-13: 200-0.05-0.05: 0.270\n",
      "-13: 200-0.01-0.05: 0.270\n",
      "-13: 500-0.05-0.0005: 0.270\n",
      "-13: 500-0.01-0.0005: 0.270\n",
      "-13: 500-0.05-0.01: 0.270\n",
      "-13: 500-0.01-0.01: 0.270\n",
      "-14: 200-0.1-0.0005: 0.270\n",
      "-14: 200-0.05-0.0005: 0.270\n",
      "-14: 200-0.01-0.0005: 0.270\n",
      "-14: 200-0.005-0.0005: 0.270\n",
      "-14: 200-0.05-0.001: 0.270\n",
      "-14: 200-0.01-0.001: 0.270\n",
      "-14: 200-0.05-0.01: 0.270\n",
      "-14: 200-0.01-0.01: 0.270\n",
      "-14: 200-0.05-0.05: 0.270\n",
      "-14: 200-0.01-0.05: 0.270\n",
      "-14: 500-0.05-0.0005: 0.270\n",
      "-14: 500-0.01-0.0005: 0.270\n",
      "-14: 500-0.05-0.01: 0.270\n",
      "-14: 500-0.01-0.01: 0.270\n",
      "-15: 200-0.1-0.0005: 0.270\n",
      "-15: 200-0.05-0.0005: 0.270\n",
      "-15: 200-0.01-0.0005: 0.270\n",
      "-15: 200-0.005-0.0005: 0.270\n",
      "-15: 200-0.05-0.001: 0.270\n",
      "-15: 200-0.01-0.001: 0.270\n",
      "-15: 200-0.05-0.01: 0.270\n",
      "-15: 200-0.01-0.01: 0.270\n",
      "-15: 200-0.05-0.05: 0.270\n",
      "-15: 200-0.01-0.05: 0.270\n",
      "-15: 500-0.05-0.0005: 0.270\n",
      "-15: 500-0.01-0.0005: 0.270\n",
      "-15: 500-0.05-0.01: 0.270\n",
      "-15: 500-0.01-0.01: 0.270\n",
      "-16: 200-0.1-0.0005: 0.270\n",
      "-16: 200-0.05-0.0005: 0.270\n",
      "-16: 200-0.01-0.0005: 0.270\n",
      "-16: 200-0.005-0.0005: 0.270\n",
      "-16: 200-0.05-0.001: 0.270\n",
      "-16: 200-0.01-0.001: 0.270\n",
      "-16: 200-0.05-0.01: 0.270\n",
      "-16: 200-0.01-0.01: 0.270\n",
      "-16: 200-0.05-0.05: 0.270\n",
      "-16: 200-0.01-0.05: 0.270\n",
      "-16: 500-0.05-0.0005: 0.270\n",
      "-16: 500-0.01-0.0005: 0.270\n",
      "-16: 500-0.05-0.01: 0.270\n",
      "-16: 500-0.01-0.01: 0.270\n",
      "-17: 200-0.1-0.0005: 0.270\n",
      "-17: 200-0.05-0.0005: 0.270\n",
      "-17: 200-0.01-0.0005: 0.270\n",
      "-17: 200-0.005-0.0005: 0.270\n",
      "-17: 200-0.05-0.001: 0.270\n",
      "-17: 200-0.01-0.001: 0.270\n",
      "-17: 200-0.05-0.01: 0.270\n",
      "-17: 200-0.01-0.01: 0.270\n",
      "-17: 200-0.05-0.05: 0.270\n",
      "-17: 200-0.01-0.05: 0.270\n",
      "-17: 500-0.05-0.0005: 0.270\n",
      "-17: 500-0.01-0.0005: 0.270\n",
      "-17: 500-0.05-0.01: 0.270\n",
      "-17: 500-0.01-0.01: 0.270\n",
      "-18: 200-0.1-0.0005: 0.270\n",
      "-18: 200-0.05-0.0005: 0.270\n",
      "-18: 200-0.01-0.0005: 0.270\n",
      "-18: 200-0.005-0.0005: 0.270\n",
      "-18: 200-0.05-0.001: 0.270\n",
      "-18: 200-0.01-0.001: 0.270\n",
      "-18: 200-0.05-0.01: 0.270\n",
      "-18: 200-0.01-0.01: 0.270\n",
      "-18: 200-0.05-0.05: 0.270\n",
      "-18: 200-0.01-0.05: 0.270\n",
      "-18: 500-0.05-0.0005: 0.270\n",
      "-18: 500-0.01-0.0005: 0.270\n",
      "-18: 500-0.05-0.01: 0.270\n",
      "-18: 500-0.01-0.01: 0.270\n",
      "-19: 200-0.1-0.0005: 0.270\n",
      "-19: 200-0.05-0.0005: 0.270\n",
      "-19: 200-0.01-0.0005: 0.270\n",
      "-19: 200-0.005-0.0005: 0.270\n",
      "-19: 200-0.05-0.001: 0.270\n",
      "-19: 200-0.01-0.001: 0.270\n",
      "-19: 200-0.05-0.01: 0.270\n",
      "-19: 200-0.01-0.01: 0.270\n",
      "-19: 200-0.05-0.05: 0.270\n",
      "-19: 200-0.01-0.05: 0.270\n",
      "-19: 500-0.05-0.0005: 0.270\n",
      "-19: 500-0.01-0.0005: 0.270\n",
      "-19: 500-0.05-0.01: 0.270\n",
      "-19: 500-0.01-0.01: 0.270\n",
      "-20: 200-0.1-0.0005: 0.270\n",
      "-20: 200-0.05-0.0005: 0.270\n",
      "-20: 200-0.01-0.0005: 0.270\n",
      "-20: 200-0.005-0.0005: 0.270\n",
      "-20: 200-0.05-0.001: 0.270\n",
      "-20: 200-0.01-0.001: 0.270\n",
      "-20: 200-0.05-0.01: 0.270\n",
      "-20: 200-0.01-0.01: 0.270\n",
      "-20: 200-0.05-0.05: 0.270\n",
      "-20: 200-0.01-0.05: 0.270\n",
      "-20: 500-0.05-0.0005: 0.270\n",
      "-20: 500-0.01-0.0005: 0.270\n",
      "-20: 500-0.05-0.01: 0.270\n",
      "-20: 500-0.01-0.01: 0.270\n",
      "-21: 200-0.1-0.0005: 0.270\n",
      "-21: 200-0.05-0.0005: 0.270\n",
      "-21: 200-0.01-0.0005: 0.270\n",
      "-21: 200-0.005-0.0005: 0.270\n",
      "-21: 200-0.05-0.001: 0.270\n",
      "-21: 200-0.01-0.001: 0.270\n",
      "-21: 200-0.05-0.01: 0.270\n",
      "-21: 200-0.01-0.01: 0.270\n",
      "-21: 200-0.05-0.05: 0.270\n",
      "-21: 200-0.01-0.05: 0.270\n",
      "-21: 500-0.05-0.0005: 0.270\n",
      "-21: 500-0.01-0.0005: 0.270\n",
      "-21: 500-0.05-0.01: 0.270\n",
      "-21: 500-0.01-0.01: 0.270\n",
      "-22: 200-0.1-0.0005: 0.270\n",
      "-22: 200-0.05-0.0005: 0.270\n",
      "-22: 200-0.01-0.0005: 0.270\n",
      "-22: 200-0.005-0.0005: 0.270\n",
      "-22: 200-0.05-0.001: 0.270\n",
      "-22: 200-0.01-0.001: 0.270\n",
      "-22: 200-0.05-0.01: 0.270\n",
      "-22: 200-0.01-0.01: 0.270\n",
      "-22: 200-0.05-0.05: 0.270\n",
      "-22: 200-0.01-0.05: 0.270\n",
      "-22: 500-0.05-0.0005: 0.270\n",
      "-22: 500-0.01-0.0005: 0.270\n",
      "-22: 500-0.05-0.01: 0.270\n",
      "-22: 500-0.01-0.01: 0.270\n",
      "-23: 200-0.1-0.0005: 0.270\n",
      "-23: 200-0.05-0.0005: 0.270\n",
      "-23: 200-0.01-0.0005: 0.270\n",
      "-23: 200-0.005-0.0005: 0.270\n",
      "-23: 200-0.05-0.001: 0.270\n",
      "-23: 200-0.01-0.001: 0.270\n",
      "-23: 200-0.05-0.01: 0.270\n",
      "-23: 200-0.01-0.01: 0.270\n",
      "-23: 200-0.05-0.05: 0.270\n",
      "-23: 200-0.01-0.05: 0.270\n",
      "-23: 500-0.05-0.0005: 0.270\n",
      "-23: 500-0.01-0.0005: 0.270\n",
      "-23: 500-0.05-0.01: 0.270\n",
      "-23: 500-0.01-0.01: 0.270\n",
      "-24: 200-0.1-0.0005: 0.270\n",
      "-24: 200-0.05-0.0005: 0.270\n",
      "-24: 200-0.01-0.0005: 0.270\n",
      "-24: 200-0.005-0.0005: 0.270\n",
      "-24: 200-0.05-0.001: 0.270\n",
      "-24: 200-0.01-0.001: 0.270\n",
      "-24: 200-0.05-0.01: 0.270\n",
      "-24: 200-0.01-0.01: 0.270\n",
      "-24: 200-0.05-0.05: 0.270\n",
      "-24: 200-0.01-0.05: 0.270\n",
      "-24: 500-0.05-0.0005: 0.270\n",
      "-24: 500-0.01-0.0005: 0.270\n",
      "-24: 500-0.05-0.01: 0.270\n",
      "-24: 500-0.01-0.01: 0.270\n",
      "-25: 200-0.1-0.0005: 0.270\n",
      "-25: 200-0.05-0.0005: 0.270\n",
      "-25: 200-0.01-0.0005: 0.270\n",
      "-25: 200-0.005-0.0005: 0.270\n",
      "-25: 200-0.05-0.001: 0.270\n",
      "-25: 200-0.01-0.001: 0.270\n",
      "-25: 200-0.05-0.01: 0.270\n",
      "-25: 200-0.01-0.01: 0.270\n",
      "-25: 200-0.05-0.05: 0.270\n",
      "-25: 200-0.01-0.05: 0.270\n",
      "-25: 500-0.05-0.0005: 0.270\n",
      "-25: 500-0.01-0.0005: 0.270\n",
      "-25: 500-0.05-0.01: 0.270\n",
      "-25: 500-0.01-0.01: 0.270\n",
      "----- 7.61 mins -----\n"
     ]
    }
   ],
   "source": [
    "EXPS = [{'epochs': 200, 'lr': .1, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .001, 'wd': 5e-4, 'drop': 0},\n",
    "        \n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-3, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 1e-3, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 5e-2, 'drop': 0},\n",
    "        \n",
    "        # {'epochs': 500, 'lr': .05, 'wd': 5e-4, 'drop': 0},\n",
    "        # {'epochs': 500, 'lr': .01, 'wd': 5e-4, 'drop': 0},\n",
    "        # {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': 0},\n",
    "        # {'epochs': 500, 'lr': .01, 'wd': 1e-2, 'drop': 0},\n",
    "\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4, 'drop': .25},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4, 'drop': .5},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .25},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .5},\n",
    "        ]\n",
    "\n",
    "best_accs5 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs5 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=exp['drop'], init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'])\n",
    "\n",
    "        best_accs5[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs5[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}: {best_val_accs5[j,i]:.3f} ({best_accs5[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}' for exp in EXPS]\n",
    "table_over5 = summary_table(best_accs5, index_name)\n",
    "table5 = summary_table(best_val_accs5, index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.001</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.001</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.01</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.05</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.05</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.01</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean accs  std\n",
       "200-0.1-0.0005      0.27027  0.0\n",
       "200-0.05-0.0005     0.27027  0.0\n",
       "200-0.01-0.0005     0.27027  0.0\n",
       "200-0.005-0.0005    0.27027  0.0\n",
       "200-0.05-0.001      0.27027  0.0\n",
       "200-0.01-0.001      0.27027  0.0\n",
       "200-0.05-0.01       0.27027  0.0\n",
       "200-0.01-0.01       0.27027  0.0\n",
       "200-0.05-0.05       0.27027  0.0\n",
       "200-0.01-0.05       0.27027  0.0\n",
       "500-0.05-0.0005     0.27027  0.0\n",
       "500-0.01-0.0005     0.27027  0.0\n",
       "500-0.05-0.01       0.27027  0.0\n",
       "500-0.01-0.01       0.27027  0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 0.01-1-1-True: 0.270\n",
      "-1: 0.1-1-1-True: 0.270\n",
      "-1: 1-1-1-True: 0.270\n",
      "-1: 1-1-1-False: 0.270\n",
      "-1: 1-10-1-True: 0.270\n",
      "-1: 1-1-10-True: 0.270\n",
      "-1: 1-10-10-True: 0.270\n",
      "-1: 1-25-25-True: 0.270\n",
      "-1: 1-50-50-True: 0.270\n",
      "-2: 0.01-1-1-True: 0.270\n",
      "-2: 0.1-1-1-True: 0.270\n",
      "-2: 1-1-1-True: 0.270\n",
      "-2: 1-1-1-False: 0.270\n",
      "-2: 1-10-1-True: 0.270\n",
      "-2: 1-1-10-True: 0.270\n",
      "-2: 1-10-10-True: 0.270\n",
      "-2: 1-25-25-True: 0.270\n",
      "-2: 1-50-50-True: 0.270\n",
      "-3: 0.01-1-1-True: 0.270\n",
      "-3: 0.1-1-1-True: 0.270\n",
      "-3: 1-1-1-True: 0.270\n",
      "-3: 1-1-1-False: 0.270\n",
      "-3: 1-10-1-True: 0.270\n",
      "-3: 1-1-10-True: 0.270\n",
      "-3: 1-10-10-True: 0.270\n",
      "-3: 1-25-25-True: 0.270\n",
      "-3: 1-50-50-True: 0.270\n",
      "-4: 0.01-1-1-True: 0.270\n",
      "-4: 0.1-1-1-True: 0.270\n",
      "-4: 1-1-1-True: 0.270\n",
      "-4: 1-1-1-False: 0.270\n",
      "-4: 1-10-1-True: 0.270\n",
      "-4: 1-1-10-True: 0.270\n",
      "-4: 1-10-10-True: 0.270\n",
      "-4: 1-25-25-True: 0.270\n",
      "-4: 1-50-50-True: 0.270\n",
      "-5: 0.01-1-1-True: 0.270\n",
      "-5: 0.1-1-1-True: 0.270\n",
      "-5: 1-1-1-True: 0.270\n",
      "-5: 1-1-1-False: 0.270\n",
      "-5: 1-10-1-True: 0.270\n",
      "-5: 1-1-10-True: 0.270\n",
      "-5: 1-10-10-True: 0.270\n",
      "-5: 1-25-25-True: 0.270\n",
      "-5: 1-50-50-True: 0.270\n",
      "-6: 0.01-1-1-True: 0.270\n",
      "-6: 0.1-1-1-True: 0.270\n",
      "-6: 1-1-1-True: 0.270\n",
      "-6: 1-1-1-False: 0.270\n",
      "-6: 1-10-1-True: 0.270\n",
      "-6: 1-1-10-True: 0.270\n",
      "-6: 1-10-10-True: 0.270\n",
      "-6: 1-25-25-True: 0.270\n",
      "-6: 1-50-50-True: 0.270\n",
      "-7: 0.01-1-1-True: 0.270\n",
      "-7: 0.1-1-1-True: 0.270\n",
      "-7: 1-1-1-True: 0.270\n",
      "-7: 1-1-1-False: 0.270\n",
      "-7: 1-10-1-True: 0.270\n",
      "-7: 1-1-10-True: 0.270\n",
      "-7: 1-10-10-True: 0.270\n",
      "-7: 1-25-25-True: 0.270\n",
      "-7: 1-50-50-True: 0.270\n",
      "-8: 0.01-1-1-True: 0.270\n",
      "-8: 0.1-1-1-True: 0.270\n",
      "-8: 1-1-1-True: 0.270\n",
      "-8: 1-1-1-False: 0.270\n",
      "-8: 1-10-1-True: 0.270\n",
      "-8: 1-1-10-True: 0.270\n",
      "-8: 1-10-10-True: 0.270\n",
      "-8: 1-25-25-True: 0.270\n",
      "-8: 1-50-50-True: 0.270\n",
      "-9: 0.01-1-1-True: 0.270\n",
      "-9: 0.1-1-1-True: 0.270\n",
      "-9: 1-1-1-True: 0.270\n",
      "-9: 1-1-1-False: 0.270\n",
      "-9: 1-10-1-True: 0.270\n",
      "-9: 1-1-10-True: 0.270\n",
      "-9: 1-10-10-True: 0.270\n",
      "-9: 1-25-25-True: 0.270\n",
      "-9: 1-50-50-True: 0.270\n",
      "-10: 0.01-1-1-True: 0.270\n",
      "-10: 0.1-1-1-True: 0.270\n",
      "-10: 1-1-1-True: 0.270\n",
      "-10: 1-1-1-False: 0.270\n",
      "-10: 1-10-1-True: 0.270\n",
      "-10: 1-1-10-True: 0.270\n",
      "-10: 1-10-10-True: 0.270\n",
      "-10: 1-25-25-True: 0.270\n",
      "-10: 1-50-50-True: 0.270\n",
      "-11: 0.01-1-1-True: 0.270\n",
      "-11: 0.1-1-1-True: 0.270\n",
      "-11: 1-1-1-True: 0.270\n",
      "-11: 1-1-1-False: 0.270\n",
      "-11: 1-10-1-True: 0.270\n",
      "-11: 1-1-10-True: 0.270\n",
      "-11: 1-10-10-True: 0.270\n",
      "-11: 1-25-25-True: 0.270\n",
      "-11: 1-50-50-True: 0.270\n",
      "-12: 0.01-1-1-True: 0.270\n",
      "-12: 0.1-1-1-True: 0.270\n",
      "-12: 1-1-1-True: 0.270\n",
      "-12: 1-1-1-False: 0.270\n",
      "-12: 1-10-1-True: 0.270\n",
      "-12: 1-1-10-True: 0.270\n",
      "-12: 1-10-10-True: 0.270\n",
      "-12: 1-25-25-True: 0.270\n",
      "-12: 1-50-50-True: 0.270\n",
      "-13: 0.01-1-1-True: 0.270\n",
      "-13: 0.1-1-1-True: 0.270\n",
      "-13: 1-1-1-True: 0.270\n",
      "-13: 1-1-1-False: 0.270\n",
      "-13: 1-10-1-True: 0.270\n",
      "-13: 1-1-10-True: 0.270\n",
      "-13: 1-10-10-True: 0.270\n",
      "-13: 1-25-25-True: 0.270\n",
      "-13: 1-50-50-True: 0.270\n",
      "-14: 0.01-1-1-True: 0.270\n",
      "-14: 0.1-1-1-True: 0.270\n",
      "-14: 1-1-1-True: 0.270\n",
      "-14: 1-1-1-False: 0.270\n",
      "-14: 1-10-1-True: 0.270\n",
      "-14: 1-1-10-True: 0.270\n",
      "-14: 1-10-10-True: 0.270\n",
      "-14: 1-25-25-True: 0.270\n",
      "-14: 1-50-50-True: 0.270\n",
      "-15: 0.01-1-1-True: 0.270\n",
      "-15: 0.1-1-1-True: 0.270\n",
      "-15: 1-1-1-True: 0.270\n",
      "-15: 1-1-1-False: 0.270\n",
      "-15: 1-10-1-True: 0.270\n",
      "-15: 1-1-10-True: 0.270\n",
      "-15: 1-10-10-True: 0.270\n",
      "-15: 1-25-25-True: 0.270\n",
      "-15: 1-50-50-True: 0.270\n",
      "-16: 0.01-1-1-True: 0.270\n",
      "-16: 0.1-1-1-True: 0.270\n",
      "-16: 1-1-1-True: 0.270\n",
      "-16: 1-1-1-False: 0.270\n",
      "-16: 1-10-1-True: 0.270\n",
      "-16: 1-1-10-True: 0.270\n",
      "-16: 1-10-10-True: 0.270\n",
      "-16: 1-25-25-True: 0.270\n",
      "-16: 1-50-50-True: 0.270\n",
      "-17: 0.01-1-1-True: 0.270\n",
      "-17: 0.1-1-1-True: 0.270\n",
      "-17: 1-1-1-True: 0.270\n",
      "-17: 1-1-1-False: 0.270\n",
      "-17: 1-10-1-True: 0.270\n",
      "-17: 1-1-10-True: 0.270\n",
      "-17: 1-10-10-True: 0.270\n",
      "-17: 1-25-25-True: 0.270\n",
      "-17: 1-50-50-True: 0.270\n",
      "-18: 0.01-1-1-True: 0.270\n",
      "-18: 0.1-1-1-True: 0.270\n",
      "-18: 1-1-1-True: 0.270\n",
      "-18: 1-1-1-False: 0.270\n",
      "-18: 1-10-1-True: 0.270\n",
      "-18: 1-1-10-True: 0.270\n",
      "-18: 1-10-10-True: 0.270\n",
      "-18: 1-25-25-True: 0.270\n",
      "-18: 1-50-50-True: 0.270\n",
      "-19: 0.01-1-1-True: 0.270\n",
      "-19: 0.1-1-1-True: 0.270\n",
      "-19: 1-1-1-True: 0.270\n",
      "-19: 1-1-1-False: 0.270\n",
      "-19: 1-10-1-True: 0.270\n",
      "-19: 1-1-10-True: 0.270\n",
      "-19: 1-10-10-True: 0.270\n",
      "-19: 1-25-25-True: 0.270\n",
      "-19: 1-50-50-True: 0.270\n",
      "-20: 0.01-1-1-True: 0.270\n",
      "-20: 0.1-1-1-True: 0.270\n",
      "-20: 1-1-1-True: 0.270\n",
      "-20: 1-1-1-False: 0.270\n",
      "-20: 1-10-1-True: 0.270\n",
      "-20: 1-1-10-True: 0.270\n",
      "-20: 1-10-10-True: 0.270\n",
      "-20: 1-25-25-True: 0.270\n",
      "-20: 1-50-50-True: 0.270\n",
      "-21: 0.01-1-1-True: 0.270\n",
      "-21: 0.1-1-1-True: 0.270\n",
      "-21: 1-1-1-True: 0.270\n",
      "-21: 1-1-1-False: 0.270\n",
      "-21: 1-10-1-True: 0.270\n",
      "-21: 1-1-10-True: 0.270\n",
      "-21: 1-10-10-True: 0.270\n",
      "-21: 1-25-25-True: 0.270\n",
      "-21: 1-50-50-True: 0.270\n",
      "-22: 0.01-1-1-True: 0.270\n",
      "-22: 0.1-1-1-True: 0.270\n",
      "-22: 1-1-1-True: 0.270\n",
      "-22: 1-1-1-False: 0.270\n",
      "-22: 1-10-1-True: 0.270\n",
      "-22: 1-1-10-True: 0.270\n",
      "-22: 1-10-10-True: 0.270\n",
      "-22: 1-25-25-True: 0.270\n",
      "-22: 1-50-50-True: 0.270\n",
      "-23: 0.01-1-1-True: 0.270\n",
      "-23: 0.1-1-1-True: 0.270\n",
      "-23: 1-1-1-True: 0.270\n",
      "-23: 1-1-1-False: 0.270\n",
      "-23: 1-10-1-True: 0.270\n",
      "-23: 1-1-10-True: 0.270\n",
      "-23: 1-10-10-True: 0.270\n",
      "-23: 1-25-25-True: 0.270\n",
      "-23: 1-50-50-True: 0.270\n",
      "-24: 0.01-1-1-True: 0.270\n",
      "-24: 0.1-1-1-True: 0.270\n",
      "-24: 1-1-1-True: 0.270\n",
      "-24: 1-1-1-False: 0.270\n",
      "-24: 1-10-1-True: 0.270\n",
      "-24: 1-1-10-True: 0.270\n",
      "-24: 1-10-10-True: 0.270\n",
      "-24: 1-25-25-True: 0.270\n",
      "-24: 1-50-50-True: 0.270\n",
      "-25: 0.01-1-1-True: 0.270\n",
      "-25: 0.1-1-1-True: 0.270\n",
      "-25: 1-1-1-True: 0.270\n",
      "-25: 1-1-1-False: 0.270\n",
      "-25: 1-10-1-True: 0.270\n",
      "-25: 1-1-10-True: 0.270\n",
      "-25: 1-10-10-True: 0.270\n",
      "-25: 1-25-25-True: 0.270\n",
      "-25: 1-50-50-True: 0.270\n",
      "----- 31.27 mins -----\n"
     ]
    }
   ],
   "source": [
    "# h0, norm (norm, not norm, norm H), sep vs joint training, optimizers iters (W vs h)\n",
    "EXPS = [{'h0': .001, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        \n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 50, 'epochs_h': 50, 'epochs_W': 50, 'alt': True},]\n",
    "\n",
    "\n",
    "best_accs6 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs6 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=exp['h0'])\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        if not exp['alt']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S,  K, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD, epochs_h=exp['epochs_h'],\n",
    "                                 epochs_W=exp['epochs_W'])\n",
    "\n",
    "        best_accs6[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs6[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}: {best_val_accs6[j,i]:.3f} ({best_accs6[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}' for exp in EXPS]\n",
    "table_over6 = summary_table(best_accs6, index_name)\n",
    "table6 = summary_table(best_val_accs6, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25: 0.01-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 0.1-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-1-1-False</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-10-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-1-10-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-10-10-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-25-25-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-50-50-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean accs  std\n",
       "25: 0.01-1-1-True    0.27027  0.0\n",
       "25: 0.1-1-1-True     0.27027  0.0\n",
       "25: 1-1-1-True       0.27027  0.0\n",
       "25: 1-1-1-False      0.27027  0.0\n",
       "25: 1-10-1-True      0.27027  0.0\n",
       "25: 1-1-10-True      0.27027  0.0\n",
       "25: 1-10-10-True     0.27027  0.0\n",
       "25: 1-25-25-True     0.27027  0.0\n",
       "25: 1-50-50-True     0.27027  0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 2-2-16: 0.270\n",
      "-1: 2-3-16: 0.270\n",
      "-1: 2-4-16: 0.270\n",
      "-1: 3-2-16: 0.270\n",
      "-1: 4-2-16: 0.270\n",
      "-1: 3-3-16: 0.270\n",
      "-1: 4-3-16: 0.270\n",
      "-1: 2-2-8: 0.270\n",
      "-1: 2-2-32: 0.270\n",
      "-1: 2-2-50: 0.270\n",
      "-1: 2-3-8: 0.270\n",
      "-1: 2-3-32: 0.270\n",
      "-1: 2-3-50: 0.270\n",
      "-1: 3-2-8: 0.270\n",
      "-1: 3-2-32: 0.270\n",
      "-1: 3-2-50: 0.270\n",
      "-1: 3-3-8: 0.270\n",
      "-1: 3-3-32: 0.270\n",
      "-1: 3-3-50: 0.270\n",
      "-2: 2-2-16: 0.270\n",
      "-2: 2-3-16: 0.270\n",
      "-2: 2-4-16: 0.270\n",
      "-2: 3-2-16: 0.270\n",
      "-2: 4-2-16: 0.270\n",
      "-2: 3-3-16: 0.270\n",
      "-2: 4-3-16: 0.270\n",
      "-2: 2-2-8: 0.270\n",
      "-2: 2-2-32: 0.270\n",
      "-2: 2-2-50: 0.270\n",
      "-2: 2-3-8: 0.270\n",
      "-2: 2-3-32: 0.270\n",
      "-2: 2-3-50: 0.270\n",
      "-2: 3-2-8: 0.270\n",
      "-2: 3-2-32: 0.270\n",
      "-2: 3-2-50: 0.270\n",
      "-2: 3-3-8: 0.270\n",
      "-2: 3-3-32: 0.270\n",
      "-2: 3-3-50: 0.270\n",
      "-3: 2-2-16: 0.270\n",
      "-3: 2-3-16: 0.270\n",
      "-3: 2-4-16: 0.270\n",
      "-3: 3-2-16: 0.270\n",
      "-3: 4-2-16: 0.270\n",
      "-3: 3-3-16: 0.270\n",
      "-3: 4-3-16: 0.270\n",
      "-3: 2-2-8: 0.270\n",
      "-3: 2-2-32: 0.270\n",
      "-3: 2-2-50: 0.270\n",
      "-3: 2-3-8: 0.270\n",
      "-3: 2-3-32: 0.270\n",
      "-3: 2-3-50: 0.270\n",
      "-3: 3-2-8: 0.270\n",
      "-3: 3-2-32: 0.270\n",
      "-3: 3-2-50: 0.270\n",
      "-3: 3-3-8: 0.270\n",
      "-3: 3-3-32: 0.270\n",
      "-3: 3-3-50: 0.270\n",
      "-4: 2-2-16: 0.270\n",
      "-4: 2-3-16: 0.270\n",
      "-4: 2-4-16: 0.270\n",
      "-4: 3-2-16: 0.270\n",
      "-4: 4-2-16: 0.270\n",
      "-4: 3-3-16: 0.270\n",
      "-4: 4-3-16: 0.270\n",
      "-4: 2-2-8: 0.270\n",
      "-4: 2-2-32: 0.270\n",
      "-4: 2-2-50: 0.270\n",
      "-4: 2-3-8: 0.270\n",
      "-4: 2-3-32: 0.270\n",
      "-4: 2-3-50: 0.270\n",
      "-4: 3-2-8: 0.270\n",
      "-4: 3-2-32: 0.270\n",
      "-4: 3-2-50: 0.270\n",
      "-4: 3-3-8: 0.270\n",
      "-4: 3-3-32: 0.270\n",
      "-4: 3-3-50: 0.270\n",
      "-5: 2-2-16: 0.270\n",
      "-5: 2-3-16: 0.270\n",
      "-5: 2-4-16: 0.270\n",
      "-5: 3-2-16: 0.270\n",
      "-5: 4-2-16: 0.270\n",
      "-5: 3-3-16: 0.270\n",
      "-5: 4-3-16: 0.270\n",
      "-5: 2-2-8: 0.270\n",
      "-5: 2-2-32: 0.270\n",
      "-5: 2-2-50: 0.270\n",
      "-5: 2-3-8: 0.270\n",
      "-5: 2-3-32: 0.270\n",
      "-5: 2-3-50: 0.270\n",
      "-5: 3-2-8: 0.270\n",
      "-5: 3-2-32: 0.270\n",
      "-5: 3-2-50: 0.270\n",
      "-5: 3-3-8: 0.270\n",
      "-5: 3-3-32: 0.270\n",
      "-5: 3-3-50: 0.270\n",
      "-6: 2-2-16: 0.270\n",
      "-6: 2-3-16: 0.270\n",
      "-6: 2-4-16: 0.270\n",
      "-6: 3-2-16: 0.270\n",
      "-6: 4-2-16: 0.270\n",
      "-6: 3-3-16: 0.270\n",
      "-6: 4-3-16: 0.270\n",
      "-6: 2-2-8: 0.270\n",
      "-6: 2-2-32: 0.270\n",
      "-6: 2-2-50: 0.270\n",
      "-6: 2-3-8: 0.270\n",
      "-6: 2-3-32: 0.270\n",
      "-6: 2-3-50: 0.270\n",
      "-6: 3-2-8: 0.270\n",
      "-6: 3-2-32: 0.270\n",
      "-6: 3-2-50: 0.270\n",
      "-6: 3-3-8: 0.270\n",
      "-6: 3-3-32: 0.270\n",
      "-6: 3-3-50: 0.270\n",
      "-7: 2-2-16: 0.270\n",
      "-7: 2-3-16: 0.270\n",
      "-7: 2-4-16: 0.270\n",
      "-7: 3-2-16: 0.270\n",
      "-7: 4-2-16: 0.270\n",
      "-7: 3-3-16: 0.270\n",
      "-7: 4-3-16: 0.270\n",
      "-7: 2-2-8: 0.270\n",
      "-7: 2-2-32: 0.270\n",
      "-7: 2-2-50: 0.270\n",
      "-7: 2-3-8: 0.270\n",
      "-7: 2-3-32: 0.270\n",
      "-7: 2-3-50: 0.270\n",
      "-7: 3-2-8: 0.270\n",
      "-7: 3-2-32: 0.270\n",
      "-7: 3-2-50: 0.270\n",
      "-7: 3-3-8: 0.270\n",
      "-7: 3-3-32: 0.270\n",
      "-7: 3-3-50: 0.270\n",
      "-8: 2-2-16: 0.270\n",
      "-8: 2-3-16: 0.270\n",
      "-8: 2-4-16: 0.270\n",
      "-8: 3-2-16: 0.270\n",
      "-8: 4-2-16: 0.270\n",
      "-8: 3-3-16: 0.270\n",
      "-8: 4-3-16: 0.270\n",
      "-8: 2-2-8: 0.270\n",
      "-8: 2-2-32: 0.270\n",
      "-8: 2-2-50: 0.270\n",
      "-8: 2-3-8: 0.270\n",
      "-8: 2-3-32: 0.270\n",
      "-8: 2-3-50: 0.270\n",
      "-8: 3-2-8: 0.270\n",
      "-8: 3-2-32: 0.270\n",
      "-8: 3-2-50: 0.270\n",
      "-8: 3-3-8: 0.270\n",
      "-8: 3-3-32: 0.270\n",
      "-8: 3-3-50: 0.270\n",
      "-9: 2-2-16: 0.270\n",
      "-9: 2-3-16: 0.270\n",
      "-9: 2-4-16: 0.270\n",
      "-9: 3-2-16: 0.270\n",
      "-9: 4-2-16: 0.270\n",
      "-9: 3-3-16: 0.270\n",
      "-9: 4-3-16: 0.270\n",
      "-9: 2-2-8: 0.270\n",
      "-9: 2-2-32: 0.270\n",
      "-9: 2-2-50: 0.270\n",
      "-9: 2-3-8: 0.270\n",
      "-9: 2-3-32: 0.270\n",
      "-9: 2-3-50: 0.270\n",
      "-9: 3-2-8: 0.270\n",
      "-9: 3-2-32: 0.270\n",
      "-9: 3-2-50: 0.270\n",
      "-9: 3-3-8: 0.270\n",
      "-9: 3-3-32: 0.270\n",
      "-9: 3-3-50: 0.270\n",
      "-10: 2-2-16: 0.270\n",
      "-10: 2-3-16: 0.270\n",
      "-10: 2-4-16: 0.270\n",
      "-10: 3-2-16: 0.270\n",
      "-10: 4-2-16: 0.270\n",
      "-10: 3-3-16: 0.270\n",
      "-10: 4-3-16: 0.270\n",
      "-10: 2-2-8: 0.270\n",
      "-10: 2-2-32: 0.270\n",
      "-10: 2-2-50: 0.270\n",
      "-10: 2-3-8: 0.270\n",
      "-10: 2-3-32: 0.270\n",
      "-10: 2-3-50: 0.270\n",
      "-10: 3-2-8: 0.270\n",
      "-10: 3-2-32: 0.270\n",
      "-10: 3-2-50: 0.270\n",
      "-10: 3-3-8: 0.270\n",
      "-10: 3-3-32: 0.270\n",
      "-10: 3-3-50: 0.270\n",
      "-11: 2-2-16: 0.270\n",
      "-11: 2-3-16: 0.270\n",
      "-11: 2-4-16: 0.270\n",
      "-11: 3-2-16: 0.270\n",
      "-11: 4-2-16: 0.270\n",
      "-11: 3-3-16: 0.270\n",
      "-11: 4-3-16: 0.270\n",
      "-11: 2-2-8: 0.270\n",
      "-11: 2-2-32: 0.270\n",
      "-11: 2-2-50: 0.270\n",
      "-11: 2-3-8: 0.270\n",
      "-11: 2-3-32: 0.270\n",
      "-11: 2-3-50: 0.270\n",
      "-11: 3-2-8: 0.270\n",
      "-11: 3-2-32: 0.270\n",
      "-11: 3-2-50: 0.270\n",
      "-11: 3-3-8: 0.270\n",
      "-11: 3-3-32: 0.270\n",
      "-11: 3-3-50: 0.270\n",
      "-12: 2-2-16: 0.270\n",
      "-12: 2-3-16: 0.270\n",
      "-12: 2-4-16: 0.270\n",
      "-12: 3-2-16: 0.270\n",
      "-12: 4-2-16: 0.270\n",
      "-12: 3-3-16: 0.270\n",
      "-12: 4-3-16: 0.270\n",
      "-12: 2-2-8: 0.270\n",
      "-12: 2-2-32: 0.270\n",
      "-12: 2-2-50: 0.270\n",
      "-12: 2-3-8: 0.270\n",
      "-12: 2-3-32: 0.270\n",
      "-12: 2-3-50: 0.270\n",
      "-12: 3-2-8: 0.270\n",
      "-12: 3-2-32: 0.270\n",
      "-12: 3-2-50: 0.270\n",
      "-12: 3-3-8: 0.270\n",
      "-12: 3-3-32: 0.270\n",
      "-12: 3-3-50: 0.270\n",
      "-13: 2-2-16: 0.270\n",
      "-13: 2-3-16: 0.270\n",
      "-13: 2-4-16: 0.270\n",
      "-13: 3-2-16: 0.270\n",
      "-13: 4-2-16: 0.270\n",
      "-13: 3-3-16: 0.270\n",
      "-13: 4-3-16: 0.270\n",
      "-13: 2-2-8: 0.270\n",
      "-13: 2-2-32: 0.270\n",
      "-13: 2-2-50: 0.270\n",
      "-13: 2-3-8: 0.270\n",
      "-13: 2-3-32: 0.270\n",
      "-13: 2-3-50: 0.270\n",
      "-13: 3-2-8: 0.270\n",
      "-13: 3-2-32: 0.270\n",
      "-13: 3-2-50: 0.270\n",
      "-13: 3-3-8: 0.270\n",
      "-13: 3-3-32: 0.270\n",
      "-13: 3-3-50: 0.270\n",
      "-14: 2-2-16: 0.270\n",
      "-14: 2-3-16: 0.270\n",
      "-14: 2-4-16: 0.270\n",
      "-14: 3-2-16: 0.270\n",
      "-14: 4-2-16: 0.270\n",
      "-14: 3-3-16: 0.270\n",
      "-14: 4-3-16: 0.270\n",
      "-14: 2-2-8: 0.270\n",
      "-14: 2-2-32: 0.270\n",
      "-14: 2-2-50: 0.270\n",
      "-14: 2-3-8: 0.270\n",
      "-14: 2-3-32: 0.270\n",
      "-14: 2-3-50: 0.270\n",
      "-14: 3-2-8: 0.270\n",
      "-14: 3-2-32: 0.270\n",
      "-14: 3-2-50: 0.270\n",
      "-14: 3-3-8: 0.270\n",
      "-14: 3-3-32: 0.270\n",
      "-14: 3-3-50: 0.270\n",
      "-15: 2-2-16: 0.270\n",
      "-15: 2-3-16: 0.270\n",
      "-15: 2-4-16: 0.270\n",
      "-15: 3-2-16: 0.270\n",
      "-15: 4-2-16: 0.270\n",
      "-15: 3-3-16: 0.270\n",
      "-15: 4-3-16: 0.270\n",
      "-15: 2-2-8: 0.270\n",
      "-15: 2-2-32: 0.270\n",
      "-15: 2-2-50: 0.270\n",
      "-15: 2-3-8: 0.270\n",
      "-15: 2-3-32: 0.270\n",
      "-15: 2-3-50: 0.270\n",
      "-15: 3-2-8: 0.270\n",
      "-15: 3-2-32: 0.270\n",
      "-15: 3-2-50: 0.270\n",
      "-15: 3-3-8: 0.270\n",
      "-15: 3-3-32: 0.270\n",
      "-15: 3-3-50: 0.270\n",
      "-16: 2-2-16: 0.270\n",
      "-16: 2-3-16: 0.270\n",
      "-16: 2-4-16: 0.270\n",
      "-16: 3-2-16: 0.270\n",
      "-16: 4-2-16: 0.270\n",
      "-16: 3-3-16: 0.270\n",
      "-16: 4-3-16: 0.270\n",
      "-16: 2-2-8: 0.270\n",
      "-16: 2-2-32: 0.270\n",
      "-16: 2-2-50: 0.270\n",
      "-16: 2-3-8: 0.270\n",
      "-16: 2-3-32: 0.270\n",
      "-16: 2-3-50: 0.270\n",
      "-16: 3-2-8: 0.270\n",
      "-16: 3-2-32: 0.270\n",
      "-16: 3-2-50: 0.270\n",
      "-16: 3-3-8: 0.270\n",
      "-16: 3-3-32: 0.270\n",
      "-16: 3-3-50: 0.270\n",
      "-17: 2-2-16: 0.270\n",
      "-17: 2-3-16: 0.270\n",
      "-17: 2-4-16: 0.270\n",
      "-17: 3-2-16: 0.270\n",
      "-17: 4-2-16: 0.270\n",
      "-17: 3-3-16: 0.270\n",
      "-17: 4-3-16: 0.270\n",
      "-17: 2-2-8: 0.270\n",
      "-17: 2-2-32: 0.270\n",
      "-17: 2-2-50: 0.270\n",
      "-17: 2-3-8: 0.270\n",
      "-17: 2-3-32: 0.270\n",
      "-17: 2-3-50: 0.270\n",
      "-17: 3-2-8: 0.270\n",
      "-17: 3-2-32: 0.270\n",
      "-17: 3-2-50: 0.270\n",
      "-17: 3-3-8: 0.270\n",
      "-17: 3-3-32: 0.270\n",
      "-17: 3-3-50: 0.270\n",
      "-18: 2-2-16: 0.270\n",
      "-18: 2-3-16: 0.270\n",
      "-18: 2-4-16: 0.270\n",
      "-18: 3-2-16: 0.270\n",
      "-18: 4-2-16: 0.270\n",
      "-18: 3-3-16: 0.270\n",
      "-18: 4-3-16: 0.270\n",
      "-18: 2-2-8: 0.270\n",
      "-18: 2-2-32: 0.270\n",
      "-18: 2-2-50: 0.270\n",
      "-18: 2-3-8: 0.270\n",
      "-18: 2-3-32: 0.270\n",
      "-18: 2-3-50: 0.270\n",
      "-18: 3-2-8: 0.270\n",
      "-18: 3-2-32: 0.270\n",
      "-18: 3-2-50: 0.270\n",
      "-18: 3-3-8: 0.270\n",
      "-18: 3-3-32: 0.270\n",
      "-18: 3-3-50: 0.270\n",
      "-19: 2-2-16: 0.270\n",
      "-19: 2-3-16: 0.270\n",
      "-19: 2-4-16: 0.270\n",
      "-19: 3-2-16: 0.270\n",
      "-19: 4-2-16: 0.270\n",
      "-19: 3-3-16: 0.270\n",
      "-19: 4-3-16: 0.270\n",
      "-19: 2-2-8: 0.270\n",
      "-19: 2-2-32: 0.270\n",
      "-19: 2-2-50: 0.270\n",
      "-19: 2-3-8: 0.270\n",
      "-19: 2-3-32: 0.270\n",
      "-19: 2-3-50: 0.270\n",
      "-19: 3-2-8: 0.270\n",
      "-19: 3-2-32: 0.270\n",
      "-19: 3-2-50: 0.270\n",
      "-19: 3-3-8: 0.270\n",
      "-19: 3-3-32: 0.270\n",
      "-19: 3-3-50: 0.270\n",
      "-20: 2-2-16: 0.270\n",
      "-20: 2-3-16: 0.270\n",
      "-20: 2-4-16: 0.270\n",
      "-20: 3-2-16: 0.270\n",
      "-20: 4-2-16: 0.270\n",
      "-20: 3-3-16: 0.270\n",
      "-20: 4-3-16: 0.270\n",
      "-20: 2-2-8: 0.270\n",
      "-20: 2-2-32: 0.270\n",
      "-20: 2-2-50: 0.270\n",
      "-20: 2-3-8: 0.270\n",
      "-20: 2-3-32: 0.270\n",
      "-20: 2-3-50: 0.270\n",
      "-20: 3-2-8: 0.270\n",
      "-20: 3-2-32: 0.270\n",
      "-20: 3-2-50: 0.270\n",
      "-20: 3-3-8: 0.270\n",
      "-20: 3-3-32: 0.270\n",
      "-20: 3-3-50: 0.270\n",
      "-21: 2-2-16: 0.270\n",
      "-21: 2-3-16: 0.270\n",
      "-21: 2-4-16: 0.270\n",
      "-21: 3-2-16: 0.270\n",
      "-21: 4-2-16: 0.270\n",
      "-21: 3-3-16: 0.270\n",
      "-21: 4-3-16: 0.270\n",
      "-21: 2-2-8: 0.270\n",
      "-21: 2-2-32: 0.270\n",
      "-21: 2-2-50: 0.270\n",
      "-21: 2-3-8: 0.270\n",
      "-21: 2-3-32: 0.270\n",
      "-21: 2-3-50: 0.270\n",
      "-21: 3-2-8: 0.270\n",
      "-21: 3-2-32: 0.270\n",
      "-21: 3-2-50: 0.270\n",
      "-21: 3-3-8: 0.270\n",
      "-21: 3-3-32: 0.270\n",
      "-21: 3-3-50: 0.270\n",
      "-22: 2-2-16: 0.270\n",
      "-22: 2-3-16: 0.270\n",
      "-22: 2-4-16: 0.270\n",
      "-22: 3-2-16: 0.270\n",
      "-22: 4-2-16: 0.270\n",
      "-22: 3-3-16: 0.270\n",
      "-22: 4-3-16: 0.270\n",
      "-22: 2-2-8: 0.270\n",
      "-22: 2-2-32: 0.270\n",
      "-22: 2-2-50: 0.270\n",
      "-22: 2-3-8: 0.270\n",
      "-22: 2-3-32: 0.270\n",
      "-22: 2-3-50: 0.270\n",
      "-22: 3-2-8: 0.270\n",
      "-22: 3-2-32: 0.270\n",
      "-22: 3-2-50: 0.270\n",
      "-22: 3-3-8: 0.270\n",
      "-22: 3-3-32: 0.270\n",
      "-22: 3-3-50: 0.270\n",
      "-23: 2-2-16: 0.270\n",
      "-23: 2-3-16: 0.270\n",
      "-23: 2-4-16: 0.270\n",
      "-23: 3-2-16: 0.270\n",
      "-23: 4-2-16: 0.270\n",
      "-23: 3-3-16: 0.270\n",
      "-23: 4-3-16: 0.270\n",
      "-23: 2-2-8: 0.270\n",
      "-23: 2-2-32: 0.270\n",
      "-23: 2-2-50: 0.270\n",
      "-23: 2-3-8: 0.270\n",
      "-23: 2-3-32: 0.270\n",
      "-23: 2-3-50: 0.270\n",
      "-23: 3-2-8: 0.270\n",
      "-23: 3-2-32: 0.270\n",
      "-23: 3-2-50: 0.270\n",
      "-23: 3-3-8: 0.270\n",
      "-23: 3-3-32: 0.270\n",
      "-23: 3-3-50: 0.270\n",
      "-24: 2-2-16: 0.270\n",
      "-24: 2-3-16: 0.270\n",
      "-24: 2-4-16: 0.270\n",
      "-24: 3-2-16: 0.270\n",
      "-24: 4-2-16: 0.270\n",
      "-24: 3-3-16: 0.270\n",
      "-24: 4-3-16: 0.270\n",
      "-24: 2-2-8: 0.270\n",
      "-24: 2-2-32: 0.270\n",
      "-24: 2-2-50: 0.270\n",
      "-24: 2-3-8: 0.270\n",
      "-24: 2-3-32: 0.270\n",
      "-24: 2-3-50: 0.270\n",
      "-24: 3-2-8: 0.270\n",
      "-24: 3-2-32: 0.270\n",
      "-24: 3-2-50: 0.270\n",
      "-24: 3-3-8: 0.270\n",
      "-24: 3-3-32: 0.270\n",
      "-24: 3-3-50: 0.270\n",
      "-25: 2-2-16: 0.270\n",
      "-25: 2-3-16: 0.270\n",
      "-25: 2-4-16: 0.270\n",
      "-25: 3-2-16: 0.270\n",
      "-25: 4-2-16: 0.270\n",
      "-25: 3-3-16: 0.270\n",
      "-25: 4-3-16: 0.270\n",
      "-25: 2-2-8: 0.270\n",
      "-25: 2-2-32: 0.270\n",
      "-25: 2-2-50: 0.270\n",
      "-25: 2-3-8: 0.270\n",
      "-25: 2-3-32: 0.270\n",
      "-25: 2-3-50: 0.270\n",
      "-25: 3-2-8: 0.270\n",
      "-25: 3-2-32: 0.270\n",
      "-25: 3-2-50: 0.270\n",
      "-25: 3-3-8: 0.270\n",
      "-25: 3-3-32: 0.270\n",
      "-25: 3-3-50: 0.270\n",
      "----- 9.20 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'L': 2, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 4, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 3, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 50},\n",
    "        ]\n",
    "\n",
    "best_accs7 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs7 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, exp['hid_dim'], OUT_DIM, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  exp['K'], masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs7[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs7[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}: {best_val_accs7[j,i]:.3f} ({best_accs7[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}' for exp in EXPS]\n",
    "table_over7 = summary_table(best_accs7, index_name)\n",
    "table7 = summary_table(best_val_accs7, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-2-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-4-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-3-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean accs  std\n",
       "2-2-16    0.27027  0.0\n",
       "2-3-16    0.27027  0.0\n",
       "2-4-16    0.27027  0.0\n",
       "3-2-16    0.27027  0.0\n",
       "4-2-16    0.27027  0.0\n",
       "3-3-16    0.27027  0.0\n",
       "4-3-16    0.27027  0.0\n",
       "2-2-8     0.27027  0.0\n",
       "2-2-32    0.27027  0.0\n",
       "2-2-50    0.27027  0.0\n",
       "2-3-8     0.27027  0.0\n",
       "2-3-32    0.27027  0.0\n",
       "2-3-50    0.27027  0.0\n",
       "3-2-8     0.27027  0.0\n",
       "3-2-32    0.27027  0.0\n",
       "3-2-50    0.27027  0.0\n",
       "3-3-8     0.27027  0.0\n",
       "3-3-32    0.27027  0.0\n",
       "3-3-50    0.27027  0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearities and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-1: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-2: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-2: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-3: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-3: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-4: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-4: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-5: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-5: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-6: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-6: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-7: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-7: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-8: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-8: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-9: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-9: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-10: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-10: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-11: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-11: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-12: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-12: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-13: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-13: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-14: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-14: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-15: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-15: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-16: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-16: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-17: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-17: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-18: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-18: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-19: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-19: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-20: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-20: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-21: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-21: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-22: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-22: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-23: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-23: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-24: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-24: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-25: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-25: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "----- 4.87 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},]\n",
    "\n",
    "best_accs8 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs8 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=exp['act'], last_act=exp['lact'],\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  K, masks, exp['loss'], device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs8[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs8[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}: {best_val_accs8[j,i]:.3f} ({best_accs8[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}' for exp in EXPS]\n",
    "table_over8 = summary_table(best_accs8, index_name)\n",
    "table8 = summary_table(best_val_accs8, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean accs  std\n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()              0.27027  0.0\n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                       0.27027  0.0\n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()           0.27027  0.0\n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                    0.27027  0.0\n",
       "ReLU()-Identity()-CrossEntropyLoss()                  0.27027  0.0\n",
       "ReLU()-Identity()-NLLLoss()                           0.27027  0.0\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()      0.27027  0.0\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()               0.27027  0.0\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...    0.27027  0.0\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...    0.27027  0.0\n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()          0.27027  0.0\n",
       "Identity()-Softmax(dim=1)-NLLLoss()                   0.27027  0.0\n",
       "Identity()-Identity()-CrossEntropyLoss()              0.27027  0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPS = [\n",
    "        {'name': 'Kipf', 'norm': 'none'},\n",
    "        {'name': 'Kipf', 'norm': 'both'},\n",
    "\n",
    "        {'name': 'A-GCNN', 'norm': False},\n",
    "        {'name': 'A-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'H-GCNN', 'norm': False}, # This should be the same as A-GCNN not norm\n",
    "        {'name': 'H-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'W-GCN-A', 'norm': False},\n",
    "        {'name': 'W-GCN-A', 'norm': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RUN: 1\n",
      "\tKipf-none: acc = 0.459\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.838\n",
      "\tH-GCNN-True: acc = 0.892\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 2\n",
      "\tKipf-none: acc = 0.405\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 3\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 4\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.838\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 5\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 6\n",
      "\tKipf-none: acc = 0.514\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.838\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.919\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 7\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 8\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.676\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.784\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 9\n",
      "\tKipf-none: acc = 0.459\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.838\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 10\n",
      "\tKipf-none: acc = 0.459\n",
      "\tKipf-both: acc = 0.676\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 11\n",
      "\tKipf-none: acc = 0.405\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.811\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 12\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.892\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 13\n",
      "\tKipf-none: acc = 0.514\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.838\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 14\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.838\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.892\n",
      "\tW-GCN-A-False: acc = 0.838\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 15\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.784\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 16\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 17\n",
      "\tKipf-none: acc = 0.405\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.838\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 18\n",
      "\tKipf-none: acc = 0.459\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.811\n",
      "\tW-GCN-A-False: acc = 0.919\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 19\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.838\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 20\n",
      "\tKipf-none: acc = 0.405\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.919\n",
      "\tH-GCNN-True: acc = 0.703\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 21\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.838\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.919\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 22\n",
      "\tKipf-none: acc = 0.514\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.811\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 23\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 24\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.730\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 25\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.676\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.811\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n"
     ]
    }
   ],
   "source": [
    "N_RUNS = 25\n",
    "\n",
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "for i in range(N_RUNS):\n",
    "    print(f'- RUN: {i+1}')\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        # t_i = time.time()\n",
    "        if exp['name'] == 'Kipf':\n",
    "            arch = GCNN_2L(IN_DIM, HID_DIM, OUT_DIM, act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=exp['norm'])\n",
    "            S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "            \n",
    "        elif exp['name'] == 'A-GCNN':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "            dropout=DROPOUT, diff_layer=GFGCNLayer, init_h0=h0)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'H-GCNN':\n",
    "            arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=DROPOUT, norm=exp['norm'], dev=device)\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'W-GCN-A':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=DROPOUT, diff_layer=GFGCN_noh_Layer)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)  \n",
    "            \n",
    "        else:\n",
    "            raise Exception(f'ERROR: Unknown architecture: {exp[\"name\"]}')\n",
    "\n",
    "        if exp['name'] in ['Kipf', 'W-GCN-A']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "\n",
    "        loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'\\t{exp[\"name\"]}-{exp[\"norm\"]}: acc = {best_val_accs[j,i]:.3f}  -  acc (over) = {best_accs[j,i]:.3f}')\n",
    "\n",
    "\n",
    "# Print results\n",
    "index_name = [f'{exp[\"name\"]}-{exp[\"norm\"]}' for exp in EXPS]\n",
    "table_comp_over = summary_table(best_accs, index_name)\n",
    "table_comp = summary_table(best_val_accs, index_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kipf-none</th>\n",
       "      <td>0.436757</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.036405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kipf-both</th>\n",
       "      <td>0.628108</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.015815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-False</th>\n",
       "      <td>0.855135</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.016887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-False</th>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.020682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-True</th>\n",
       "      <td>0.796757</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.060250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-False</th>\n",
       "      <td>0.836757</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.029089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean accs  med accs       std\n",
       "Kipf-none       0.436757  0.432432  0.036405\n",
       "Kipf-both       0.628108  0.621622  0.015815\n",
       "A-GCNN-False    0.855135  0.864865  0.016887\n",
       "A-GCNN-True     0.270270  0.270270  0.000000\n",
       "H-GCNN-False    0.861622  0.864865  0.020682\n",
       "H-GCNN-True     0.796757  0.810811  0.060250\n",
       "W-GCN-A-False   0.836757  0.837838  0.029089\n",
       "W-GCN-A-True    0.270270  0.270270  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_comp_over"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9c21115890>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import utils\n",
    "from gsp_utils.baselines_archs import GCNN_2L\n",
    "from gsp_utils.baselines_models import NodeClassModel, GF_NodeClassModel\n",
    "from gsp_utils.data import normalize_gso\n",
    "from src.arch import GFGCN, GFGCNLayer, GFGCN_noh_Layer, GFGCN_Spows\n",
    "\n",
    "SEED = 15\n",
    "# PATH = 'results/diff_filters/'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CornellDataset\n",
      "Number of nodes: 183\n",
      "Number of features: 1703\n",
      "Shape of signals: torch.Size([183, 1703])\n",
      "Number of classes: 5\n",
      "Norm of A: 17.262676239013672\n",
      "Max value of A: 1.0\n",
      "Proportion of validation data: 0.32\n",
      "Proportion of test data: 0.20\n",
      "Node homophily: 0.11\n",
      "Edge homophily: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Dataset must be from DGL\n",
    "dataset_name = 'CornellDataset'\n",
    "\n",
    "A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device,\n",
    "                                                     verb=True)\n",
    "N = A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without normalizing the GSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "## Reaining params\n",
    "N_RUNS = 25\n",
    "N_EPOCHS = 200  # 500\n",
    "LR = .05\n",
    "WD = .01\n",
    "DROPOUT = 0\n",
    "\n",
    "# BEST PARAMETERS\n",
    "## Architecture params\n",
    "N_LAYERS = 2\n",
    "K = 3\n",
    "HID_DIM = 50\n",
    "\n",
    "## Model params\n",
    "h0 = .1  # 1\n",
    "NORM = False\n",
    "\n",
    "IN_DIM = feat.shape[1]\n",
    "OUT_DIM = n_class\n",
    "\n",
    "\n",
    "ACT = nn.ReLU()\n",
    "LAST_ACT = nn.Softmax(dim=1)\n",
    "LOSS_FN = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 200-0.1-0.0005: 0.622\n",
      "-1: 200-0.05-0.0005: 0.324\n",
      "-1: 200-0.01-0.0005: 0.486\n",
      "-1: 200-0.005-0.0005: 0.270\n",
      "-1: 200-0.05-0.001: 0.514\n",
      "-1: 200-0.01-0.001: 0.459\n",
      "-1: 200-0.05-0.01: 0.865\n",
      "-1: 200-0.01-0.01: 0.784\n",
      "-1: 200-0.05-0.05: 0.865\n",
      "-1: 200-0.01-0.05: 0.730\n",
      "-1: 500-0.05-0.0005: 0.838\n",
      "-1: 500-0.01-0.0005: 0.730\n",
      "-1: 500-0.05-0.01: 0.838\n",
      "-1: 500-0.01-0.01: 0.838\n",
      "-2: 200-0.1-0.0005: 0.595\n",
      "-2: 200-0.05-0.0005: 0.757\n",
      "-2: 200-0.01-0.0005: 0.514\n",
      "-2: 200-0.005-0.0005: 0.216\n",
      "-2: 200-0.05-0.001: 0.514\n",
      "-2: 200-0.01-0.001: 0.486\n",
      "-2: 200-0.05-0.01: 0.838\n",
      "-2: 200-0.01-0.01: 0.784\n",
      "-2: 200-0.05-0.05: 0.514\n",
      "-2: 200-0.01-0.05: 0.730\n",
      "-2: 500-0.05-0.0005: 0.595\n",
      "-2: 500-0.01-0.0005: 0.486\n",
      "-2: 500-0.05-0.01: 0.865\n",
      "-2: 500-0.01-0.01: 0.838\n",
      "-3: 200-0.1-0.0005: 0.622\n",
      "-3: 200-0.05-0.0005: 0.514\n",
      "-3: 200-0.01-0.0005: 0.432\n",
      "-3: 200-0.005-0.0005: 0.459\n",
      "-3: 200-0.05-0.001: 0.757\n",
      "-3: 200-0.01-0.001: 0.486\n",
      "-3: 200-0.05-0.01: 0.865\n",
      "-3: 200-0.01-0.01: 0.703\n",
      "-3: 200-0.05-0.05: 0.514\n",
      "-3: 200-0.01-0.05: 0.703\n",
      "-3: 500-0.05-0.0005: 0.730\n",
      "-3: 500-0.01-0.0005: 0.459\n",
      "-3: 500-0.05-0.01: 0.838\n",
      "-3: 500-0.01-0.01: 0.757\n",
      "-4: 200-0.1-0.0005: 0.351\n",
      "-4: 200-0.05-0.0005: 0.486\n",
      "-4: 200-0.01-0.0005: 0.568\n",
      "-4: 200-0.005-0.0005: 0.405\n",
      "-4: 200-0.05-0.001: 0.730\n",
      "-4: 200-0.01-0.001: 0.405\n",
      "-4: 200-0.05-0.01: 0.865\n",
      "-4: 200-0.01-0.01: 0.838\n",
      "-4: 200-0.05-0.05: 0.486\n",
      "-4: 200-0.01-0.05: 0.730\n",
      "-4: 500-0.05-0.0005: 0.730\n",
      "-4: 500-0.01-0.0005: 0.189\n",
      "-4: 500-0.05-0.01: 0.865\n",
      "-4: 500-0.01-0.01: 0.838\n",
      "-5: 200-0.1-0.0005: 0.595\n",
      "-5: 200-0.05-0.0005: 0.811\n",
      "-5: 200-0.01-0.0005: 0.459\n",
      "-5: 200-0.005-0.0005: 0.514\n",
      "-5: 200-0.05-0.001: 0.865\n",
      "-5: 200-0.01-0.001: 0.541\n",
      "-5: 200-0.05-0.01: 0.865\n",
      "-5: 200-0.01-0.01: 0.784\n",
      "-5: 200-0.05-0.05: 0.865\n",
      "-5: 200-0.01-0.05: 0.703\n",
      "-5: 500-0.05-0.0005: 0.811\n",
      "-5: 500-0.01-0.0005: 0.730\n",
      "-5: 500-0.05-0.01: 0.892\n",
      "-5: 500-0.01-0.01: 0.784\n",
      "-6: 200-0.1-0.0005: 0.541\n",
      "-6: 200-0.05-0.0005: 0.459\n",
      "-6: 200-0.01-0.0005: 0.622\n",
      "-6: 200-0.005-0.0005: 0.432\n",
      "-6: 200-0.05-0.001: 0.811\n",
      "-6: 200-0.01-0.001: 0.459\n",
      "-6: 200-0.05-0.01: 0.865\n",
      "-6: 200-0.01-0.01: 0.838\n",
      "-6: 200-0.05-0.05: 0.865\n",
      "-6: 200-0.01-0.05: 0.703\n",
      "-6: 500-0.05-0.0005: 0.595\n",
      "-6: 500-0.01-0.0005: 0.486\n",
      "-6: 500-0.05-0.01: 0.892\n",
      "-6: 500-0.01-0.01: 0.784\n",
      "-7: 200-0.1-0.0005: 0.568\n",
      "-7: 200-0.05-0.0005: 0.541\n",
      "-7: 200-0.01-0.0005: 0.459\n",
      "-7: 200-0.005-0.0005: 0.405\n",
      "-7: 200-0.05-0.001: 0.784\n",
      "-7: 200-0.01-0.001: 0.486\n",
      "-7: 200-0.05-0.01: 0.811\n",
      "-7: 200-0.01-0.01: 0.784\n",
      "-7: 200-0.05-0.05: 0.865\n",
      "-7: 200-0.01-0.05: 0.757\n",
      "-7: 500-0.05-0.0005: 0.865\n",
      "-7: 500-0.01-0.0005: 0.459\n",
      "-7: 500-0.05-0.01: 0.892\n",
      "-7: 500-0.01-0.01: 0.811\n",
      "-8: 200-0.1-0.0005: 0.649\n",
      "-8: 200-0.05-0.0005: 0.784\n",
      "-8: 200-0.01-0.0005: 0.459\n",
      "-8: 200-0.005-0.0005: 0.405\n",
      "-8: 200-0.05-0.001: 0.595\n",
      "-8: 200-0.01-0.001: 0.297\n",
      "-8: 200-0.05-0.01: 0.865\n",
      "-8: 200-0.01-0.01: 0.784\n",
      "-8: 200-0.05-0.05: 0.514\n",
      "-8: 200-0.01-0.05: 0.703\n",
      "-8: 500-0.05-0.0005: 0.595\n",
      "-8: 500-0.01-0.0005: 0.838\n",
      "-8: 500-0.05-0.01: 0.892\n",
      "-8: 500-0.01-0.01: 0.784\n",
      "-9: 200-0.1-0.0005: 0.649\n",
      "-9: 200-0.05-0.0005: 0.486\n",
      "-9: 200-0.01-0.0005: 0.432\n",
      "-9: 200-0.005-0.0005: 0.432\n",
      "-9: 200-0.05-0.001: 0.811\n",
      "-9: 200-0.01-0.001: 0.568\n",
      "-9: 200-0.05-0.01: 0.865\n",
      "-9: 200-0.01-0.01: 0.784\n",
      "-9: 200-0.05-0.05: 0.514\n",
      "-9: 200-0.01-0.05: 0.757\n",
      "-9: 500-0.05-0.0005: 0.676\n",
      "-9: 500-0.01-0.0005: 0.486\n",
      "-9: 500-0.05-0.01: 0.892\n",
      "-9: 500-0.01-0.01: 0.811\n",
      "-10: 200-0.1-0.0005: 0.351\n",
      "-10: 200-0.05-0.0005: 0.811\n",
      "-10: 200-0.01-0.0005: 0.459\n",
      "-10: 200-0.005-0.0005: 0.405\n",
      "-10: 200-0.05-0.001: 0.784\n",
      "-10: 200-0.01-0.001: 0.432\n",
      "-10: 200-0.05-0.01: 0.865\n",
      "-10: 200-0.01-0.01: 0.757\n",
      "-10: 200-0.05-0.05: 0.865\n",
      "-10: 200-0.01-0.05: 0.703\n",
      "-10: 500-0.05-0.0005: 0.811\n",
      "-10: 500-0.01-0.0005: 0.459\n",
      "-10: 500-0.05-0.01: 0.865\n",
      "-10: 500-0.01-0.01: 0.730\n",
      "-11: 200-0.1-0.0005: 0.541\n",
      "-11: 200-0.05-0.0005: 0.784\n",
      "-11: 200-0.01-0.0005: 0.568\n",
      "-11: 200-0.005-0.0005: 0.405\n",
      "-11: 200-0.05-0.001: 0.784\n",
      "-11: 200-0.01-0.001: 0.459\n",
      "-11: 200-0.05-0.01: 0.865\n",
      "-11: 200-0.01-0.01: 0.676\n",
      "-11: 200-0.05-0.05: 0.514\n",
      "-11: 200-0.01-0.05: 0.703\n",
      "-11: 500-0.05-0.0005: 0.676\n",
      "-11: 500-0.01-0.0005: 0.514\n",
      "-11: 500-0.05-0.01: 0.865\n",
      "-11: 500-0.01-0.01: 0.784\n",
      "-12: 200-0.1-0.0005: 0.486\n",
      "-12: 200-0.05-0.0005: 0.486\n",
      "-12: 200-0.01-0.0005: 0.703\n",
      "-12: 200-0.005-0.0005: 0.324\n",
      "-12: 200-0.05-0.001: 0.730\n",
      "-12: 200-0.01-0.001: 0.432\n",
      "-12: 200-0.05-0.01: 0.865\n",
      "-12: 200-0.01-0.01: 0.757\n",
      "-12: 200-0.05-0.05: 0.514\n",
      "-12: 200-0.01-0.05: 0.730\n",
      "-12: 500-0.05-0.0005: 0.514\n",
      "-12: 500-0.01-0.0005: 0.622\n",
      "-12: 500-0.05-0.01: 0.865\n",
      "-12: 500-0.01-0.01: 0.784\n",
      "-13: 200-0.1-0.0005: 0.541\n",
      "-13: 200-0.05-0.0005: 0.703\n",
      "-13: 200-0.01-0.0005: 0.514\n",
      "-13: 200-0.005-0.0005: 0.459\n",
      "-13: 200-0.05-0.001: 0.811\n",
      "-13: 200-0.01-0.001: 0.486\n",
      "-13: 200-0.05-0.01: 0.865\n",
      "-13: 200-0.01-0.01: 0.784\n",
      "-13: 200-0.05-0.05: 0.514\n",
      "-13: 200-0.01-0.05: 0.703\n",
      "-13: 500-0.05-0.0005: 0.730\n",
      "-13: 500-0.01-0.0005: 0.486\n",
      "-13: 500-0.05-0.01: 0.865\n",
      "-13: 500-0.01-0.01: 0.784\n",
      "-14: 200-0.1-0.0005: 0.459\n",
      "-14: 200-0.05-0.0005: 0.784\n",
      "-14: 200-0.01-0.0005: 0.486\n",
      "-14: 200-0.005-0.0005: 0.378\n",
      "-14: 200-0.05-0.001: 0.568\n",
      "-14: 200-0.01-0.001: 0.649\n",
      "-14: 200-0.05-0.01: 0.865\n",
      "-14: 200-0.01-0.01: 0.784\n",
      "-14: 200-0.05-0.05: 0.514\n",
      "-14: 200-0.01-0.05: 0.730\n",
      "-14: 500-0.05-0.0005: 0.541\n",
      "-14: 500-0.01-0.0005: 0.514\n",
      "-14: 500-0.05-0.01: 0.919\n",
      "-14: 500-0.01-0.01: 0.784\n",
      "-15: 200-0.1-0.0005: 0.757\n",
      "-15: 200-0.05-0.0005: 0.784\n",
      "-15: 200-0.01-0.0005: 0.405\n",
      "-15: 200-0.005-0.0005: 0.459\n",
      "-15: 200-0.05-0.001: 0.541\n",
      "-15: 200-0.01-0.001: 0.351\n",
      "-15: 200-0.05-0.01: 0.865\n",
      "-15: 200-0.01-0.01: 0.784\n",
      "-15: 200-0.05-0.05: 0.514\n",
      "-15: 200-0.01-0.05: 0.703\n",
      "-15: 500-0.05-0.0005: 0.757\n",
      "-15: 500-0.01-0.0005: 0.459\n",
      "-15: 500-0.05-0.01: 0.865\n",
      "-15: 500-0.01-0.01: 0.757\n",
      "-16: 200-0.1-0.0005: 0.514\n",
      "-16: 200-0.05-0.0005: 0.784\n",
      "-16: 200-0.01-0.0005: 0.297\n",
      "-16: 200-0.005-0.0005: 0.514\n",
      "-16: 200-0.05-0.001: 0.595\n",
      "-16: 200-0.01-0.001: 0.459\n",
      "-16: 200-0.05-0.01: 0.865\n",
      "-16: 200-0.01-0.01: 0.811\n",
      "-16: 200-0.05-0.05: 0.757\n",
      "-16: 200-0.01-0.05: 0.703\n",
      "-16: 500-0.05-0.0005: 0.838\n",
      "-16: 500-0.01-0.0005: 0.784\n",
      "-16: 500-0.05-0.01: 0.865\n",
      "-16: 500-0.01-0.01: 0.838\n",
      "-17: 200-0.1-0.0005: 0.514\n",
      "-17: 200-0.05-0.0005: 0.757\n",
      "-17: 200-0.01-0.0005: 0.459\n",
      "-17: 200-0.005-0.0005: 0.297\n",
      "-17: 200-0.05-0.001: 0.595\n",
      "-17: 200-0.01-0.001: 0.405\n",
      "-17: 200-0.05-0.01: 0.865\n",
      "-17: 200-0.01-0.01: 0.757\n",
      "-17: 200-0.05-0.05: 0.865\n",
      "-17: 200-0.01-0.05: 0.730\n",
      "-17: 500-0.05-0.0005: 0.811\n",
      "-17: 500-0.01-0.0005: 0.784\n",
      "-17: 500-0.05-0.01: 0.892\n",
      "-17: 500-0.01-0.01: 0.784\n",
      "-18: 200-0.1-0.0005: 0.514\n",
      "-18: 200-0.05-0.0005: 0.486\n",
      "-18: 200-0.01-0.0005: 0.459\n",
      "-18: 200-0.005-0.0005: 0.324\n",
      "-18: 200-0.05-0.001: 0.784\n",
      "-18: 200-0.01-0.001: 0.486\n",
      "-18: 200-0.05-0.01: 0.865\n",
      "-18: 200-0.01-0.01: 0.757\n",
      "-18: 200-0.05-0.05: 0.892\n",
      "-18: 200-0.01-0.05: 0.730\n",
      "-18: 500-0.05-0.0005: 0.649\n",
      "-18: 500-0.01-0.0005: 0.486\n",
      "-18: 500-0.05-0.01: 0.892\n",
      "-18: 500-0.01-0.01: 0.784\n",
      "-19: 200-0.1-0.0005: 0.514\n",
      "-19: 200-0.05-0.0005: 0.514\n",
      "-19: 200-0.01-0.0005: 0.622\n",
      "-19: 200-0.005-0.0005: 0.459\n",
      "-19: 200-0.05-0.001: 0.730\n",
      "-19: 200-0.01-0.001: 0.649\n",
      "-19: 200-0.05-0.01: 0.838\n",
      "-19: 200-0.01-0.01: 0.757\n",
      "-19: 200-0.05-0.05: 0.838\n",
      "-19: 200-0.01-0.05: 0.703\n",
      "-19: 500-0.05-0.0005: 0.730\n",
      "-19: 500-0.01-0.0005: 0.486\n",
      "-19: 500-0.05-0.01: 0.892\n",
      "-19: 500-0.01-0.01: 0.757\n",
      "-20: 200-0.1-0.0005: 0.541\n",
      "-20: 200-0.05-0.0005: 0.730\n",
      "-20: 200-0.01-0.0005: 0.405\n",
      "-20: 200-0.005-0.0005: 0.351\n",
      "-20: 200-0.05-0.001: 0.811\n",
      "-20: 200-0.01-0.001: 0.351\n",
      "-20: 200-0.05-0.01: 0.865\n",
      "-20: 200-0.01-0.01: 0.757\n",
      "-20: 200-0.05-0.05: 0.892\n",
      "-20: 200-0.01-0.05: 0.703\n",
      "-20: 500-0.05-0.0005: 0.784\n",
      "-20: 500-0.01-0.0005: 0.757\n",
      "-20: 500-0.05-0.01: 0.892\n",
      "-20: 500-0.01-0.01: 0.811\n",
      "-21: 200-0.1-0.0005: 0.459\n",
      "-21: 200-0.05-0.0005: 0.703\n",
      "-21: 200-0.01-0.0005: 0.486\n",
      "-21: 200-0.005-0.0005: 0.459\n",
      "-21: 200-0.05-0.001: 0.676\n",
      "-21: 200-0.01-0.001: 0.811\n",
      "-21: 200-0.05-0.01: 0.865\n",
      "-21: 200-0.01-0.01: 0.730\n",
      "-21: 200-0.05-0.05: 0.459\n",
      "-21: 200-0.01-0.05: 0.730\n",
      "-21: 500-0.05-0.0005: 0.622\n",
      "-21: 500-0.01-0.0005: 0.459\n",
      "-21: 500-0.05-0.01: 0.892\n",
      "-21: 500-0.01-0.01: 0.784\n",
      "-22: 200-0.1-0.0005: 0.459\n",
      "-22: 200-0.05-0.0005: 0.541\n",
      "-22: 200-0.01-0.0005: 0.486\n",
      "-22: 200-0.005-0.0005: 0.514\n",
      "-22: 200-0.05-0.001: 0.595\n",
      "-22: 200-0.01-0.001: 0.514\n",
      "-22: 200-0.05-0.01: 0.838\n",
      "-22: 200-0.01-0.01: 0.811\n",
      "-22: 200-0.05-0.05: 0.865\n",
      "-22: 200-0.01-0.05: 0.703\n",
      "-22: 500-0.05-0.0005: 0.811\n",
      "-22: 500-0.01-0.0005: 0.541\n",
      "-22: 500-0.05-0.01: 0.865\n",
      "-22: 500-0.01-0.01: 0.811\n",
      "-23: 200-0.1-0.0005: 0.514\n",
      "-23: 200-0.05-0.0005: 0.541\n",
      "-23: 200-0.01-0.0005: 0.486\n",
      "-23: 200-0.005-0.0005: 0.486\n",
      "-23: 200-0.05-0.001: 0.784\n",
      "-23: 200-0.01-0.001: 0.676\n",
      "-23: 200-0.05-0.01: 0.865\n",
      "-23: 200-0.01-0.01: 0.757\n",
      "-23: 200-0.05-0.05: 0.486\n",
      "-23: 200-0.01-0.05: 0.757\n",
      "-23: 500-0.05-0.0005: 0.595\n",
      "-23: 500-0.01-0.0005: 0.486\n",
      "-23: 500-0.05-0.01: 0.865\n",
      "-23: 500-0.01-0.01: 0.811\n",
      "-24: 200-0.1-0.0005: 0.568\n",
      "-24: 200-0.05-0.0005: 0.757\n",
      "-24: 200-0.01-0.0005: 0.514\n",
      "-24: 200-0.005-0.0005: 0.432\n",
      "-24: 200-0.05-0.001: 0.784\n",
      "-24: 200-0.01-0.001: 0.514\n",
      "-24: 200-0.05-0.01: 0.865\n",
      "-24: 200-0.01-0.01: 0.838\n",
      "-24: 200-0.05-0.05: 0.514\n",
      "-24: 200-0.01-0.05: 0.757\n",
      "-24: 500-0.05-0.0005: 0.649\n",
      "-24: 500-0.01-0.0005: 0.432\n",
      "-24: 500-0.05-0.01: 0.865\n",
      "-24: 500-0.01-0.01: 0.784\n",
      "-25: 200-0.1-0.0005: 0.676\n",
      "-25: 200-0.05-0.0005: 0.595\n",
      "-25: 200-0.01-0.0005: 0.459\n",
      "-25: 200-0.005-0.0005: 0.324\n",
      "-25: 200-0.05-0.001: 0.757\n",
      "-25: 200-0.01-0.001: 0.297\n",
      "-25: 200-0.05-0.01: 0.865\n",
      "-25: 200-0.01-0.01: 0.595\n",
      "-25: 200-0.05-0.05: 0.838\n",
      "-25: 200-0.01-0.05: 0.703\n",
      "-25: 500-0.05-0.0005: 0.541\n",
      "-25: 500-0.01-0.0005: 0.757\n",
      "-25: 500-0.05-0.01: 0.865\n",
      "-25: 500-0.01-0.01: 0.838\n",
      "----- 8.70 mins -----\n"
     ]
    }
   ],
   "source": [
    "EXPS = [{'epochs': 200, 'lr': .1, 'wd': 5e-4},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 5e-4},\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 5e-4},\n",
    "        \n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-3},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 1e-3},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-2},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 1e-2},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-2},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 5e-2},\n",
    "        \n",
    "        {'epochs': 500, 'lr': .05, 'wd': 5e-4},\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 5e-4},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2},\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 1e-2},\n",
    "        ]\n",
    "\n",
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'])\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}: {best_accs[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs.mean(axis=1)\n",
    "std_accs = best_accs.std(axis=1)\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}' for exp in EXPS]\n",
    "table1 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.0005</th>\n",
       "      <td>0.543784</td>\n",
       "      <td>0.090875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005</th>\n",
       "      <td>0.636757</td>\n",
       "      <td>0.142621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.0005</th>\n",
       "      <td>0.489730</td>\n",
       "      <td>0.079561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.0005</th>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.076825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.001</th>\n",
       "      <td>0.708108</td>\n",
       "      <td>0.106474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.001</th>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.115681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01</th>\n",
       "      <td>0.859459</td>\n",
       "      <td>0.013240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.01</th>\n",
       "      <td>0.767568</td>\n",
       "      <td>0.051280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.05</th>\n",
       "      <td>0.673514</td>\n",
       "      <td>0.177132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.05</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.020051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.0005</th>\n",
       "      <td>0.699459</td>\n",
       "      <td>0.104065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.0005</th>\n",
       "      <td>0.555676</td>\n",
       "      <td>0.150009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01</th>\n",
       "      <td>0.875676</td>\n",
       "      <td>0.018725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.01</th>\n",
       "      <td>0.794595</td>\n",
       "      <td>0.028603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean accs       std\n",
       "200-0.1-0.0005     0.543784  0.090875\n",
       "200-0.05-0.0005    0.636757  0.142621\n",
       "200-0.01-0.0005    0.489730  0.079561\n",
       "200-0.005-0.0005   0.405405  0.076825\n",
       "200-0.05-0.001     0.708108  0.106474\n",
       "200-0.01-0.001     0.486486  0.115681\n",
       "200-0.05-0.01      0.859459  0.013240\n",
       "200-0.01-0.01      0.767568  0.051280\n",
       "200-0.05-0.05      0.673514  0.177132\n",
       "200-0.01-0.05      0.720000  0.020051\n",
       "500-0.05-0.0005    0.699459  0.104065\n",
       "500-0.01-0.0005    0.555676  0.150009\n",
       "500-0.05-0.01      0.875676  0.018725\n",
       "500-0.01-0.01      0.794595  0.028603"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 0.001-1-1-True: 0.865\n",
      "-1: 0.01-1-1-True: 0.865\n",
      "-1: 0.1-1-1-True: 0.838\n",
      "-1: 1-1-1-True: 0.892\n",
      "-1: 0.01-1-1-False: 0.892\n",
      "-1: 1-1-1-False: 0.838\n",
      "-1: 1-10-1-True: 0.892\n",
      "-1: 1-1-10-True: 0.892\n",
      "-1: 0.01-10-10-True: 0.865\n",
      "-1: 1-10-10-True: 0.865\n",
      "-1: 1-25-25-True: 0.838\n",
      "-1: 1-50-50-True: 0.838\n",
      "-2: 0.001-1-1-True: 0.865\n",
      "-2: 0.01-1-1-True: 0.865\n",
      "-2: 0.1-1-1-True: 0.892\n",
      "-2: 1-1-1-True: 0.865\n",
      "-2: 0.01-1-1-False: 0.865\n",
      "-2: 1-1-1-False: 0.919\n",
      "-2: 1-10-1-True: 0.892\n",
      "-2: 1-1-10-True: 0.865\n",
      "-2: 0.01-10-10-True: 0.865\n",
      "-2: 1-10-10-True: 0.919\n",
      "-2: 1-25-25-True: 0.865\n",
      "-2: 1-50-50-True: 0.838\n",
      "-3: 0.001-1-1-True: 0.865\n",
      "-3: 0.01-1-1-True: 0.865\n",
      "-3: 0.1-1-1-True: 0.838\n",
      "-3: 1-1-1-True: 0.838\n",
      "-3: 0.01-1-1-False: 0.865\n",
      "-3: 1-1-1-False: 0.892\n",
      "-3: 1-10-1-True: 0.865\n",
      "-3: 1-1-10-True: 0.865\n",
      "-3: 0.01-10-10-True: 0.838\n",
      "-3: 1-10-10-True: 0.865\n",
      "-3: 1-25-25-True: 0.865\n",
      "-3: 1-50-50-True: 0.838\n",
      "-4: 0.001-1-1-True: 0.892\n",
      "-4: 0.01-1-1-True: 0.865\n",
      "-4: 0.1-1-1-True: 0.865\n",
      "-4: 1-1-1-True: 0.865\n",
      "-4: 0.01-1-1-False: 0.892\n",
      "-4: 1-1-1-False: 0.892\n",
      "-4: 1-10-1-True: 0.838\n",
      "-4: 1-1-10-True: 0.838\n",
      "-4: 0.01-10-10-True: 0.865\n",
      "-4: 1-10-10-True: 0.865\n",
      "-4: 1-25-25-True: 0.865\n",
      "-4: 1-50-50-True: 0.838\n",
      "-5: 0.001-1-1-True: 0.811\n",
      "-5: 0.01-1-1-True: 0.838\n",
      "-5: 0.1-1-1-True: 0.865\n",
      "-5: 1-1-1-True: 0.811\n",
      "-5: 0.01-1-1-False: 0.865\n",
      "-5: 1-1-1-False: 0.838\n",
      "-5: 1-10-1-True: 0.865\n",
      "-5: 1-1-10-True: 0.865\n",
      "-5: 0.01-10-10-True: 0.865\n",
      "-5: 1-10-10-True: 0.892\n",
      "-5: 1-25-25-True: 0.892\n",
      "-5: 1-50-50-True: 0.865\n",
      "-6: 0.001-1-1-True: 0.919\n",
      "-6: 0.01-1-1-True: 0.568\n",
      "-6: 0.1-1-1-True: 0.892\n",
      "-6: 1-1-1-True: 0.838\n",
      "-6: 0.01-1-1-False: 0.865\n",
      "-6: 1-1-1-False: 0.892\n",
      "-6: 1-10-1-True: 0.892\n",
      "-6: 1-1-10-True: 0.865\n",
      "-6: 0.01-10-10-True: 0.865\n",
      "-6: 1-10-10-True: 0.919\n",
      "-6: 1-25-25-True: 0.892\n",
      "-6: 1-50-50-True: 0.838\n",
      "-7: 0.001-1-1-True: 0.865\n",
      "-7: 0.01-1-1-True: 0.892\n",
      "-7: 0.1-1-1-True: 0.865\n",
      "-7: 1-1-1-True: 0.892\n",
      "-7: 0.01-1-1-False: 0.865\n",
      "-7: 1-1-1-False: 0.865\n",
      "-7: 1-10-1-True: 0.892\n",
      "-7: 1-1-10-True: 0.838\n",
      "-7: 0.01-10-10-True: 0.892\n",
      "-7: 1-10-10-True: 0.865\n",
      "-7: 1-25-25-True: 0.865\n",
      "-7: 1-50-50-True: 0.892\n",
      "-8: 0.001-1-1-True: 0.892\n",
      "-8: 0.01-1-1-True: 0.865\n",
      "-8: 0.1-1-1-True: 0.892\n",
      "-8: 1-1-1-True: 0.838\n",
      "-8: 0.01-1-1-False: 0.865\n",
      "-8: 1-1-1-False: 0.865\n",
      "-8: 1-10-1-True: 0.892\n",
      "-8: 1-1-10-True: 0.892\n",
      "-8: 0.01-10-10-True: 0.865\n",
      "-8: 1-10-10-True: 0.865\n",
      "-8: 1-25-25-True: 0.838\n",
      "-8: 1-50-50-True: 0.838\n",
      "-9: 0.001-1-1-True: 0.892\n",
      "-9: 0.01-1-1-True: 0.865\n",
      "-9: 0.1-1-1-True: 0.865\n",
      "-9: 1-1-1-True: 0.865\n",
      "-9: 0.01-1-1-False: 0.838\n",
      "-9: 1-1-1-False: 0.892\n",
      "-9: 1-10-1-True: 0.892\n",
      "-9: 1-1-10-True: 0.865\n",
      "-9: 0.01-10-10-True: 0.865\n",
      "-9: 1-10-10-True: 0.838\n",
      "-9: 1-25-25-True: 0.838\n",
      "-9: 1-50-50-True: 0.865\n",
      "-10: 0.001-1-1-True: 0.865\n",
      "-10: 0.01-1-1-True: 0.865\n",
      "-10: 0.1-1-1-True: 0.892\n",
      "-10: 1-1-1-True: 0.892\n",
      "-10: 0.01-1-1-False: 0.892\n",
      "-10: 1-1-1-False: 0.865\n",
      "-10: 1-10-1-True: 0.865\n",
      "-10: 1-1-10-True: 0.865\n",
      "-10: 0.01-10-10-True: 0.865\n",
      "-10: 1-10-10-True: 0.838\n",
      "-10: 1-25-25-True: 0.865\n",
      "-10: 1-50-50-True: 0.865\n",
      "-11: 0.001-1-1-True: 0.865\n",
      "-11: 0.01-1-1-True: 0.892\n",
      "-11: 0.1-1-1-True: 0.892\n",
      "-11: 1-1-1-True: 0.865\n",
      "-11: 0.01-1-1-False: 0.892\n",
      "-11: 1-1-1-False: 0.865\n",
      "-11: 1-10-1-True: 0.865\n",
      "-11: 1-1-10-True: 0.865\n",
      "-11: 0.01-10-10-True: 0.865\n",
      "-11: 1-10-10-True: 0.892\n",
      "-11: 1-25-25-True: 0.892\n",
      "-11: 1-50-50-True: 0.838\n",
      "-12: 0.001-1-1-True: 0.892\n",
      "-12: 0.01-1-1-True: 0.865\n",
      "-12: 0.1-1-1-True: 0.919\n",
      "-12: 1-1-1-True: 0.838\n",
      "-12: 0.01-1-1-False: 0.757\n",
      "-12: 1-1-1-False: 0.865\n",
      "-12: 1-10-1-True: 0.865\n",
      "-12: 1-1-10-True: 0.865\n",
      "-12: 0.01-10-10-True: 0.865\n",
      "-12: 1-10-10-True: 0.892\n",
      "-12: 1-25-25-True: 0.865\n",
      "-12: 1-50-50-True: 0.838\n",
      "-13: 0.001-1-1-True: 0.892\n",
      "-13: 0.01-1-1-True: 0.892\n",
      "-13: 0.1-1-1-True: 0.838\n",
      "-13: 1-1-1-True: 0.865\n",
      "-13: 0.01-1-1-False: 0.892\n",
      "-13: 1-1-1-False: 0.865\n",
      "-13: 1-10-1-True: 0.865\n",
      "-13: 1-1-10-True: 0.865\n",
      "-13: 0.01-10-10-True: 0.865\n",
      "-13: 1-10-10-True: 0.865\n",
      "-13: 1-25-25-True: 0.865\n",
      "-13: 1-50-50-True: 0.865\n",
      "-14: 0.001-1-1-True: 0.865\n",
      "-14: 0.01-1-1-True: 0.865\n",
      "-14: 0.1-1-1-True: 0.838\n",
      "-14: 1-1-1-True: 0.838\n",
      "-14: 0.01-1-1-False: 0.865\n",
      "-14: 1-1-1-False: 0.865\n",
      "-14: 1-10-1-True: 0.865\n",
      "-14: 1-1-10-True: 0.838\n",
      "-14: 0.01-10-10-True: 0.892\n",
      "-14: 1-10-10-True: 0.865\n",
      "-14: 1-25-25-True: 0.865\n",
      "-14: 1-50-50-True: 0.838\n",
      "-15: 0.001-1-1-True: 0.892\n",
      "-15: 0.01-1-1-True: 0.865\n",
      "-15: 0.1-1-1-True: 0.865\n",
      "-15: 1-1-1-True: 0.838\n",
      "-15: 0.01-1-1-False: 0.838\n",
      "-15: 1-1-1-False: 0.892\n",
      "-15: 1-10-1-True: 0.865\n",
      "-15: 1-1-10-True: 0.865\n",
      "-15: 0.01-10-10-True: 0.892\n",
      "-15: 1-10-10-True: 0.865\n",
      "-15: 1-25-25-True: 0.865\n",
      "-15: 1-50-50-True: 0.865\n",
      "-16: 0.001-1-1-True: 0.892\n",
      "-16: 0.01-1-1-True: 0.865\n",
      "-16: 0.1-1-1-True: 0.865\n",
      "-16: 1-1-1-True: 0.865\n",
      "-16: 0.01-1-1-False: 0.865\n",
      "-16: 1-1-1-False: 0.865\n",
      "-16: 1-10-1-True: 0.838\n",
      "-16: 1-1-10-True: 0.865\n",
      "-16: 0.01-10-10-True: 0.919\n",
      "-16: 1-10-10-True: 0.865\n",
      "-16: 1-25-25-True: 0.865\n",
      "-16: 1-50-50-True: 0.838\n",
      "-17: 0.001-1-1-True: 0.865\n",
      "-17: 0.01-1-1-True: 0.892\n",
      "-17: 0.1-1-1-True: 0.865\n",
      "-17: 1-1-1-True: 0.865\n",
      "-17: 0.01-1-1-False: 0.865\n",
      "-17: 1-1-1-False: 0.892\n",
      "-17: 1-10-1-True: 0.892\n",
      "-17: 1-1-10-True: 0.865\n",
      "-17: 0.01-10-10-True: 0.865\n",
      "-17: 1-10-10-True: 0.865\n",
      "-17: 1-25-25-True: 0.865\n",
      "-17: 1-50-50-True: 0.838\n",
      "-18: 0.001-1-1-True: 0.865\n",
      "-18: 0.01-1-1-True: 0.838\n",
      "-18: 0.1-1-1-True: 0.865\n",
      "-18: 1-1-1-True: 0.865\n",
      "-18: 0.01-1-1-False: 0.838\n",
      "-18: 1-1-1-False: 0.865\n",
      "-18: 1-10-1-True: 0.865\n",
      "-18: 1-1-10-True: 0.838\n",
      "-18: 0.01-10-10-True: 0.865\n",
      "-18: 1-10-10-True: 0.865\n",
      "-18: 1-25-25-True: 0.865\n",
      "-18: 1-50-50-True: 0.865\n",
      "-19: 0.001-1-1-True: 0.865\n",
      "-19: 0.01-1-1-True: 0.838\n",
      "-19: 0.1-1-1-True: 0.865\n",
      "-19: 1-1-1-True: 0.892\n",
      "-19: 0.01-1-1-False: 0.865\n",
      "-19: 1-1-1-False: 0.865\n",
      "-19: 1-10-1-True: 0.892\n",
      "-19: 1-1-10-True: 0.838\n",
      "-19: 0.01-10-10-True: 0.838\n",
      "-19: 1-10-10-True: 0.865\n",
      "-19: 1-25-25-True: 0.892\n",
      "-19: 1-50-50-True: 0.865\n",
      "-20: 0.001-1-1-True: 0.703\n",
      "-20: 0.01-1-1-True: 0.865\n",
      "-20: 0.1-1-1-True: 0.865\n",
      "-20: 1-1-1-True: 0.838\n",
      "-20: 0.01-1-1-False: 0.865\n",
      "-20: 1-1-1-False: 0.865\n",
      "-20: 1-10-1-True: 0.865\n",
      "-20: 1-1-10-True: 0.838\n",
      "-20: 0.01-10-10-True: 0.892\n",
      "-20: 1-10-10-True: 0.838\n",
      "-20: 1-25-25-True: 0.865\n",
      "-20: 1-50-50-True: 0.865\n",
      "-21: 0.001-1-1-True: 0.919\n",
      "-21: 0.01-1-1-True: 0.865\n",
      "-21: 0.1-1-1-True: 0.865\n",
      "-21: 1-1-1-True: 0.838\n",
      "-21: 0.01-1-1-False: 0.865\n",
      "-21: 1-1-1-False: 0.865\n",
      "-21: 1-10-1-True: 0.865\n",
      "-21: 1-1-10-True: 0.865\n",
      "-21: 0.01-10-10-True: 0.865\n",
      "-21: 1-10-10-True: 0.865\n",
      "-21: 1-25-25-True: 0.838\n",
      "-21: 1-50-50-True: 0.838\n",
      "-22: 0.001-1-1-True: 0.865\n",
      "-22: 0.01-1-1-True: 0.892\n",
      "-22: 0.1-1-1-True: 0.838\n",
      "-22: 1-1-1-True: 0.865\n",
      "-22: 0.01-1-1-False: 0.865\n",
      "-22: 1-1-1-False: 0.865\n",
      "-22: 1-10-1-True: 0.892\n",
      "-22: 1-1-10-True: 0.865\n",
      "-22: 0.01-10-10-True: 0.865\n",
      "-22: 1-10-10-True: 0.865\n",
      "-22: 1-25-25-True: 0.865\n",
      "-22: 1-50-50-True: 0.838\n",
      "-23: 0.001-1-1-True: 0.892\n",
      "-23: 0.01-1-1-True: 0.865\n",
      "-23: 0.1-1-1-True: 0.865\n",
      "-23: 1-1-1-True: 0.865\n",
      "-23: 0.01-1-1-False: 0.892\n",
      "-23: 1-1-1-False: 0.865\n",
      "-23: 1-10-1-True: 0.892\n",
      "-23: 1-1-10-True: 0.892\n",
      "-23: 0.01-10-10-True: 0.865\n",
      "-23: 1-10-10-True: 0.865\n",
      "-23: 1-25-25-True: 0.838\n",
      "-23: 1-50-50-True: 0.838\n",
      "-24: 0.001-1-1-True: 0.838\n",
      "-24: 0.01-1-1-True: 0.865\n",
      "-24: 0.1-1-1-True: 0.892\n",
      "-24: 1-1-1-True: 0.865\n",
      "-24: 0.01-1-1-False: 0.865\n",
      "-24: 1-1-1-False: 0.865\n",
      "-24: 1-10-1-True: 0.838\n",
      "-24: 1-1-10-True: 0.865\n",
      "-24: 0.01-10-10-True: 0.865\n",
      "-24: 1-10-10-True: 0.865\n",
      "-24: 1-25-25-True: 0.865\n",
      "-24: 1-50-50-True: 0.838\n",
      "-25: 0.001-1-1-True: 0.838\n",
      "-25: 0.01-1-1-True: 0.865\n",
      "-25: 0.1-1-1-True: 0.892\n",
      "-25: 1-1-1-True: 0.811\n",
      "-25: 0.01-1-1-False: 0.784\n",
      "-25: 1-1-1-False: 0.865\n",
      "-25: 1-10-1-True: 0.838\n",
      "-25: 1-1-10-True: 0.838\n",
      "-25: 0.01-10-10-True: 0.865\n",
      "-25: 1-10-10-True: 0.865\n",
      "-25: 1-25-25-True: 0.892\n",
      "-25: 1-50-50-True: 0.865\n",
      "----- 23.94 mins -----\n"
     ]
    }
   ],
   "source": [
    "# h0, norm (norm, not norm, norm H), sep vs joint training, optimizers iters (W vs h)\n",
    "EXPS = [{'h0': .001, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        \n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 50, 'epochs_h': 50, 'epochs_W': 50, 'alt': True},]\n",
    "\n",
    "\n",
    "best_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=exp['h0'])\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        if not exp['alt']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S,  K, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD, epochs_h=exp['epochs_h'],\n",
    "                                 epochs_W=exp['epochs_W'])\n",
    "\n",
    "        best_accs2[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}: {best_accs2[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs2.mean(axis=1)\n",
    "std_accs = best_accs2.std(axis=1)\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}' for exp in EXPS]\n",
    "table2 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.001-1-1-True</th>\n",
       "      <td>0.867027</td>\n",
       "      <td>0.041110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-1-1-True</th>\n",
       "      <td>0.855135</td>\n",
       "      <td>0.060618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-1-1-True</th>\n",
       "      <td>0.869189</td>\n",
       "      <td>0.021185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-1-True</th>\n",
       "      <td>0.856216</td>\n",
       "      <td>0.022574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-1-1-False</th>\n",
       "      <td>0.860541</td>\n",
       "      <td>0.031221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-1-False</th>\n",
       "      <td>0.871351</td>\n",
       "      <td>0.017565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-1-True</th>\n",
       "      <td>0.871351</td>\n",
       "      <td>0.019157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-10-True</th>\n",
       "      <td>0.860541</td>\n",
       "      <td>0.016537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-10-10-True</th>\n",
       "      <td>0.869189</td>\n",
       "      <td>0.016537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-10-True</th>\n",
       "      <td>0.869189</td>\n",
       "      <td>0.019757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-25-True</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.017093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50-1-50-50-True</th>\n",
       "      <td>0.849730</td>\n",
       "      <td>0.015441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean accs       std\n",
       "200-0.001-1-1-True    0.867027  0.041110\n",
       "200-0.01-1-1-True     0.855135  0.060618\n",
       "200-0.1-1-1-True      0.869189  0.021185\n",
       "200-1-1-1-True        0.856216  0.022574\n",
       "200-0.01-1-1-False    0.860541  0.031221\n",
       "200-1-1-1-False       0.871351  0.017565\n",
       "200-1-10-1-True       0.871351  0.019157\n",
       "200-1-1-10-True       0.860541  0.016537\n",
       "200-0.01-10-10-True   0.869189  0.016537\n",
       "200-1-10-10-True      0.869189  0.019757\n",
       "200-1-25-25-True      0.864865  0.017093\n",
       "50-1-50-50-True       0.849730  0.015441"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 2-2-16: 0.865\n",
      "-1: 2-3-16: 0.865\n",
      "-1: 2-4-16: 0.865\n",
      "-1: 3-2-16: 0.865\n",
      "-1: 4-2-16: 0.811\n",
      "-1: 3-3-16: 0.811\n",
      "-1: 4-3-16: 0.865\n",
      "-1: 2-2-8: 0.838\n",
      "-1: 2-2-32: 0.838\n",
      "-1: 2-2-50: 0.865\n",
      "-1: 2-3-8: 0.865\n",
      "-1: 2-3-32: 0.865\n",
      "-1: 2-3-50: 0.865\n",
      "-1: 3-2-8: 0.865\n",
      "-1: 3-2-32: 0.838\n",
      "-1: 3-2-50: 0.811\n",
      "-1: 3-3-8: 0.811\n",
      "-1: 3-3-32: 0.865\n",
      "-1: 3-3-50: 0.838\n",
      "-2: 2-2-16: 0.865\n",
      "-2: 2-3-16: 0.838\n",
      "-2: 2-4-16: 0.838\n",
      "-2: 3-2-16: 0.865\n",
      "-2: 4-2-16: 0.757\n",
      "-2: 3-3-16: 0.865\n",
      "-2: 4-3-16: 0.865\n",
      "-2: 2-2-8: 0.811\n",
      "-2: 2-2-32: 0.865\n",
      "-2: 2-2-50: 0.838\n",
      "-2: 2-3-8: 0.838\n",
      "-2: 2-3-32: 0.892\n",
      "-2: 2-3-50: 0.838\n",
      "-2: 3-2-8: 0.838\n",
      "-2: 3-2-32: 0.865\n",
      "-2: 3-2-50: 0.865\n",
      "-2: 3-3-8: 0.838\n",
      "-2: 3-3-32: 0.892\n",
      "-2: 3-3-50: 0.514\n",
      "-3: 2-2-16: 0.838\n",
      "-3: 2-3-16: 0.865\n",
      "-3: 2-4-16: 0.838\n",
      "-3: 3-2-16: 0.865\n",
      "-3: 4-2-16: 0.784\n",
      "-3: 3-3-16: 0.865\n",
      "-3: 4-3-16: 0.784\n",
      "-3: 2-2-8: 0.811\n",
      "-3: 2-2-32: 0.865\n",
      "-3: 2-2-50: 0.865\n",
      "-3: 2-3-8: 0.865\n",
      "-3: 2-3-32: 0.865\n",
      "-3: 2-3-50: 0.865\n",
      "-3: 3-2-8: 0.838\n",
      "-3: 3-2-32: 0.838\n",
      "-3: 3-2-50: 0.892\n",
      "-3: 3-3-8: 0.784\n",
      "-3: 3-3-32: 0.865\n",
      "-3: 3-3-50: 0.568\n",
      "-4: 2-2-16: 0.838\n",
      "-4: 2-3-16: 0.865\n",
      "-4: 2-4-16: 0.865\n",
      "-4: 3-2-16: 0.865\n",
      "-4: 4-2-16: 0.865\n",
      "-4: 3-3-16: 0.892\n",
      "-4: 4-3-16: 0.865\n",
      "-4: 2-2-8: 0.811\n",
      "-4: 2-2-32: 0.865\n",
      "-4: 2-2-50: 0.838\n",
      "-4: 2-3-8: 0.541\n",
      "-4: 2-3-32: 0.838\n",
      "-4: 2-3-50: 0.838\n",
      "-4: 3-2-8: 0.811\n",
      "-4: 3-2-32: 0.811\n",
      "-4: 3-2-50: 0.865\n",
      "-4: 3-3-8: 0.811\n",
      "-4: 3-3-32: 0.784\n",
      "-4: 3-3-50: 0.703\n",
      "-5: 2-2-16: 0.865\n",
      "-5: 2-3-16: 0.865\n",
      "-5: 2-4-16: 0.892\n",
      "-5: 3-2-16: 0.811\n",
      "-5: 4-2-16: 0.838\n",
      "-5: 3-3-16: 0.541\n",
      "-5: 4-3-16: 0.892\n",
      "-5: 2-2-8: 0.811\n",
      "-5: 2-2-32: 0.865\n",
      "-5: 2-2-50: 0.865\n",
      "-5: 2-3-8: 0.865\n",
      "-5: 2-3-32: 0.865\n",
      "-5: 2-3-50: 0.838\n",
      "-5: 3-2-8: 0.838\n",
      "-5: 3-2-32: 0.892\n",
      "-5: 3-2-50: 0.865\n",
      "-5: 3-3-8: 0.811\n",
      "-5: 3-3-32: 0.838\n",
      "-5: 3-3-50: 0.865\n",
      "-6: 2-2-16: 0.838\n",
      "-6: 2-3-16: 0.865\n",
      "-6: 2-4-16: 0.811\n",
      "-6: 3-2-16: 0.865\n",
      "-6: 4-2-16: 0.784\n",
      "-6: 3-3-16: 0.838\n",
      "-6: 4-3-16: 0.838\n",
      "-6: 2-2-8: 0.838\n",
      "-6: 2-2-32: 0.865\n",
      "-6: 2-2-50: 0.865\n",
      "-6: 2-3-8: 0.865\n",
      "-6: 2-3-32: 0.865\n",
      "-6: 2-3-50: 0.892\n",
      "-6: 3-2-8: 0.838\n",
      "-6: 3-2-32: 0.838\n",
      "-6: 3-2-50: 0.703\n",
      "-6: 3-3-8: 0.811\n",
      "-6: 3-3-32: 0.838\n",
      "-6: 3-3-50: 0.892\n",
      "-7: 2-2-16: 0.865\n",
      "-7: 2-3-16: 0.838\n",
      "-7: 2-4-16: 0.811\n",
      "-7: 3-2-16: 0.892\n",
      "-7: 4-2-16: 0.784\n",
      "-7: 3-3-16: 0.865\n",
      "-7: 4-3-16: 0.865\n",
      "-7: 2-2-8: 0.811\n",
      "-7: 2-2-32: 0.865\n",
      "-7: 2-2-50: 0.865\n",
      "-7: 2-3-8: 0.838\n",
      "-7: 2-3-32: 0.865\n",
      "-7: 2-3-50: 0.838\n",
      "-7: 3-2-8: 0.838\n",
      "-7: 3-2-32: 0.622\n",
      "-7: 3-2-50: 0.541\n",
      "-7: 3-3-8: 0.757\n",
      "-7: 3-3-32: 0.514\n",
      "-7: 3-3-50: 0.838\n",
      "-8: 2-2-16: 0.865\n",
      "-8: 2-3-16: 0.892\n",
      "-8: 2-4-16: 0.838\n",
      "-8: 3-2-16: 0.838\n",
      "-8: 4-2-16: 0.892\n",
      "-8: 3-3-16: 0.838\n",
      "-8: 4-3-16: 0.838\n",
      "-8: 2-2-8: 0.838\n",
      "-8: 2-2-32: 0.865\n",
      "-8: 2-2-50: 0.865\n",
      "-8: 2-3-8: 0.865\n",
      "-8: 2-3-32: 0.865\n",
      "-8: 2-3-50: 0.838\n",
      "-8: 3-2-8: 0.757\n",
      "-8: 3-2-32: 0.865\n",
      "-8: 3-2-50: 0.865\n",
      "-8: 3-3-8: 0.838\n",
      "-8: 3-3-32: 0.865\n",
      "-8: 3-3-50: 0.865\n",
      "-9: 2-2-16: 0.838\n",
      "-9: 2-3-16: 0.865\n",
      "-9: 2-4-16: 0.838\n",
      "-9: 3-2-16: 0.838\n",
      "-9: 4-2-16: 0.838\n",
      "-9: 3-3-16: 0.865\n",
      "-9: 4-3-16: 0.811\n",
      "-9: 2-2-8: 0.838\n",
      "-9: 2-2-32: 0.865\n",
      "-9: 2-2-50: 0.865\n",
      "-9: 2-3-8: 0.811\n",
      "-9: 2-3-32: 0.865\n",
      "-9: 2-3-50: 0.865\n",
      "-9: 3-2-8: 0.865\n",
      "-9: 3-2-32: 0.838\n",
      "-9: 3-2-50: 0.865\n",
      "-9: 3-3-8: 0.865\n",
      "-9: 3-3-32: 0.838\n",
      "-9: 3-3-50: 0.811\n",
      "-10: 2-2-16: 0.865\n",
      "-10: 2-3-16: 0.892\n",
      "-10: 2-4-16: 0.865\n",
      "-10: 3-2-16: 0.865\n",
      "-10: 4-2-16: 0.541\n",
      "-10: 3-3-16: 0.865\n",
      "-10: 4-3-16: 0.568\n",
      "-10: 2-2-8: 0.811\n",
      "-10: 2-2-32: 0.838\n",
      "-10: 2-2-50: 0.865\n",
      "-10: 2-3-8: 0.838\n",
      "-10: 2-3-32: 0.865\n",
      "-10: 2-3-50: 0.865\n",
      "-10: 3-2-8: 0.865\n",
      "-10: 3-2-32: 0.865\n",
      "-10: 3-2-50: 0.838\n",
      "-10: 3-3-8: 0.919\n",
      "-10: 3-3-32: 0.865\n",
      "-10: 3-3-50: 0.892\n",
      "-11: 2-2-16: 0.892\n",
      "-11: 2-3-16: 0.838\n",
      "-11: 2-4-16: 0.865\n",
      "-11: 3-2-16: 0.838\n",
      "-11: 4-2-16: 0.811\n",
      "-11: 3-3-16: 0.838\n",
      "-11: 4-3-16: 0.892\n",
      "-11: 2-2-8: 0.865\n",
      "-11: 2-2-32: 0.865\n",
      "-11: 2-2-50: 0.865\n",
      "-11: 2-3-8: 0.892\n",
      "-11: 2-3-32: 0.865\n",
      "-11: 2-3-50: 0.838\n",
      "-11: 3-2-8: 0.865\n",
      "-11: 3-2-32: 0.838\n",
      "-11: 3-2-50: 0.865\n",
      "-11: 3-3-8: 0.838\n",
      "-11: 3-3-32: 0.757\n",
      "-11: 3-3-50: 0.541\n",
      "-12: 2-2-16: 0.892\n",
      "-12: 2-3-16: 0.838\n",
      "-12: 2-4-16: 0.865\n",
      "-12: 3-2-16: 0.865\n",
      "-12: 4-2-16: 0.730\n",
      "-12: 3-3-16: 0.811\n",
      "-12: 4-3-16: 0.757\n",
      "-12: 2-2-8: 0.838\n",
      "-12: 2-2-32: 0.838\n",
      "-12: 2-2-50: 0.865\n",
      "-12: 2-3-8: 0.865\n",
      "-12: 2-3-32: 0.865\n",
      "-12: 2-3-50: 0.865\n",
      "-12: 3-2-8: 0.865\n",
      "-12: 3-2-32: 0.865\n",
      "-12: 3-2-50: 0.568\n",
      "-12: 3-3-8: 0.865\n",
      "-12: 3-3-32: 0.838\n",
      "-12: 3-3-50: 0.838\n",
      "-13: 2-2-16: 0.865\n",
      "-13: 2-3-16: 0.865\n",
      "-13: 2-4-16: 0.865\n",
      "-13: 3-2-16: 0.838\n",
      "-13: 4-2-16: 0.730\n",
      "-13: 3-3-16: 0.865\n",
      "-13: 4-3-16: 0.730\n",
      "-13: 2-2-8: 0.865\n",
      "-13: 2-2-32: 0.865\n",
      "-13: 2-2-50: 0.865\n",
      "-13: 2-3-8: 0.838\n",
      "-13: 2-3-32: 0.865\n",
      "-13: 2-3-50: 0.865\n",
      "-13: 3-2-8: 0.865\n",
      "-13: 3-2-32: 0.784\n",
      "-13: 3-2-50: 0.865\n",
      "-13: 3-3-8: 0.811\n",
      "-13: 3-3-32: 0.892\n",
      "-13: 3-3-50: 0.757\n",
      "-14: 2-2-16: 0.838\n",
      "-14: 2-3-16: 0.865\n",
      "-14: 2-4-16: 0.811\n",
      "-14: 3-2-16: 0.865\n",
      "-14: 4-2-16: 0.649\n",
      "-14: 3-3-16: 0.865\n",
      "-14: 4-3-16: 0.811\n",
      "-14: 2-2-8: 0.865\n",
      "-14: 2-2-32: 0.865\n",
      "-14: 2-2-50: 0.865\n",
      "-14: 2-3-8: 0.838\n",
      "-14: 2-3-32: 0.892\n",
      "-14: 2-3-50: 0.892\n",
      "-14: 3-2-8: 0.730\n",
      "-14: 3-2-32: 0.838\n",
      "-14: 3-2-50: 0.865\n",
      "-14: 3-3-8: 0.730\n",
      "-14: 3-3-32: 0.892\n",
      "-14: 3-3-50: 0.514\n",
      "-15: 2-2-16: 0.838\n",
      "-15: 2-3-16: 0.865\n",
      "-15: 2-4-16: 0.892\n",
      "-15: 3-2-16: 0.865\n",
      "-15: 4-2-16: 0.838\n",
      "-15: 3-3-16: 0.865\n",
      "-15: 4-3-16: 0.838\n",
      "-15: 2-2-8: 0.865\n",
      "-15: 2-2-32: 0.838\n",
      "-15: 2-2-50: 0.892\n",
      "-15: 2-3-8: 0.865\n",
      "-15: 2-3-32: 0.865\n",
      "-15: 2-3-50: 0.892\n",
      "-15: 3-2-8: 0.838\n",
      "-15: 3-2-32: 0.865\n",
      "-15: 3-2-50: 0.811\n",
      "-15: 3-3-8: 0.892\n",
      "-15: 3-3-32: 0.838\n",
      "-15: 3-3-50: 0.595\n",
      "-16: 2-2-16: 0.865\n",
      "-16: 2-3-16: 0.865\n",
      "-16: 2-4-16: 0.838\n",
      "-16: 3-2-16: 0.865\n",
      "-16: 4-2-16: 0.784\n",
      "-16: 3-3-16: 0.865\n",
      "-16: 4-3-16: 0.865\n",
      "-16: 2-2-8: 0.838\n",
      "-16: 2-2-32: 0.838\n",
      "-16: 2-2-50: 0.838\n",
      "-16: 2-3-8: 0.811\n",
      "-16: 2-3-32: 0.865\n",
      "-16: 2-3-50: 0.892\n",
      "-16: 3-2-8: 0.838\n",
      "-16: 3-2-32: 0.892\n",
      "-16: 3-2-50: 0.838\n",
      "-16: 3-3-8: 0.838\n",
      "-16: 3-3-32: 0.865\n",
      "-16: 3-3-50: 0.838\n",
      "-17: 2-2-16: 0.838\n",
      "-17: 2-3-16: 0.865\n",
      "-17: 2-4-16: 0.838\n",
      "-17: 3-2-16: 0.838\n",
      "-17: 4-2-16: 0.811\n",
      "-17: 3-3-16: 0.892\n",
      "-17: 4-3-16: 0.595\n",
      "-17: 2-2-8: 0.838\n",
      "-17: 2-2-32: 0.865\n",
      "-17: 2-2-50: 0.919\n",
      "-17: 2-3-8: 0.865\n",
      "-17: 2-3-32: 0.865\n",
      "-17: 2-3-50: 0.865\n",
      "-17: 3-2-8: 0.892\n",
      "-17: 3-2-32: 0.865\n",
      "-17: 3-2-50: 0.838\n",
      "-17: 3-3-8: 0.865\n",
      "-17: 3-3-32: 0.865\n",
      "-17: 3-3-50: 0.541\n",
      "-18: 2-2-16: 0.865\n",
      "-18: 2-3-16: 0.838\n",
      "-18: 2-4-16: 0.865\n",
      "-18: 3-2-16: 0.838\n",
      "-18: 4-2-16: 0.514\n",
      "-18: 3-3-16: 0.811\n",
      "-18: 4-3-16: 0.838\n",
      "-18: 2-2-8: 0.838\n",
      "-18: 2-2-32: 0.865\n",
      "-18: 2-2-50: 0.865\n",
      "-18: 2-3-8: 0.838\n",
      "-18: 2-3-32: 0.865\n",
      "-18: 2-3-50: 0.838\n",
      "-18: 3-2-8: 0.784\n",
      "-18: 3-2-32: 0.541\n",
      "-18: 3-2-50: 0.811\n",
      "-18: 3-3-8: 0.838\n",
      "-18: 3-3-32: 0.865\n",
      "-18: 3-3-50: 0.865\n",
      "-19: 2-2-16: 0.865\n",
      "-19: 2-3-16: 0.919\n",
      "-19: 2-4-16: 0.838\n",
      "-19: 3-2-16: 0.838\n",
      "-19: 4-2-16: 0.838\n",
      "-19: 3-3-16: 0.838\n",
      "-19: 4-3-16: 0.865\n",
      "-19: 2-2-8: 0.784\n",
      "-19: 2-2-32: 0.892\n",
      "-19: 2-2-50: 0.892\n",
      "-19: 2-3-8: 0.838\n",
      "-19: 2-3-32: 0.865\n",
      "-19: 2-3-50: 0.865\n",
      "-19: 3-2-8: 0.811\n",
      "-19: 3-2-32: 0.757\n",
      "-19: 3-2-50: 0.919\n",
      "-19: 3-3-8: 0.838\n",
      "-19: 3-3-32: 0.811\n",
      "-19: 3-3-50: 0.703\n",
      "-20: 2-2-16: 0.892\n",
      "-20: 2-3-16: 0.838\n",
      "-20: 2-4-16: 0.892\n",
      "-20: 3-2-16: 0.865\n",
      "-20: 4-2-16: 0.865\n",
      "-20: 3-3-16: 0.811\n",
      "-20: 4-3-16: 0.865\n",
      "-20: 2-2-8: 0.838\n",
      "-20: 2-2-32: 0.892\n",
      "-20: 2-2-50: 0.865\n",
      "-20: 2-3-8: 0.892\n",
      "-20: 2-3-32: 0.892\n",
      "-20: 2-3-50: 0.892\n",
      "-20: 3-2-8: 0.865\n",
      "-20: 3-2-32: 0.838\n",
      "-20: 3-2-50: 0.892\n",
      "-20: 3-3-8: 0.757\n",
      "-20: 3-3-32: 0.838\n",
      "-20: 3-3-50: 0.838\n",
      "-21: 2-2-16: 0.838\n",
      "-21: 2-3-16: 0.838\n",
      "-21: 2-4-16: 0.838\n",
      "-21: 3-2-16: 0.865\n",
      "-21: 4-2-16: 0.811\n",
      "-21: 3-3-16: 0.865\n",
      "-21: 4-3-16: 0.568\n",
      "-21: 2-2-8: 0.838\n",
      "-21: 2-2-32: 0.892\n",
      "-21: 2-2-50: 0.892\n",
      "-21: 2-3-8: 0.838\n",
      "-21: 2-3-32: 0.892\n",
      "-21: 2-3-50: 0.865\n",
      "-21: 3-2-8: 0.838\n",
      "-21: 3-2-32: 0.892\n",
      "-21: 3-2-50: 0.757\n",
      "-21: 3-3-8: 0.838\n",
      "-21: 3-3-32: 0.838\n",
      "-21: 3-3-50: 0.838\n",
      "-22: 2-2-16: 0.892\n",
      "-22: 2-3-16: 0.838\n",
      "-22: 2-4-16: 0.784\n",
      "-22: 3-2-16: 0.838\n",
      "-22: 4-2-16: 0.838\n",
      "-22: 3-3-16: 0.919\n",
      "-22: 4-3-16: 0.838\n",
      "-22: 2-2-8: 0.865\n",
      "-22: 2-2-32: 0.865\n",
      "-22: 2-2-50: 0.865\n",
      "-22: 2-3-8: 0.865\n",
      "-22: 2-3-32: 0.865\n",
      "-22: 2-3-50: 0.865\n",
      "-22: 3-2-8: 0.865\n",
      "-22: 3-2-32: 0.811\n",
      "-22: 3-2-50: 0.838\n",
      "-22: 3-3-8: 0.568\n",
      "-22: 3-3-32: 0.811\n",
      "-22: 3-3-50: 0.784\n",
      "-23: 2-2-16: 0.838\n",
      "-23: 2-3-16: 0.838\n",
      "-23: 2-4-16: 0.865\n",
      "-23: 3-2-16: 0.865\n",
      "-23: 4-2-16: 0.838\n",
      "-23: 3-3-16: 0.838\n",
      "-23: 4-3-16: 0.784\n",
      "-23: 2-2-8: 0.838\n",
      "-23: 2-2-32: 0.865\n",
      "-23: 2-2-50: 0.892\n",
      "-23: 2-3-8: 0.865\n",
      "-23: 2-3-32: 0.838\n",
      "-23: 2-3-50: 0.892\n",
      "-23: 3-2-8: 0.838\n",
      "-23: 3-2-32: 0.757\n",
      "-23: 3-2-50: 0.811\n",
      "-23: 3-3-8: 0.838\n",
      "-23: 3-3-32: 0.865\n",
      "-23: 3-3-50: 0.838\n",
      "-24: 2-2-16: 0.838\n",
      "-24: 2-3-16: 0.838\n",
      "-24: 2-4-16: 0.865\n",
      "-24: 3-2-16: 0.838\n",
      "-24: 4-2-16: 0.892\n",
      "-24: 3-3-16: 0.811\n",
      "-24: 4-3-16: 0.838\n",
      "-24: 2-2-8: 0.838\n",
      "-24: 2-2-32: 0.865\n",
      "-24: 2-2-50: 0.892\n",
      "-24: 2-3-8: 0.892\n",
      "-24: 2-3-32: 0.811\n",
      "-24: 2-3-50: 0.892\n",
      "-24: 3-2-8: 0.865\n",
      "-24: 3-2-32: 0.811\n",
      "-24: 3-2-50: 0.865\n",
      "-24: 3-3-8: 0.838\n",
      "-24: 3-3-32: 0.730\n",
      "-24: 3-3-50: 0.541\n",
      "-25: 2-2-16: 0.865\n",
      "-25: 2-3-16: 0.892\n",
      "-25: 2-4-16: 0.838\n",
      "-25: 3-2-16: 0.811\n",
      "-25: 4-2-16: 0.838\n",
      "-25: 3-3-16: 0.838\n",
      "-25: 4-3-16: 0.865\n",
      "-25: 2-2-8: 0.865\n",
      "-25: 2-2-32: 0.865\n",
      "-25: 2-2-50: 0.865\n",
      "-25: 2-3-8: 0.838\n",
      "-25: 2-3-32: 0.865\n",
      "-25: 2-3-50: 0.838\n",
      "-25: 3-2-8: 0.838\n",
      "-25: 3-2-32: 0.811\n",
      "-25: 3-2-50: 0.838\n",
      "-25: 3-3-8: 0.730\n",
      "-25: 3-3-32: 0.865\n",
      "-25: 3-3-50: 0.541\n",
      "----- 9.18 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'L': 2, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 4, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 3, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 50},\n",
    "        ]\n",
    "\n",
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, exp['hid_dim'], OUT_DIM, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  exp['K'], masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}: {best_accs[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs.mean(axis=1)\n",
    "std_accs = best_accs.std(axis=1)\n",
    "index_name = [f'{exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}' for exp in EXPS]\n",
    "table3 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-2-16</th>\n",
       "      <td>0.858378</td>\n",
       "      <td>0.019157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-16</th>\n",
       "      <td>0.859459</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-4-16</th>\n",
       "      <td>0.848649</td>\n",
       "      <td>0.026481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-16</th>\n",
       "      <td>0.851892</td>\n",
       "      <td>0.018911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2-16</th>\n",
       "      <td>0.787027</td>\n",
       "      <td>0.093099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-16</th>\n",
       "      <td>0.838919</td>\n",
       "      <td>0.066852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-3-16</th>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.092998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-8</th>\n",
       "      <td>0.835676</td>\n",
       "      <td>0.021513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-32</th>\n",
       "      <td>0.862703</td>\n",
       "      <td>0.015135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-50</th>\n",
       "      <td>0.869189</td>\n",
       "      <td>0.018219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-8</th>\n",
       "      <td>0.841081</td>\n",
       "      <td>0.065009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-32</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.017093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-50</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.020907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-8</th>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.035855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-32</th>\n",
       "      <td>0.817297</td>\n",
       "      <td>0.079178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-50</th>\n",
       "      <td>0.819459</td>\n",
       "      <td>0.089384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-8</th>\n",
       "      <td>0.812973</td>\n",
       "      <td>0.067044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-32</th>\n",
       "      <td>0.829189</td>\n",
       "      <td>0.075180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-50</th>\n",
       "      <td>0.734054</td>\n",
       "      <td>0.138800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean accs       std\n",
       "2-2-16   0.858378  0.019157\n",
       "2-3-16   0.859459  0.021622\n",
       "2-4-16   0.848649  0.026481\n",
       "3-2-16   0.851892  0.018911\n",
       "4-2-16   0.787027  0.093099\n",
       "3-3-16   0.838919  0.066852\n",
       "4-3-16   0.805405  0.092998\n",
       "2-2-8    0.835676  0.021513\n",
       "2-2-32   0.862703  0.015135\n",
       "2-2-50   0.869189  0.018219\n",
       "2-3-8    0.841081  0.065009\n",
       "2-3-32   0.864865  0.017093\n",
       "2-3-50   0.863784  0.020907\n",
       "3-2-8    0.837838  0.035855\n",
       "3-2-32   0.817297  0.079178\n",
       "3-2-50   0.819459  0.089384\n",
       "3-3-8    0.812973  0.067044\n",
       "3-3-32   0.829189  0.075180\n",
       "3-3-50   0.734054  0.138800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearities and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-1: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-1: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.622\n",
      "-1: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-1: ReLU()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-1: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-1: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-1: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-1: Identity()-Identity()-CrossEntropyLoss(): 0.459\n",
      "-2: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-2: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-2: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-2: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.676\n",
      "-2: ReLU()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-2: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-2: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-2: Identity()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-2: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-3: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-3: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-3: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-3: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.541\n",
      "-3: ReLU()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-3: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.919\n",
      "-3: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-3: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-3: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-4: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-4: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-4: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.514\n",
      "-4: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.486\n",
      "-4: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-4: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-4: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-4: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-4: Identity()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-5: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-5: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-5: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-5: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649\n",
      "-5: ReLU()-Identity()-CrossEntropyLoss(): 0.676\n",
      "-5: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-5: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-5: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-5: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-6: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-6: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-6: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.676\n",
      "-6: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.595\n",
      "-6: ReLU()-Identity()-CrossEntropyLoss(): 0.730\n",
      "-6: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-6: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.784\n",
      "-6: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-6: Identity()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-7: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-7: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-7: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.541\n",
      "-7: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-7: ReLU()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-7: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-7: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-7: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-7: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-8: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-8: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-8: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.541\n",
      "-8: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-8: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-8: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-8: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-8: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-8: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-9: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-9: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-9: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.649\n",
      "-9: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649\n",
      "-9: ReLU()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-9: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-9: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-9: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-9: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-10: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-10: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-10: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-10: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.622\n",
      "-10: ReLU()-Identity()-CrossEntropyLoss(): 0.730\n",
      "-10: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-10: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-10: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-10: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-11: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-11: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-11: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.459\n",
      "-11: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.703\n",
      "-11: ReLU()-Identity()-CrossEntropyLoss(): 0.730\n",
      "-11: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-11: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-11: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-11: Identity()-Identity()-CrossEntropyLoss(): 0.432\n",
      "-12: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-12: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-12: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.541\n",
      "-12: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.541\n",
      "-12: ReLU()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-12: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-12: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-12: Identity()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-12: Identity()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-13: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-13: ReLU()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-13: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.676\n",
      "-13: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-13: ReLU()-Identity()-CrossEntropyLoss(): 0.676\n",
      "-13: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-13: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.676\n",
      "-13: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-13: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-14: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-14: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-14: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.514\n",
      "-14: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.595\n",
      "-14: ReLU()-Identity()-CrossEntropyLoss(): 0.622\n",
      "-14: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-14: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-14: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-14: Identity()-Identity()-CrossEntropyLoss(): 0.622\n",
      "-15: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-15: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-15: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-15: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-15: ReLU()-Identity()-CrossEntropyLoss(): 0.676\n",
      "-15: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-15: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-15: Identity()-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-15: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-16: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-16: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-16: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.486\n",
      "-16: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.595\n",
      "-16: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-16: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-16: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-16: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-16: Identity()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-17: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-17: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-17: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.622\n",
      "-17: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-17: ReLU()-Identity()-CrossEntropyLoss(): 0.649\n",
      "-17: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-17: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.703\n",
      "-17: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-17: Identity()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-18: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-18: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-18: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-18: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-18: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-18: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-18: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-18: Identity()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-18: Identity()-Identity()-CrossEntropyLoss(): 0.459\n",
      "-19: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.757\n",
      "-19: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811\n",
      "-19: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.459\n",
      "-19: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514\n",
      "-19: ReLU()-Identity()-CrossEntropyLoss(): 0.649\n",
      "-19: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-19: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-19: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-19: Identity()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-20: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-20: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-20: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-20: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.676\n",
      "-20: ReLU()-Identity()-CrossEntropyLoss(): 0.514\n",
      "-20: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-20: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-20: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-20: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-21: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-21: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-21: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-21: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649\n",
      "-21: ReLU()-Identity()-CrossEntropyLoss(): 0.595\n",
      "-21: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-21: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-21: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-21: Identity()-Identity()-CrossEntropyLoss(): 0.432\n",
      "-22: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-22: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-22: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595\n",
      "-22: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.676\n",
      "-22: ReLU()-Identity()-CrossEntropyLoss(): 0.405\n",
      "-22: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.919\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-22: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-22: Identity()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-22: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-23: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-23: ReLU()-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-23: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.541\n",
      "-23: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-23: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-23: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-23: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-23: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-23: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "-24: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-24: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-24: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.568\n",
      "-24: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649\n",
      "-24: ReLU()-Identity()-CrossEntropyLoss(): 0.622\n",
      "-24: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-24: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.892\n",
      "-24: Identity()-Softmax(dim=1)-NLLLoss(): 0.919\n",
      "-24: Identity()-Identity()-CrossEntropyLoss(): 0.486\n",
      "-25: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-25: ReLU()-Softmax(dim=1)-NLLLoss(): 0.892\n",
      "-25: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.514\n",
      "-25: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.568\n",
      "-25: ReLU()-Identity()-CrossEntropyLoss(): 0.568\n",
      "-25: ReLU()-Identity()-NLLLoss(): 0.405\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.865\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.865\n",
      "-25: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.838\n",
      "-25: Identity()-Softmax(dim=1)-NLLLoss(): 0.838\n",
      "-25: Identity()-Identity()-CrossEntropyLoss(): 0.541\n",
      "----- 5.59 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},]\n",
    "\n",
    "best_accs4 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=exp['act'], last_act=exp['lact'],\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  K, masks, exp['loss'], device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs4[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}: {best_accs4[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs4.mean(axis=1)\n",
    "std_accs = best_accs4.std(axis=1)\n",
    "index_name = [f'{exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}' for exp in EXPS]\n",
    "table4 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.028603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.019459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.057205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.588108</td>\n",
       "      <td>0.062235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.602162</td>\n",
       "      <td>0.074712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-NLLLoss()</th>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.872432</td>\n",
       "      <td>0.025946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.022261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.022933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.871351</td>\n",
       "      <td>0.020626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.842162</td>\n",
       "      <td>0.051098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.852973</td>\n",
       "      <td>0.024270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.527568</td>\n",
       "      <td>0.045302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean accs       std\n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()             0.864865  0.028603\n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                      0.863784  0.019459\n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()          0.567568  0.057205\n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                   0.588108  0.062235\n",
       "ReLU()-Identity()-CrossEntropyLoss()                 0.602162  0.074712\n",
       "ReLU()-Identity()-NLLLoss()                          0.405405  0.000000\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()     0.872432  0.025946\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()              0.863784  0.022261\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...   0.864865  0.022933\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...   0.871351  0.020626\n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()         0.842162  0.051098\n",
       "Identity()-Softmax(dim=1)-NLLLoss()                  0.852973  0.024270\n",
       "Identity()-Identity()-CrossEntropyLoss()             0.527568  0.045302"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the GSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BEST PARAMETERS\n",
    "# ## Reaining params\n",
    "# N_RUNS = 25\n",
    "# N_EPOCHS = 200\n",
    "# LR = .05\n",
    "# WD = .01\n",
    "# DROPOUT = 0\n",
    "\n",
    "# # BEST PARAMETERS\n",
    "# ## Architecture params\n",
    "# N_LAYERS = 2\n",
    "# K = 2\n",
    "# HID_DIM = 16\n",
    "\n",
    "# ## Model params\n",
    "# h0 = 1\n",
    "NORM = True\n",
    "\n",
    "# IN_DIM = feat.shape[1]\n",
    "# OUT_DIM = n_class\n",
    "\n",
    "\n",
    "# ACT = nn.ReLU()\n",
    "# LAST_ACT = nn.Softmax(dim=1)\n",
    "# LOSS_FN = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 200-0.1-0.0005: 0.270\n",
      "-1: 200-0.05-0.0005: 0.270\n",
      "-1: 200-0.01-0.0005: 0.270\n",
      "-1: 200-0.005-0.0005: 0.270\n",
      "-1: 200-0.05-0.001: 0.270\n",
      "-1: 200-0.01-0.001: 0.270\n",
      "-1: 200-0.05-0.01: 0.270\n",
      "-1: 200-0.01-0.01: 0.270\n",
      "-1: 200-0.05-0.05: 0.270\n",
      "-1: 200-0.01-0.05: 0.270\n",
      "-1: 500-0.05-0.0005: 0.270\n",
      "-1: 500-0.01-0.0005: 0.270\n",
      "-1: 500-0.05-0.01: 0.270\n",
      "-1: 500-0.01-0.01: 0.270\n",
      "-2: 200-0.1-0.0005: 0.270\n",
      "-2: 200-0.05-0.0005: 0.270\n",
      "-2: 200-0.01-0.0005: 0.270\n",
      "-2: 200-0.005-0.0005: 0.270\n",
      "-2: 200-0.05-0.001: 0.270\n",
      "-2: 200-0.01-0.001: 0.270\n",
      "-2: 200-0.05-0.01: 0.270\n",
      "-2: 200-0.01-0.01: 0.270\n",
      "-2: 200-0.05-0.05: 0.270\n",
      "-2: 200-0.01-0.05: 0.270\n",
      "-2: 500-0.05-0.0005: 0.270\n",
      "-2: 500-0.01-0.0005: 0.270\n",
      "-2: 500-0.05-0.01: 0.270\n",
      "-2: 500-0.01-0.01: 0.270\n",
      "-3: 200-0.1-0.0005: 0.270\n",
      "-3: 200-0.05-0.0005: 0.270\n",
      "-3: 200-0.01-0.0005: 0.270\n",
      "-3: 200-0.005-0.0005: 0.270\n",
      "-3: 200-0.05-0.001: 0.270\n",
      "-3: 200-0.01-0.001: 0.270\n",
      "-3: 200-0.05-0.01: 0.270\n",
      "-3: 200-0.01-0.01: 0.270\n",
      "-3: 200-0.05-0.05: 0.270\n",
      "-3: 200-0.01-0.05: 0.270\n",
      "-3: 500-0.05-0.0005: 0.270\n",
      "-3: 500-0.01-0.0005: 0.270\n",
      "-3: 500-0.05-0.01: 0.270\n",
      "-3: 500-0.01-0.01: 0.270\n",
      "-4: 200-0.1-0.0005: 0.270\n",
      "-4: 200-0.05-0.0005: 0.270\n",
      "-4: 200-0.01-0.0005: 0.270\n",
      "-4: 200-0.005-0.0005: 0.270\n",
      "-4: 200-0.05-0.001: 0.270\n",
      "-4: 200-0.01-0.001: 0.270\n",
      "-4: 200-0.05-0.01: 0.270\n",
      "-4: 200-0.01-0.01: 0.270\n",
      "-4: 200-0.05-0.05: 0.270\n",
      "-4: 200-0.01-0.05: 0.270\n",
      "-4: 500-0.05-0.0005: 0.270\n",
      "-4: 500-0.01-0.0005: 0.270\n",
      "-4: 500-0.05-0.01: 0.270\n",
      "-4: 500-0.01-0.01: 0.270\n",
      "-5: 200-0.1-0.0005: 0.270\n",
      "-5: 200-0.05-0.0005: 0.270\n",
      "-5: 200-0.01-0.0005: 0.270\n",
      "-5: 200-0.005-0.0005: 0.270\n",
      "-5: 200-0.05-0.001: 0.270\n",
      "-5: 200-0.01-0.001: 0.270\n",
      "-5: 200-0.05-0.01: 0.270\n",
      "-5: 200-0.01-0.01: 0.270\n",
      "-5: 200-0.05-0.05: 0.270\n",
      "-5: 200-0.01-0.05: 0.270\n",
      "-5: 500-0.05-0.0005: 0.270\n",
      "-5: 500-0.01-0.0005: 0.270\n",
      "-5: 500-0.05-0.01: 0.270\n",
      "-5: 500-0.01-0.01: 0.270\n",
      "-6: 200-0.1-0.0005: 0.270\n",
      "-6: 200-0.05-0.0005: 0.270\n",
      "-6: 200-0.01-0.0005: 0.270\n",
      "-6: 200-0.005-0.0005: 0.270\n",
      "-6: 200-0.05-0.001: 0.270\n",
      "-6: 200-0.01-0.001: 0.270\n",
      "-6: 200-0.05-0.01: 0.270\n",
      "-6: 200-0.01-0.01: 0.270\n",
      "-6: 200-0.05-0.05: 0.270\n",
      "-6: 200-0.01-0.05: 0.270\n",
      "-6: 500-0.05-0.0005: 0.270\n",
      "-6: 500-0.01-0.0005: 0.270\n",
      "-6: 500-0.05-0.01: 0.270\n",
      "-6: 500-0.01-0.01: 0.270\n",
      "-7: 200-0.1-0.0005: 0.270\n",
      "-7: 200-0.05-0.0005: 0.270\n",
      "-7: 200-0.01-0.0005: 0.270\n",
      "-7: 200-0.005-0.0005: 0.270\n",
      "-7: 200-0.05-0.001: 0.270\n",
      "-7: 200-0.01-0.001: 0.270\n",
      "-7: 200-0.05-0.01: 0.270\n",
      "-7: 200-0.01-0.01: 0.270\n",
      "-7: 200-0.05-0.05: 0.270\n",
      "-7: 200-0.01-0.05: 0.270\n",
      "-7: 500-0.05-0.0005: 0.270\n",
      "-7: 500-0.01-0.0005: 0.270\n",
      "-7: 500-0.05-0.01: 0.270\n",
      "-7: 500-0.01-0.01: 0.270\n",
      "-8: 200-0.1-0.0005: 0.270\n",
      "-8: 200-0.05-0.0005: 0.270\n",
      "-8: 200-0.01-0.0005: 0.270\n",
      "-8: 200-0.005-0.0005: 0.270\n",
      "-8: 200-0.05-0.001: 0.270\n",
      "-8: 200-0.01-0.001: 0.270\n",
      "-8: 200-0.05-0.01: 0.270\n",
      "-8: 200-0.01-0.01: 0.270\n",
      "-8: 200-0.05-0.05: 0.270\n",
      "-8: 200-0.01-0.05: 0.270\n",
      "-8: 500-0.05-0.0005: 0.270\n",
      "-8: 500-0.01-0.0005: 0.270\n",
      "-8: 500-0.05-0.01: 0.270\n",
      "-8: 500-0.01-0.01: 0.270\n",
      "-9: 200-0.1-0.0005: 0.270\n",
      "-9: 200-0.05-0.0005: 0.270\n",
      "-9: 200-0.01-0.0005: 0.270\n",
      "-9: 200-0.005-0.0005: 0.270\n",
      "-9: 200-0.05-0.001: 0.270\n",
      "-9: 200-0.01-0.001: 0.270\n",
      "-9: 200-0.05-0.01: 0.270\n",
      "-9: 200-0.01-0.01: 0.270\n",
      "-9: 200-0.05-0.05: 0.270\n",
      "-9: 200-0.01-0.05: 0.270\n",
      "-9: 500-0.05-0.0005: 0.270\n",
      "-9: 500-0.01-0.0005: 0.270\n",
      "-9: 500-0.05-0.01: 0.270\n",
      "-9: 500-0.01-0.01: 0.270\n",
      "-10: 200-0.1-0.0005: 0.270\n",
      "-10: 200-0.05-0.0005: 0.270\n",
      "-10: 200-0.01-0.0005: 0.270\n",
      "-10: 200-0.005-0.0005: 0.270\n",
      "-10: 200-0.05-0.001: 0.270\n",
      "-10: 200-0.01-0.001: 0.270\n",
      "-10: 200-0.05-0.01: 0.270\n",
      "-10: 200-0.01-0.01: 0.270\n",
      "-10: 200-0.05-0.05: 0.270\n",
      "-10: 200-0.01-0.05: 0.270\n",
      "-10: 500-0.05-0.0005: 0.270\n",
      "-10: 500-0.01-0.0005: 0.270\n",
      "-10: 500-0.05-0.01: 0.270\n",
      "-10: 500-0.01-0.01: 0.270\n",
      "-11: 200-0.1-0.0005: 0.270\n",
      "-11: 200-0.05-0.0005: 0.270\n",
      "-11: 200-0.01-0.0005: 0.270\n",
      "-11: 200-0.005-0.0005: 0.270\n",
      "-11: 200-0.05-0.001: 0.270\n",
      "-11: 200-0.01-0.001: 0.270\n",
      "-11: 200-0.05-0.01: 0.270\n",
      "-11: 200-0.01-0.01: 0.270\n",
      "-11: 200-0.05-0.05: 0.270\n",
      "-11: 200-0.01-0.05: 0.270\n",
      "-11: 500-0.05-0.0005: 0.270\n",
      "-11: 500-0.01-0.0005: 0.270\n",
      "-11: 500-0.05-0.01: 0.270\n",
      "-11: 500-0.01-0.01: 0.270\n",
      "-12: 200-0.1-0.0005: 0.270\n",
      "-12: 200-0.05-0.0005: 0.270\n",
      "-12: 200-0.01-0.0005: 0.270\n",
      "-12: 200-0.005-0.0005: 0.270\n",
      "-12: 200-0.05-0.001: 0.270\n",
      "-12: 200-0.01-0.001: 0.270\n",
      "-12: 200-0.05-0.01: 0.270\n",
      "-12: 200-0.01-0.01: 0.270\n",
      "-12: 200-0.05-0.05: 0.270\n",
      "-12: 200-0.01-0.05: 0.270\n",
      "-12: 500-0.05-0.0005: 0.270\n",
      "-12: 500-0.01-0.0005: 0.270\n",
      "-12: 500-0.05-0.01: 0.270\n",
      "-12: 500-0.01-0.01: 0.270\n",
      "-13: 200-0.1-0.0005: 0.270\n",
      "-13: 200-0.05-0.0005: 0.270\n",
      "-13: 200-0.01-0.0005: 0.270\n",
      "-13: 200-0.005-0.0005: 0.270\n",
      "-13: 200-0.05-0.001: 0.270\n",
      "-13: 200-0.01-0.001: 0.270\n",
      "-13: 200-0.05-0.01: 0.270\n",
      "-13: 200-0.01-0.01: 0.270\n",
      "-13: 200-0.05-0.05: 0.270\n",
      "-13: 200-0.01-0.05: 0.270\n",
      "-13: 500-0.05-0.0005: 0.270\n",
      "-13: 500-0.01-0.0005: 0.270\n",
      "-13: 500-0.05-0.01: 0.270\n",
      "-13: 500-0.01-0.01: 0.270\n",
      "-14: 200-0.1-0.0005: 0.270\n",
      "-14: 200-0.05-0.0005: 0.270\n",
      "-14: 200-0.01-0.0005: 0.270\n",
      "-14: 200-0.005-0.0005: 0.270\n",
      "-14: 200-0.05-0.001: 0.270\n",
      "-14: 200-0.01-0.001: 0.270\n",
      "-14: 200-0.05-0.01: 0.270\n",
      "-14: 200-0.01-0.01: 0.270\n",
      "-14: 200-0.05-0.05: 0.270\n",
      "-14: 200-0.01-0.05: 0.270\n",
      "-14: 500-0.05-0.0005: 0.270\n",
      "-14: 500-0.01-0.0005: 0.270\n",
      "-14: 500-0.05-0.01: 0.270\n",
      "-14: 500-0.01-0.01: 0.270\n",
      "-15: 200-0.1-0.0005: 0.270\n",
      "-15: 200-0.05-0.0005: 0.270\n",
      "-15: 200-0.01-0.0005: 0.270\n",
      "-15: 200-0.005-0.0005: 0.270\n",
      "-15: 200-0.05-0.001: 0.270\n",
      "-15: 200-0.01-0.001: 0.270\n",
      "-15: 200-0.05-0.01: 0.270\n",
      "-15: 200-0.01-0.01: 0.270\n",
      "-15: 200-0.05-0.05: 0.270\n",
      "-15: 200-0.01-0.05: 0.270\n",
      "-15: 500-0.05-0.0005: 0.270\n",
      "-15: 500-0.01-0.0005: 0.270\n",
      "-15: 500-0.05-0.01: 0.270\n",
      "-15: 500-0.01-0.01: 0.270\n",
      "-16: 200-0.1-0.0005: 0.270\n",
      "-16: 200-0.05-0.0005: 0.270\n",
      "-16: 200-0.01-0.0005: 0.270\n",
      "-16: 200-0.005-0.0005: 0.270\n",
      "-16: 200-0.05-0.001: 0.270\n",
      "-16: 200-0.01-0.001: 0.270\n",
      "-16: 200-0.05-0.01: 0.270\n",
      "-16: 200-0.01-0.01: 0.270\n",
      "-16: 200-0.05-0.05: 0.270\n",
      "-16: 200-0.01-0.05: 0.270\n",
      "-16: 500-0.05-0.0005: 0.270\n",
      "-16: 500-0.01-0.0005: 0.270\n",
      "-16: 500-0.05-0.01: 0.270\n",
      "-16: 500-0.01-0.01: 0.270\n",
      "-17: 200-0.1-0.0005: 0.270\n",
      "-17: 200-0.05-0.0005: 0.270\n",
      "-17: 200-0.01-0.0005: 0.270\n",
      "-17: 200-0.005-0.0005: 0.270\n",
      "-17: 200-0.05-0.001: 0.270\n",
      "-17: 200-0.01-0.001: 0.270\n",
      "-17: 200-0.05-0.01: 0.270\n",
      "-17: 200-0.01-0.01: 0.270\n",
      "-17: 200-0.05-0.05: 0.270\n",
      "-17: 200-0.01-0.05: 0.270\n",
      "-17: 500-0.05-0.0005: 0.270\n",
      "-17: 500-0.01-0.0005: 0.270\n",
      "-17: 500-0.05-0.01: 0.270\n",
      "-17: 500-0.01-0.01: 0.270\n",
      "-18: 200-0.1-0.0005: 0.270\n",
      "-18: 200-0.05-0.0005: 0.270\n",
      "-18: 200-0.01-0.0005: 0.270\n",
      "-18: 200-0.005-0.0005: 0.270\n",
      "-18: 200-0.05-0.001: 0.270\n",
      "-18: 200-0.01-0.001: 0.270\n",
      "-18: 200-0.05-0.01: 0.270\n",
      "-18: 200-0.01-0.01: 0.270\n",
      "-18: 200-0.05-0.05: 0.270\n",
      "-18: 200-0.01-0.05: 0.270\n",
      "-18: 500-0.05-0.0005: 0.270\n",
      "-18: 500-0.01-0.0005: 0.270\n",
      "-18: 500-0.05-0.01: 0.270\n",
      "-18: 500-0.01-0.01: 0.270\n",
      "-19: 200-0.1-0.0005: 0.270\n",
      "-19: 200-0.05-0.0005: 0.270\n",
      "-19: 200-0.01-0.0005: 0.270\n",
      "-19: 200-0.005-0.0005: 0.270\n",
      "-19: 200-0.05-0.001: 0.270\n",
      "-19: 200-0.01-0.001: 0.270\n",
      "-19: 200-0.05-0.01: 0.270\n",
      "-19: 200-0.01-0.01: 0.270\n",
      "-19: 200-0.05-0.05: 0.270\n",
      "-19: 200-0.01-0.05: 0.270\n",
      "-19: 500-0.05-0.0005: 0.270\n",
      "-19: 500-0.01-0.0005: 0.270\n",
      "-19: 500-0.05-0.01: 0.270\n",
      "-19: 500-0.01-0.01: 0.270\n",
      "-20: 200-0.1-0.0005: 0.270\n",
      "-20: 200-0.05-0.0005: 0.270\n",
      "-20: 200-0.01-0.0005: 0.270\n",
      "-20: 200-0.005-0.0005: 0.270\n",
      "-20: 200-0.05-0.001: 0.270\n",
      "-20: 200-0.01-0.001: 0.270\n",
      "-20: 200-0.05-0.01: 0.270\n",
      "-20: 200-0.01-0.01: 0.270\n",
      "-20: 200-0.05-0.05: 0.270\n",
      "-20: 200-0.01-0.05: 0.270\n",
      "-20: 500-0.05-0.0005: 0.270\n",
      "-20: 500-0.01-0.0005: 0.270\n",
      "-20: 500-0.05-0.01: 0.270\n",
      "-20: 500-0.01-0.01: 0.270\n",
      "-21: 200-0.1-0.0005: 0.270\n",
      "-21: 200-0.05-0.0005: 0.270\n",
      "-21: 200-0.01-0.0005: 0.270\n",
      "-21: 200-0.005-0.0005: 0.270\n",
      "-21: 200-0.05-0.001: 0.270\n",
      "-21: 200-0.01-0.001: 0.270\n",
      "-21: 200-0.05-0.01: 0.270\n",
      "-21: 200-0.01-0.01: 0.270\n",
      "-21: 200-0.05-0.05: 0.270\n",
      "-21: 200-0.01-0.05: 0.270\n",
      "-21: 500-0.05-0.0005: 0.270\n",
      "-21: 500-0.01-0.0005: 0.270\n",
      "-21: 500-0.05-0.01: 0.270\n",
      "-21: 500-0.01-0.01: 0.270\n",
      "-22: 200-0.1-0.0005: 0.270\n",
      "-22: 200-0.05-0.0005: 0.270\n",
      "-22: 200-0.01-0.0005: 0.270\n",
      "-22: 200-0.005-0.0005: 0.270\n",
      "-22: 200-0.05-0.001: 0.270\n",
      "-22: 200-0.01-0.001: 0.270\n",
      "-22: 200-0.05-0.01: 0.270\n",
      "-22: 200-0.01-0.01: 0.270\n",
      "-22: 200-0.05-0.05: 0.270\n",
      "-22: 200-0.01-0.05: 0.270\n",
      "-22: 500-0.05-0.0005: 0.270\n",
      "-22: 500-0.01-0.0005: 0.270\n",
      "-22: 500-0.05-0.01: 0.270\n",
      "-22: 500-0.01-0.01: 0.270\n",
      "-23: 200-0.1-0.0005: 0.270\n",
      "-23: 200-0.05-0.0005: 0.270\n",
      "-23: 200-0.01-0.0005: 0.270\n",
      "-23: 200-0.005-0.0005: 0.270\n",
      "-23: 200-0.05-0.001: 0.270\n",
      "-23: 200-0.01-0.001: 0.270\n",
      "-23: 200-0.05-0.01: 0.270\n",
      "-23: 200-0.01-0.01: 0.270\n",
      "-23: 200-0.05-0.05: 0.270\n",
      "-23: 200-0.01-0.05: 0.270\n",
      "-23: 500-0.05-0.0005: 0.270\n",
      "-23: 500-0.01-0.0005: 0.270\n",
      "-23: 500-0.05-0.01: 0.270\n",
      "-23: 500-0.01-0.01: 0.270\n",
      "-24: 200-0.1-0.0005: 0.270\n",
      "-24: 200-0.05-0.0005: 0.270\n",
      "-24: 200-0.01-0.0005: 0.270\n",
      "-24: 200-0.005-0.0005: 0.270\n",
      "-24: 200-0.05-0.001: 0.270\n",
      "-24: 200-0.01-0.001: 0.270\n",
      "-24: 200-0.05-0.01: 0.270\n",
      "-24: 200-0.01-0.01: 0.270\n",
      "-24: 200-0.05-0.05: 0.270\n",
      "-24: 200-0.01-0.05: 0.270\n",
      "-24: 500-0.05-0.0005: 0.270\n",
      "-24: 500-0.01-0.0005: 0.270\n",
      "-24: 500-0.05-0.01: 0.270\n",
      "-24: 500-0.01-0.01: 0.270\n",
      "-25: 200-0.1-0.0005: 0.270\n",
      "-25: 200-0.05-0.0005: 0.270\n",
      "-25: 200-0.01-0.0005: 0.270\n",
      "-25: 200-0.005-0.0005: 0.270\n",
      "-25: 200-0.05-0.001: 0.270\n",
      "-25: 200-0.01-0.001: 0.270\n",
      "-25: 200-0.05-0.01: 0.270\n",
      "-25: 200-0.01-0.01: 0.270\n",
      "-25: 200-0.05-0.05: 0.270\n",
      "-25: 200-0.01-0.05: 0.270\n",
      "-25: 500-0.05-0.0005: 0.270\n",
      "-25: 500-0.01-0.0005: 0.270\n",
      "-25: 500-0.05-0.01: 0.270\n",
      "-25: 500-0.01-0.01: 0.270\n",
      "----- 7.61 mins -----\n"
     ]
    }
   ],
   "source": [
    "EXPS = [{'epochs': 200, 'lr': .1, 'wd': 5e-4},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 5e-4},\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 5e-4},\n",
    "        \n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-3},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 1e-3},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-2},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 1e-2},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-2},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 5e-2},\n",
    "        \n",
    "        {'epochs': 500, 'lr': .05, 'wd': 5e-4},\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 5e-4},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2},\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 1e-2},]\n",
    "\n",
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'])\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}: {best_accs[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs.mean(axis=1)\n",
    "std_accs = best_accs.std(axis=1)\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}' for exp in EXPS]\n",
    "table5 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.001</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.001</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.01</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.05</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.05</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.0005</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.01</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean accs  std\n",
       "200-0.1-0.0005      0.27027  0.0\n",
       "200-0.05-0.0005     0.27027  0.0\n",
       "200-0.01-0.0005     0.27027  0.0\n",
       "200-0.005-0.0005    0.27027  0.0\n",
       "200-0.05-0.001      0.27027  0.0\n",
       "200-0.01-0.001      0.27027  0.0\n",
       "200-0.05-0.01       0.27027  0.0\n",
       "200-0.01-0.01       0.27027  0.0\n",
       "200-0.05-0.05       0.27027  0.0\n",
       "200-0.01-0.05       0.27027  0.0\n",
       "500-0.05-0.0005     0.27027  0.0\n",
       "500-0.01-0.0005     0.27027  0.0\n",
       "500-0.05-0.01       0.27027  0.0\n",
       "500-0.01-0.01       0.27027  0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 0.01-1-1-True: 0.270\n",
      "-1: 0.1-1-1-True: 0.270\n",
      "-1: 1-1-1-True: 0.270\n",
      "-1: 1-1-1-False: 0.270\n",
      "-1: 1-10-1-True: 0.270\n",
      "-1: 1-1-10-True: 0.270\n",
      "-1: 1-10-10-True: 0.270\n",
      "-1: 1-25-25-True: 0.270\n",
      "-1: 1-50-50-True: 0.270\n",
      "-2: 0.01-1-1-True: 0.270\n",
      "-2: 0.1-1-1-True: 0.270\n",
      "-2: 1-1-1-True: 0.270\n",
      "-2: 1-1-1-False: 0.270\n",
      "-2: 1-10-1-True: 0.270\n",
      "-2: 1-1-10-True: 0.270\n",
      "-2: 1-10-10-True: 0.270\n",
      "-2: 1-25-25-True: 0.270\n",
      "-2: 1-50-50-True: 0.270\n",
      "-3: 0.01-1-1-True: 0.270\n",
      "-3: 0.1-1-1-True: 0.270\n",
      "-3: 1-1-1-True: 0.270\n",
      "-3: 1-1-1-False: 0.270\n",
      "-3: 1-10-1-True: 0.270\n",
      "-3: 1-1-10-True: 0.270\n",
      "-3: 1-10-10-True: 0.270\n",
      "-3: 1-25-25-True: 0.270\n",
      "-3: 1-50-50-True: 0.270\n",
      "-4: 0.01-1-1-True: 0.270\n",
      "-4: 0.1-1-1-True: 0.270\n",
      "-4: 1-1-1-True: 0.270\n",
      "-4: 1-1-1-False: 0.270\n",
      "-4: 1-10-1-True: 0.270\n",
      "-4: 1-1-10-True: 0.270\n",
      "-4: 1-10-10-True: 0.270\n",
      "-4: 1-25-25-True: 0.270\n",
      "-4: 1-50-50-True: 0.270\n",
      "-5: 0.01-1-1-True: 0.270\n",
      "-5: 0.1-1-1-True: 0.270\n",
      "-5: 1-1-1-True: 0.270\n",
      "-5: 1-1-1-False: 0.270\n",
      "-5: 1-10-1-True: 0.270\n",
      "-5: 1-1-10-True: 0.270\n",
      "-5: 1-10-10-True: 0.270\n",
      "-5: 1-25-25-True: 0.270\n",
      "-5: 1-50-50-True: 0.270\n",
      "-6: 0.01-1-1-True: 0.270\n",
      "-6: 0.1-1-1-True: 0.270\n",
      "-6: 1-1-1-True: 0.270\n",
      "-6: 1-1-1-False: 0.270\n",
      "-6: 1-10-1-True: 0.270\n",
      "-6: 1-1-10-True: 0.270\n",
      "-6: 1-10-10-True: 0.270\n",
      "-6: 1-25-25-True: 0.270\n",
      "-6: 1-50-50-True: 0.270\n",
      "-7: 0.01-1-1-True: 0.270\n",
      "-7: 0.1-1-1-True: 0.270\n",
      "-7: 1-1-1-True: 0.270\n",
      "-7: 1-1-1-False: 0.270\n",
      "-7: 1-10-1-True: 0.270\n",
      "-7: 1-1-10-True: 0.270\n",
      "-7: 1-10-10-True: 0.270\n",
      "-7: 1-25-25-True: 0.270\n",
      "-7: 1-50-50-True: 0.270\n",
      "-8: 0.01-1-1-True: 0.270\n",
      "-8: 0.1-1-1-True: 0.270\n",
      "-8: 1-1-1-True: 0.270\n",
      "-8: 1-1-1-False: 0.270\n",
      "-8: 1-10-1-True: 0.270\n",
      "-8: 1-1-10-True: 0.270\n",
      "-8: 1-10-10-True: 0.270\n",
      "-8: 1-25-25-True: 0.270\n",
      "-8: 1-50-50-True: 0.270\n",
      "-9: 0.01-1-1-True: 0.270\n",
      "-9: 0.1-1-1-True: 0.270\n",
      "-9: 1-1-1-True: 0.270\n",
      "-9: 1-1-1-False: 0.270\n",
      "-9: 1-10-1-True: 0.270\n",
      "-9: 1-1-10-True: 0.270\n",
      "-9: 1-10-10-True: 0.270\n",
      "-9: 1-25-25-True: 0.270\n",
      "-9: 1-50-50-True: 0.270\n",
      "-10: 0.01-1-1-True: 0.270\n",
      "-10: 0.1-1-1-True: 0.270\n",
      "-10: 1-1-1-True: 0.270\n",
      "-10: 1-1-1-False: 0.270\n",
      "-10: 1-10-1-True: 0.270\n",
      "-10: 1-1-10-True: 0.270\n",
      "-10: 1-10-10-True: 0.270\n",
      "-10: 1-25-25-True: 0.270\n",
      "-10: 1-50-50-True: 0.270\n",
      "-11: 0.01-1-1-True: 0.270\n",
      "-11: 0.1-1-1-True: 0.270\n",
      "-11: 1-1-1-True: 0.270\n",
      "-11: 1-1-1-False: 0.270\n",
      "-11: 1-10-1-True: 0.270\n",
      "-11: 1-1-10-True: 0.270\n",
      "-11: 1-10-10-True: 0.270\n",
      "-11: 1-25-25-True: 0.270\n",
      "-11: 1-50-50-True: 0.270\n",
      "-12: 0.01-1-1-True: 0.270\n",
      "-12: 0.1-1-1-True: 0.270\n",
      "-12: 1-1-1-True: 0.270\n",
      "-12: 1-1-1-False: 0.270\n",
      "-12: 1-10-1-True: 0.270\n",
      "-12: 1-1-10-True: 0.270\n",
      "-12: 1-10-10-True: 0.270\n",
      "-12: 1-25-25-True: 0.270\n",
      "-12: 1-50-50-True: 0.270\n",
      "-13: 0.01-1-1-True: 0.270\n",
      "-13: 0.1-1-1-True: 0.270\n",
      "-13: 1-1-1-True: 0.270\n",
      "-13: 1-1-1-False: 0.270\n",
      "-13: 1-10-1-True: 0.270\n",
      "-13: 1-1-10-True: 0.270\n",
      "-13: 1-10-10-True: 0.270\n",
      "-13: 1-25-25-True: 0.270\n",
      "-13: 1-50-50-True: 0.270\n",
      "-14: 0.01-1-1-True: 0.270\n",
      "-14: 0.1-1-1-True: 0.270\n",
      "-14: 1-1-1-True: 0.270\n",
      "-14: 1-1-1-False: 0.270\n",
      "-14: 1-10-1-True: 0.270\n",
      "-14: 1-1-10-True: 0.270\n",
      "-14: 1-10-10-True: 0.270\n",
      "-14: 1-25-25-True: 0.270\n",
      "-14: 1-50-50-True: 0.270\n",
      "-15: 0.01-1-1-True: 0.270\n",
      "-15: 0.1-1-1-True: 0.270\n",
      "-15: 1-1-1-True: 0.270\n",
      "-15: 1-1-1-False: 0.270\n",
      "-15: 1-10-1-True: 0.270\n",
      "-15: 1-1-10-True: 0.270\n",
      "-15: 1-10-10-True: 0.270\n",
      "-15: 1-25-25-True: 0.270\n",
      "-15: 1-50-50-True: 0.270\n",
      "-16: 0.01-1-1-True: 0.270\n",
      "-16: 0.1-1-1-True: 0.270\n",
      "-16: 1-1-1-True: 0.270\n",
      "-16: 1-1-1-False: 0.270\n",
      "-16: 1-10-1-True: 0.270\n",
      "-16: 1-1-10-True: 0.270\n",
      "-16: 1-10-10-True: 0.270\n",
      "-16: 1-25-25-True: 0.270\n",
      "-16: 1-50-50-True: 0.270\n",
      "-17: 0.01-1-1-True: 0.270\n",
      "-17: 0.1-1-1-True: 0.270\n",
      "-17: 1-1-1-True: 0.270\n",
      "-17: 1-1-1-False: 0.270\n",
      "-17: 1-10-1-True: 0.270\n",
      "-17: 1-1-10-True: 0.270\n",
      "-17: 1-10-10-True: 0.270\n",
      "-17: 1-25-25-True: 0.270\n",
      "-17: 1-50-50-True: 0.270\n",
      "-18: 0.01-1-1-True: 0.270\n",
      "-18: 0.1-1-1-True: 0.270\n",
      "-18: 1-1-1-True: 0.270\n",
      "-18: 1-1-1-False: 0.270\n",
      "-18: 1-10-1-True: 0.270\n",
      "-18: 1-1-10-True: 0.270\n",
      "-18: 1-10-10-True: 0.270\n",
      "-18: 1-25-25-True: 0.270\n",
      "-18: 1-50-50-True: 0.270\n",
      "-19: 0.01-1-1-True: 0.270\n",
      "-19: 0.1-1-1-True: 0.270\n",
      "-19: 1-1-1-True: 0.270\n",
      "-19: 1-1-1-False: 0.270\n",
      "-19: 1-10-1-True: 0.270\n",
      "-19: 1-1-10-True: 0.270\n",
      "-19: 1-10-10-True: 0.270\n",
      "-19: 1-25-25-True: 0.270\n",
      "-19: 1-50-50-True: 0.270\n",
      "-20: 0.01-1-1-True: 0.270\n",
      "-20: 0.1-1-1-True: 0.270\n",
      "-20: 1-1-1-True: 0.270\n",
      "-20: 1-1-1-False: 0.270\n",
      "-20: 1-10-1-True: 0.270\n",
      "-20: 1-1-10-True: 0.270\n",
      "-20: 1-10-10-True: 0.270\n",
      "-20: 1-25-25-True: 0.270\n",
      "-20: 1-50-50-True: 0.270\n",
      "-21: 0.01-1-1-True: 0.270\n",
      "-21: 0.1-1-1-True: 0.270\n",
      "-21: 1-1-1-True: 0.270\n",
      "-21: 1-1-1-False: 0.270\n",
      "-21: 1-10-1-True: 0.270\n",
      "-21: 1-1-10-True: 0.270\n",
      "-21: 1-10-10-True: 0.270\n",
      "-21: 1-25-25-True: 0.270\n",
      "-21: 1-50-50-True: 0.270\n",
      "-22: 0.01-1-1-True: 0.270\n",
      "-22: 0.1-1-1-True: 0.270\n",
      "-22: 1-1-1-True: 0.270\n",
      "-22: 1-1-1-False: 0.270\n",
      "-22: 1-10-1-True: 0.270\n",
      "-22: 1-1-10-True: 0.270\n",
      "-22: 1-10-10-True: 0.270\n",
      "-22: 1-25-25-True: 0.270\n",
      "-22: 1-50-50-True: 0.270\n",
      "-23: 0.01-1-1-True: 0.270\n",
      "-23: 0.1-1-1-True: 0.270\n",
      "-23: 1-1-1-True: 0.270\n",
      "-23: 1-1-1-False: 0.270\n",
      "-23: 1-10-1-True: 0.270\n",
      "-23: 1-1-10-True: 0.270\n",
      "-23: 1-10-10-True: 0.270\n",
      "-23: 1-25-25-True: 0.270\n",
      "-23: 1-50-50-True: 0.270\n",
      "-24: 0.01-1-1-True: 0.270\n",
      "-24: 0.1-1-1-True: 0.270\n",
      "-24: 1-1-1-True: 0.270\n",
      "-24: 1-1-1-False: 0.270\n",
      "-24: 1-10-1-True: 0.270\n",
      "-24: 1-1-10-True: 0.270\n",
      "-24: 1-10-10-True: 0.270\n",
      "-24: 1-25-25-True: 0.270\n",
      "-24: 1-50-50-True: 0.270\n",
      "-25: 0.01-1-1-True: 0.270\n",
      "-25: 0.1-1-1-True: 0.270\n",
      "-25: 1-1-1-True: 0.270\n",
      "-25: 1-1-1-False: 0.270\n",
      "-25: 1-10-1-True: 0.270\n",
      "-25: 1-1-10-True: 0.270\n",
      "-25: 1-10-10-True: 0.270\n",
      "-25: 1-25-25-True: 0.270\n",
      "-25: 1-50-50-True: 0.270\n",
      "----- 31.27 mins -----\n"
     ]
    }
   ],
   "source": [
    "# h0, norm (norm, not norm, norm H), sep vs joint training, optimizers iters (W vs h)\n",
    "EXPS = [{'h0': .01, 'epochs': 500, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .5, 'epochs': 500, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 500, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        \n",
    "        {'h0': 1, 'epochs': 500, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "        {'h0': 1, 'epochs': 500, 'epochs_h': 10, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 500, 'epochs_h': 1, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 500, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 500, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 50, 'epochs_h': 50, 'epochs_W': 50, 'alt': True},]\n",
    "\n",
    "\n",
    "best_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=exp['h0'])\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        if not exp['alt']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S,  K, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD, epochs_h=exp['epochs_h'],\n",
    "                                 epochs_W=exp['epochs_W'])\n",
    "\n",
    "        best_accs2[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}: {best_accs2[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs2.mean(axis=1)\n",
    "std_accs = best_accs2.std(axis=1)\n",
    "index_name = [f'{i+1}: {exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}' for exp in EXPS]\n",
    "table6 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25: 0.01-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 0.1-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-1-1-False</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-10-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-1-10-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-10-10-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-25-25-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25: 1-50-50-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean accs  std\n",
       "25: 0.01-1-1-True    0.27027  0.0\n",
       "25: 0.1-1-1-True     0.27027  0.0\n",
       "25: 1-1-1-True       0.27027  0.0\n",
       "25: 1-1-1-False      0.27027  0.0\n",
       "25: 1-10-1-True      0.27027  0.0\n",
       "25: 1-1-10-True      0.27027  0.0\n",
       "25: 1-10-10-True     0.27027  0.0\n",
       "25: 1-25-25-True     0.27027  0.0\n",
       "25: 1-50-50-True     0.27027  0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 2-2-16: 0.270\n",
      "-1: 2-3-16: 0.270\n",
      "-1: 2-4-16: 0.270\n",
      "-1: 3-2-16: 0.270\n",
      "-1: 4-2-16: 0.270\n",
      "-1: 3-3-16: 0.270\n",
      "-1: 4-3-16: 0.270\n",
      "-1: 2-2-8: 0.270\n",
      "-1: 2-2-32: 0.270\n",
      "-1: 2-2-50: 0.270\n",
      "-1: 2-3-8: 0.270\n",
      "-1: 2-3-32: 0.270\n",
      "-1: 2-3-50: 0.270\n",
      "-1: 3-2-8: 0.270\n",
      "-1: 3-2-32: 0.270\n",
      "-1: 3-2-50: 0.270\n",
      "-1: 3-3-8: 0.270\n",
      "-1: 3-3-32: 0.270\n",
      "-1: 3-3-50: 0.270\n",
      "-2: 2-2-16: 0.270\n",
      "-2: 2-3-16: 0.270\n",
      "-2: 2-4-16: 0.270\n",
      "-2: 3-2-16: 0.270\n",
      "-2: 4-2-16: 0.270\n",
      "-2: 3-3-16: 0.270\n",
      "-2: 4-3-16: 0.270\n",
      "-2: 2-2-8: 0.270\n",
      "-2: 2-2-32: 0.270\n",
      "-2: 2-2-50: 0.270\n",
      "-2: 2-3-8: 0.270\n",
      "-2: 2-3-32: 0.270\n",
      "-2: 2-3-50: 0.270\n",
      "-2: 3-2-8: 0.270\n",
      "-2: 3-2-32: 0.270\n",
      "-2: 3-2-50: 0.270\n",
      "-2: 3-3-8: 0.270\n",
      "-2: 3-3-32: 0.270\n",
      "-2: 3-3-50: 0.270\n",
      "-3: 2-2-16: 0.270\n",
      "-3: 2-3-16: 0.270\n",
      "-3: 2-4-16: 0.270\n",
      "-3: 3-2-16: 0.270\n",
      "-3: 4-2-16: 0.270\n",
      "-3: 3-3-16: 0.270\n",
      "-3: 4-3-16: 0.270\n",
      "-3: 2-2-8: 0.270\n",
      "-3: 2-2-32: 0.270\n",
      "-3: 2-2-50: 0.270\n",
      "-3: 2-3-8: 0.270\n",
      "-3: 2-3-32: 0.270\n",
      "-3: 2-3-50: 0.270\n",
      "-3: 3-2-8: 0.270\n",
      "-3: 3-2-32: 0.270\n",
      "-3: 3-2-50: 0.270\n",
      "-3: 3-3-8: 0.270\n",
      "-3: 3-3-32: 0.270\n",
      "-3: 3-3-50: 0.270\n",
      "-4: 2-2-16: 0.270\n",
      "-4: 2-3-16: 0.270\n",
      "-4: 2-4-16: 0.270\n",
      "-4: 3-2-16: 0.270\n",
      "-4: 4-2-16: 0.270\n",
      "-4: 3-3-16: 0.270\n",
      "-4: 4-3-16: 0.270\n",
      "-4: 2-2-8: 0.270\n",
      "-4: 2-2-32: 0.270\n",
      "-4: 2-2-50: 0.270\n",
      "-4: 2-3-8: 0.270\n",
      "-4: 2-3-32: 0.270\n",
      "-4: 2-3-50: 0.270\n",
      "-4: 3-2-8: 0.270\n",
      "-4: 3-2-32: 0.270\n",
      "-4: 3-2-50: 0.270\n",
      "-4: 3-3-8: 0.270\n",
      "-4: 3-3-32: 0.270\n",
      "-4: 3-3-50: 0.270\n",
      "-5: 2-2-16: 0.270\n",
      "-5: 2-3-16: 0.270\n",
      "-5: 2-4-16: 0.270\n",
      "-5: 3-2-16: 0.270\n",
      "-5: 4-2-16: 0.270\n",
      "-5: 3-3-16: 0.270\n",
      "-5: 4-3-16: 0.270\n",
      "-5: 2-2-8: 0.270\n",
      "-5: 2-2-32: 0.270\n",
      "-5: 2-2-50: 0.270\n",
      "-5: 2-3-8: 0.270\n",
      "-5: 2-3-32: 0.270\n",
      "-5: 2-3-50: 0.270\n",
      "-5: 3-2-8: 0.270\n",
      "-5: 3-2-32: 0.270\n",
      "-5: 3-2-50: 0.270\n",
      "-5: 3-3-8: 0.270\n",
      "-5: 3-3-32: 0.270\n",
      "-5: 3-3-50: 0.270\n",
      "-6: 2-2-16: 0.270\n",
      "-6: 2-3-16: 0.270\n",
      "-6: 2-4-16: 0.270\n",
      "-6: 3-2-16: 0.270\n",
      "-6: 4-2-16: 0.270\n",
      "-6: 3-3-16: 0.270\n",
      "-6: 4-3-16: 0.270\n",
      "-6: 2-2-8: 0.270\n",
      "-6: 2-2-32: 0.270\n",
      "-6: 2-2-50: 0.270\n",
      "-6: 2-3-8: 0.270\n",
      "-6: 2-3-32: 0.270\n",
      "-6: 2-3-50: 0.270\n",
      "-6: 3-2-8: 0.270\n",
      "-6: 3-2-32: 0.270\n",
      "-6: 3-2-50: 0.270\n",
      "-6: 3-3-8: 0.270\n",
      "-6: 3-3-32: 0.270\n",
      "-6: 3-3-50: 0.270\n",
      "-7: 2-2-16: 0.270\n",
      "-7: 2-3-16: 0.270\n",
      "-7: 2-4-16: 0.270\n",
      "-7: 3-2-16: 0.270\n",
      "-7: 4-2-16: 0.270\n",
      "-7: 3-3-16: 0.270\n",
      "-7: 4-3-16: 0.270\n",
      "-7: 2-2-8: 0.270\n",
      "-7: 2-2-32: 0.270\n",
      "-7: 2-2-50: 0.270\n",
      "-7: 2-3-8: 0.270\n",
      "-7: 2-3-32: 0.270\n",
      "-7: 2-3-50: 0.270\n",
      "-7: 3-2-8: 0.270\n",
      "-7: 3-2-32: 0.270\n",
      "-7: 3-2-50: 0.270\n",
      "-7: 3-3-8: 0.270\n",
      "-7: 3-3-32: 0.270\n",
      "-7: 3-3-50: 0.270\n",
      "-8: 2-2-16: 0.270\n",
      "-8: 2-3-16: 0.270\n",
      "-8: 2-4-16: 0.270\n",
      "-8: 3-2-16: 0.270\n",
      "-8: 4-2-16: 0.270\n",
      "-8: 3-3-16: 0.270\n",
      "-8: 4-3-16: 0.270\n",
      "-8: 2-2-8: 0.270\n",
      "-8: 2-2-32: 0.270\n",
      "-8: 2-2-50: 0.270\n",
      "-8: 2-3-8: 0.270\n",
      "-8: 2-3-32: 0.270\n",
      "-8: 2-3-50: 0.270\n",
      "-8: 3-2-8: 0.270\n",
      "-8: 3-2-32: 0.270\n",
      "-8: 3-2-50: 0.270\n",
      "-8: 3-3-8: 0.270\n",
      "-8: 3-3-32: 0.270\n",
      "-8: 3-3-50: 0.270\n",
      "-9: 2-2-16: 0.270\n",
      "-9: 2-3-16: 0.270\n",
      "-9: 2-4-16: 0.270\n",
      "-9: 3-2-16: 0.270\n",
      "-9: 4-2-16: 0.270\n",
      "-9: 3-3-16: 0.270\n",
      "-9: 4-3-16: 0.270\n",
      "-9: 2-2-8: 0.270\n",
      "-9: 2-2-32: 0.270\n",
      "-9: 2-2-50: 0.270\n",
      "-9: 2-3-8: 0.270\n",
      "-9: 2-3-32: 0.270\n",
      "-9: 2-3-50: 0.270\n",
      "-9: 3-2-8: 0.270\n",
      "-9: 3-2-32: 0.270\n",
      "-9: 3-2-50: 0.270\n",
      "-9: 3-3-8: 0.270\n",
      "-9: 3-3-32: 0.270\n",
      "-9: 3-3-50: 0.270\n",
      "-10: 2-2-16: 0.270\n",
      "-10: 2-3-16: 0.270\n",
      "-10: 2-4-16: 0.270\n",
      "-10: 3-2-16: 0.270\n",
      "-10: 4-2-16: 0.270\n",
      "-10: 3-3-16: 0.270\n",
      "-10: 4-3-16: 0.270\n",
      "-10: 2-2-8: 0.270\n",
      "-10: 2-2-32: 0.270\n",
      "-10: 2-2-50: 0.270\n",
      "-10: 2-3-8: 0.270\n",
      "-10: 2-3-32: 0.270\n",
      "-10: 2-3-50: 0.270\n",
      "-10: 3-2-8: 0.270\n",
      "-10: 3-2-32: 0.270\n",
      "-10: 3-2-50: 0.270\n",
      "-10: 3-3-8: 0.270\n",
      "-10: 3-3-32: 0.270\n",
      "-10: 3-3-50: 0.270\n",
      "-11: 2-2-16: 0.270\n",
      "-11: 2-3-16: 0.270\n",
      "-11: 2-4-16: 0.270\n",
      "-11: 3-2-16: 0.270\n",
      "-11: 4-2-16: 0.270\n",
      "-11: 3-3-16: 0.270\n",
      "-11: 4-3-16: 0.270\n",
      "-11: 2-2-8: 0.270\n",
      "-11: 2-2-32: 0.270\n",
      "-11: 2-2-50: 0.270\n",
      "-11: 2-3-8: 0.270\n",
      "-11: 2-3-32: 0.270\n",
      "-11: 2-3-50: 0.270\n",
      "-11: 3-2-8: 0.270\n",
      "-11: 3-2-32: 0.270\n",
      "-11: 3-2-50: 0.270\n",
      "-11: 3-3-8: 0.270\n",
      "-11: 3-3-32: 0.270\n",
      "-11: 3-3-50: 0.270\n",
      "-12: 2-2-16: 0.270\n",
      "-12: 2-3-16: 0.270\n",
      "-12: 2-4-16: 0.270\n",
      "-12: 3-2-16: 0.270\n",
      "-12: 4-2-16: 0.270\n",
      "-12: 3-3-16: 0.270\n",
      "-12: 4-3-16: 0.270\n",
      "-12: 2-2-8: 0.270\n",
      "-12: 2-2-32: 0.270\n",
      "-12: 2-2-50: 0.270\n",
      "-12: 2-3-8: 0.270\n",
      "-12: 2-3-32: 0.270\n",
      "-12: 2-3-50: 0.270\n",
      "-12: 3-2-8: 0.270\n",
      "-12: 3-2-32: 0.270\n",
      "-12: 3-2-50: 0.270\n",
      "-12: 3-3-8: 0.270\n",
      "-12: 3-3-32: 0.270\n",
      "-12: 3-3-50: 0.270\n",
      "-13: 2-2-16: 0.270\n",
      "-13: 2-3-16: 0.270\n",
      "-13: 2-4-16: 0.270\n",
      "-13: 3-2-16: 0.270\n",
      "-13: 4-2-16: 0.270\n",
      "-13: 3-3-16: 0.270\n",
      "-13: 4-3-16: 0.270\n",
      "-13: 2-2-8: 0.270\n",
      "-13: 2-2-32: 0.270\n",
      "-13: 2-2-50: 0.270\n",
      "-13: 2-3-8: 0.270\n",
      "-13: 2-3-32: 0.270\n",
      "-13: 2-3-50: 0.270\n",
      "-13: 3-2-8: 0.270\n",
      "-13: 3-2-32: 0.270\n",
      "-13: 3-2-50: 0.270\n",
      "-13: 3-3-8: 0.270\n",
      "-13: 3-3-32: 0.270\n",
      "-13: 3-3-50: 0.270\n",
      "-14: 2-2-16: 0.270\n",
      "-14: 2-3-16: 0.270\n",
      "-14: 2-4-16: 0.270\n",
      "-14: 3-2-16: 0.270\n",
      "-14: 4-2-16: 0.270\n",
      "-14: 3-3-16: 0.270\n",
      "-14: 4-3-16: 0.270\n",
      "-14: 2-2-8: 0.270\n",
      "-14: 2-2-32: 0.270\n",
      "-14: 2-2-50: 0.270\n",
      "-14: 2-3-8: 0.270\n",
      "-14: 2-3-32: 0.270\n",
      "-14: 2-3-50: 0.270\n",
      "-14: 3-2-8: 0.270\n",
      "-14: 3-2-32: 0.270\n",
      "-14: 3-2-50: 0.270\n",
      "-14: 3-3-8: 0.270\n",
      "-14: 3-3-32: 0.270\n",
      "-14: 3-3-50: 0.270\n",
      "-15: 2-2-16: 0.270\n",
      "-15: 2-3-16: 0.270\n",
      "-15: 2-4-16: 0.270\n",
      "-15: 3-2-16: 0.270\n",
      "-15: 4-2-16: 0.270\n",
      "-15: 3-3-16: 0.270\n",
      "-15: 4-3-16: 0.270\n",
      "-15: 2-2-8: 0.270\n",
      "-15: 2-2-32: 0.270\n",
      "-15: 2-2-50: 0.270\n",
      "-15: 2-3-8: 0.270\n",
      "-15: 2-3-32: 0.270\n",
      "-15: 2-3-50: 0.270\n",
      "-15: 3-2-8: 0.270\n",
      "-15: 3-2-32: 0.270\n",
      "-15: 3-2-50: 0.270\n",
      "-15: 3-3-8: 0.270\n",
      "-15: 3-3-32: 0.270\n",
      "-15: 3-3-50: 0.270\n",
      "-16: 2-2-16: 0.270\n",
      "-16: 2-3-16: 0.270\n",
      "-16: 2-4-16: 0.270\n",
      "-16: 3-2-16: 0.270\n",
      "-16: 4-2-16: 0.270\n",
      "-16: 3-3-16: 0.270\n",
      "-16: 4-3-16: 0.270\n",
      "-16: 2-2-8: 0.270\n",
      "-16: 2-2-32: 0.270\n",
      "-16: 2-2-50: 0.270\n",
      "-16: 2-3-8: 0.270\n",
      "-16: 2-3-32: 0.270\n",
      "-16: 2-3-50: 0.270\n",
      "-16: 3-2-8: 0.270\n",
      "-16: 3-2-32: 0.270\n",
      "-16: 3-2-50: 0.270\n",
      "-16: 3-3-8: 0.270\n",
      "-16: 3-3-32: 0.270\n",
      "-16: 3-3-50: 0.270\n",
      "-17: 2-2-16: 0.270\n",
      "-17: 2-3-16: 0.270\n",
      "-17: 2-4-16: 0.270\n",
      "-17: 3-2-16: 0.270\n",
      "-17: 4-2-16: 0.270\n",
      "-17: 3-3-16: 0.270\n",
      "-17: 4-3-16: 0.270\n",
      "-17: 2-2-8: 0.270\n",
      "-17: 2-2-32: 0.270\n",
      "-17: 2-2-50: 0.270\n",
      "-17: 2-3-8: 0.270\n",
      "-17: 2-3-32: 0.270\n",
      "-17: 2-3-50: 0.270\n",
      "-17: 3-2-8: 0.270\n",
      "-17: 3-2-32: 0.270\n",
      "-17: 3-2-50: 0.270\n",
      "-17: 3-3-8: 0.270\n",
      "-17: 3-3-32: 0.270\n",
      "-17: 3-3-50: 0.270\n",
      "-18: 2-2-16: 0.270\n",
      "-18: 2-3-16: 0.270\n",
      "-18: 2-4-16: 0.270\n",
      "-18: 3-2-16: 0.270\n",
      "-18: 4-2-16: 0.270\n",
      "-18: 3-3-16: 0.270\n",
      "-18: 4-3-16: 0.270\n",
      "-18: 2-2-8: 0.270\n",
      "-18: 2-2-32: 0.270\n",
      "-18: 2-2-50: 0.270\n",
      "-18: 2-3-8: 0.270\n",
      "-18: 2-3-32: 0.270\n",
      "-18: 2-3-50: 0.270\n",
      "-18: 3-2-8: 0.270\n",
      "-18: 3-2-32: 0.270\n",
      "-18: 3-2-50: 0.270\n",
      "-18: 3-3-8: 0.270\n",
      "-18: 3-3-32: 0.270\n",
      "-18: 3-3-50: 0.270\n",
      "-19: 2-2-16: 0.270\n",
      "-19: 2-3-16: 0.270\n",
      "-19: 2-4-16: 0.270\n",
      "-19: 3-2-16: 0.270\n",
      "-19: 4-2-16: 0.270\n",
      "-19: 3-3-16: 0.270\n",
      "-19: 4-3-16: 0.270\n",
      "-19: 2-2-8: 0.270\n",
      "-19: 2-2-32: 0.270\n",
      "-19: 2-2-50: 0.270\n",
      "-19: 2-3-8: 0.270\n",
      "-19: 2-3-32: 0.270\n",
      "-19: 2-3-50: 0.270\n",
      "-19: 3-2-8: 0.270\n",
      "-19: 3-2-32: 0.270\n",
      "-19: 3-2-50: 0.270\n",
      "-19: 3-3-8: 0.270\n",
      "-19: 3-3-32: 0.270\n",
      "-19: 3-3-50: 0.270\n",
      "-20: 2-2-16: 0.270\n",
      "-20: 2-3-16: 0.270\n",
      "-20: 2-4-16: 0.270\n",
      "-20: 3-2-16: 0.270\n",
      "-20: 4-2-16: 0.270\n",
      "-20: 3-3-16: 0.270\n",
      "-20: 4-3-16: 0.270\n",
      "-20: 2-2-8: 0.270\n",
      "-20: 2-2-32: 0.270\n",
      "-20: 2-2-50: 0.270\n",
      "-20: 2-3-8: 0.270\n",
      "-20: 2-3-32: 0.270\n",
      "-20: 2-3-50: 0.270\n",
      "-20: 3-2-8: 0.270\n",
      "-20: 3-2-32: 0.270\n",
      "-20: 3-2-50: 0.270\n",
      "-20: 3-3-8: 0.270\n",
      "-20: 3-3-32: 0.270\n",
      "-20: 3-3-50: 0.270\n",
      "-21: 2-2-16: 0.270\n",
      "-21: 2-3-16: 0.270\n",
      "-21: 2-4-16: 0.270\n",
      "-21: 3-2-16: 0.270\n",
      "-21: 4-2-16: 0.270\n",
      "-21: 3-3-16: 0.270\n",
      "-21: 4-3-16: 0.270\n",
      "-21: 2-2-8: 0.270\n",
      "-21: 2-2-32: 0.270\n",
      "-21: 2-2-50: 0.270\n",
      "-21: 2-3-8: 0.270\n",
      "-21: 2-3-32: 0.270\n",
      "-21: 2-3-50: 0.270\n",
      "-21: 3-2-8: 0.270\n",
      "-21: 3-2-32: 0.270\n",
      "-21: 3-2-50: 0.270\n",
      "-21: 3-3-8: 0.270\n",
      "-21: 3-3-32: 0.270\n",
      "-21: 3-3-50: 0.270\n",
      "-22: 2-2-16: 0.270\n",
      "-22: 2-3-16: 0.270\n",
      "-22: 2-4-16: 0.270\n",
      "-22: 3-2-16: 0.270\n",
      "-22: 4-2-16: 0.270\n",
      "-22: 3-3-16: 0.270\n",
      "-22: 4-3-16: 0.270\n",
      "-22: 2-2-8: 0.270\n",
      "-22: 2-2-32: 0.270\n",
      "-22: 2-2-50: 0.270\n",
      "-22: 2-3-8: 0.270\n",
      "-22: 2-3-32: 0.270\n",
      "-22: 2-3-50: 0.270\n",
      "-22: 3-2-8: 0.270\n",
      "-22: 3-2-32: 0.270\n",
      "-22: 3-2-50: 0.270\n",
      "-22: 3-3-8: 0.270\n",
      "-22: 3-3-32: 0.270\n",
      "-22: 3-3-50: 0.270\n",
      "-23: 2-2-16: 0.270\n",
      "-23: 2-3-16: 0.270\n",
      "-23: 2-4-16: 0.270\n",
      "-23: 3-2-16: 0.270\n",
      "-23: 4-2-16: 0.270\n",
      "-23: 3-3-16: 0.270\n",
      "-23: 4-3-16: 0.270\n",
      "-23: 2-2-8: 0.270\n",
      "-23: 2-2-32: 0.270\n",
      "-23: 2-2-50: 0.270\n",
      "-23: 2-3-8: 0.270\n",
      "-23: 2-3-32: 0.270\n",
      "-23: 2-3-50: 0.270\n",
      "-23: 3-2-8: 0.270\n",
      "-23: 3-2-32: 0.270\n",
      "-23: 3-2-50: 0.270\n",
      "-23: 3-3-8: 0.270\n",
      "-23: 3-3-32: 0.270\n",
      "-23: 3-3-50: 0.270\n",
      "-24: 2-2-16: 0.270\n",
      "-24: 2-3-16: 0.270\n",
      "-24: 2-4-16: 0.270\n",
      "-24: 3-2-16: 0.270\n",
      "-24: 4-2-16: 0.270\n",
      "-24: 3-3-16: 0.270\n",
      "-24: 4-3-16: 0.270\n",
      "-24: 2-2-8: 0.270\n",
      "-24: 2-2-32: 0.270\n",
      "-24: 2-2-50: 0.270\n",
      "-24: 2-3-8: 0.270\n",
      "-24: 2-3-32: 0.270\n",
      "-24: 2-3-50: 0.270\n",
      "-24: 3-2-8: 0.270\n",
      "-24: 3-2-32: 0.270\n",
      "-24: 3-2-50: 0.270\n",
      "-24: 3-3-8: 0.270\n",
      "-24: 3-3-32: 0.270\n",
      "-24: 3-3-50: 0.270\n",
      "-25: 2-2-16: 0.270\n",
      "-25: 2-3-16: 0.270\n",
      "-25: 2-4-16: 0.270\n",
      "-25: 3-2-16: 0.270\n",
      "-25: 4-2-16: 0.270\n",
      "-25: 3-3-16: 0.270\n",
      "-25: 4-3-16: 0.270\n",
      "-25: 2-2-8: 0.270\n",
      "-25: 2-2-32: 0.270\n",
      "-25: 2-2-50: 0.270\n",
      "-25: 2-3-8: 0.270\n",
      "-25: 2-3-32: 0.270\n",
      "-25: 2-3-50: 0.270\n",
      "-25: 3-2-8: 0.270\n",
      "-25: 3-2-32: 0.270\n",
      "-25: 3-2-50: 0.270\n",
      "-25: 3-3-8: 0.270\n",
      "-25: 3-3-32: 0.270\n",
      "-25: 3-3-50: 0.270\n",
      "----- 9.20 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'L': 2, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 4, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 3, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 50},\n",
    "        ]\n",
    "\n",
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, exp['hid_dim'], OUT_DIM, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  exp['K'], masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}: {best_accs[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs.mean(axis=1)\n",
    "std_accs = best_accs.std(axis=1)\n",
    "index_name = [f'{exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}' for exp in EXPS]\n",
    "table7 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-2-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-4-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-3-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean accs  std\n",
       "2-2-16    0.27027  0.0\n",
       "2-3-16    0.27027  0.0\n",
       "2-4-16    0.27027  0.0\n",
       "3-2-16    0.27027  0.0\n",
       "4-2-16    0.27027  0.0\n",
       "3-3-16    0.27027  0.0\n",
       "4-3-16    0.27027  0.0\n",
       "2-2-8     0.27027  0.0\n",
       "2-2-32    0.27027  0.0\n",
       "2-2-50    0.27027  0.0\n",
       "2-3-8     0.27027  0.0\n",
       "2-3-32    0.27027  0.0\n",
       "2-3-50    0.27027  0.0\n",
       "3-2-8     0.27027  0.0\n",
       "3-2-32    0.27027  0.0\n",
       "3-2-50    0.27027  0.0\n",
       "3-3-8     0.27027  0.0\n",
       "3-3-32    0.27027  0.0\n",
       "3-3-50    0.27027  0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearities and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-1: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-1: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-1: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-2: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-2: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-2: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-2: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-3: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-3: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-3: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-3: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-4: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-4: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-4: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-4: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-5: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-5: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-5: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-5: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-6: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-6: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-6: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-6: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-7: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-7: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-7: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-7: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-8: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-8: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-8: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-8: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-9: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-9: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-9: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-9: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-10: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-10: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-10: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-10: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-11: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-11: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-11: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-11: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-12: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-12: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-12: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-12: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-13: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-13: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-13: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-13: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-14: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-14: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-14: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-14: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-15: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-15: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-15: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-15: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-16: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-16: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-16: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-16: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-17: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-17: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-17: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-17: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-18: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-18: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-18: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-18: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-19: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-19: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-19: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-19: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-20: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-20: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-20: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-20: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-21: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-21: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-21: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-21: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-22: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-22: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-22: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-22: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-23: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-23: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-23: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-23: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-24: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-24: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-24: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-24: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-25: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: ReLU()-Identity()-CrossEntropyLoss(): 0.270\n",
      "-25: ReLU()-Identity()-NLLLoss(): 0.270\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270\n",
      "-25: Identity()-Softmax(dim=1)-NLLLoss(): 0.270\n",
      "-25: Identity()-Identity()-CrossEntropyLoss(): 0.270\n",
      "----- 4.87 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},]\n",
    "\n",
    "best_accs4 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=exp['act'], last_act=exp['lact'],\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  K, masks, exp['loss'], device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs4[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}: {best_accs4[j,i]:.3f}')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "mean_accs = best_accs4.mean(axis=1)\n",
    "std_accs = best_accs4.std(axis=1)\n",
    "index_name = [f'{exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}' for exp in EXPS]\n",
    "table8 = DataFrame(np.vstack((mean_accs, std_accs)).T, columns=['mean accs', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean accs  std\n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()              0.27027  0.0\n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                       0.27027  0.0\n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()           0.27027  0.0\n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                    0.27027  0.0\n",
       "ReLU()-Identity()-CrossEntropyLoss()                  0.27027  0.0\n",
       "ReLU()-Identity()-NLLLoss()                           0.27027  0.0\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()      0.27027  0.0\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()               0.27027  0.0\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...    0.27027  0.0\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...    0.27027  0.0\n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()          0.27027  0.0\n",
       "Identity()-Softmax(dim=1)-NLLLoss()                   0.27027  0.0\n",
       "Identity()-Identity()-CrossEntropyLoss()              0.27027  0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPS = [\n",
    "        {'name': 'Kipf', 'norm': 'none'},\n",
    "        {'name': 'Kipf', 'norm': 'both'},\n",
    "\n",
    "        {'name': 'A-GCNN', 'norm': False},\n",
    "        {'name': 'A-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'H-GCNN', 'norm': False}, # This should be the same as A-GCNN not norm\n",
    "        {'name': 'H-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'W-GCN-A', 'norm': False},\n",
    "        {'name': 'W-GCN-A', 'norm': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RUN: 1\n",
      "\tKipf-none: acc = 0.459\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.838\n",
      "\tH-GCNN-True: acc = 0.892\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 2\n",
      "\tKipf-none: acc = 0.405\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 3\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 4\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.838\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 5\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 6\n",
      "\tKipf-none: acc = 0.514\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.838\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.919\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 7\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 8\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.676\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.784\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 9\n",
      "\tKipf-none: acc = 0.459\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.838\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 10\n",
      "\tKipf-none: acc = 0.459\n",
      "\tKipf-both: acc = 0.676\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 11\n",
      "\tKipf-none: acc = 0.405\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.811\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 12\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.892\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 13\n",
      "\tKipf-none: acc = 0.514\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.838\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 14\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.838\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.892\n",
      "\tW-GCN-A-False: acc = 0.838\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 15\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.784\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 16\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 17\n",
      "\tKipf-none: acc = 0.405\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.838\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 18\n",
      "\tKipf-none: acc = 0.459\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.811\n",
      "\tW-GCN-A-False: acc = 0.919\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 19\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.838\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.838\n",
      "\tW-GCN-A-False: acc = 0.892\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 20\n",
      "\tKipf-none: acc = 0.405\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.919\n",
      "\tH-GCNN-True: acc = 0.703\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 21\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.838\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.919\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 22\n",
      "\tKipf-none: acc = 0.514\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.811\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 23\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.622\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.865\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 24\n",
      "\tKipf-none: acc = 0.486\n",
      "\tKipf-both: acc = 0.649\n",
      "\tA-GCNN-False: acc = 0.865\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.892\n",
      "\tH-GCNN-True: acc = 0.730\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n",
      "- RUN: 25\n",
      "\tKipf-none: acc = 0.432\n",
      "\tKipf-both: acc = 0.676\n",
      "\tA-GCNN-False: acc = 0.892\n",
      "\tA-GCNN-True: acc = 0.270\n",
      "\tH-GCNN-False: acc = 0.865\n",
      "\tH-GCNN-True: acc = 0.811\n",
      "\tW-GCN-A-False: acc = 0.865\n",
      "\tW-GCN-A-True: acc = 0.270\n"
     ]
    }
   ],
   "source": [
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "for i in range(N_RUNS):\n",
    "    print(f'- RUN: {i+1}')\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        # t_i = time.time()\n",
    "        if exp['name'] == 'Kipf':\n",
    "            arch = GCNN_2L(IN_DIM, HID_DIM, OUT_DIM, act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=exp['norm'])\n",
    "            S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "            \n",
    "        elif exp['name'] == 'A-GCNN':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "            dropout=DROPOUT, diff_layer=GFGCNLayer, init_h0=h0)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'H-GCNN':\n",
    "            arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=DROPOUT, norm=exp['norm'], dev=device)\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'W-GCN-A':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=DROPOUT, diff_layer=GFGCN_noh_Layer)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)  \n",
    "            \n",
    "        else:\n",
    "            raise Exception(f'ERROR: Unknown architecture: {exp[\"name\"]}')\n",
    "\n",
    "        if exp['name'] in ['Kipf', 'W-GCN-A']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "\n",
    "        loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "\n",
    "        print(f'\\t{exp[\"name\"]}-{exp[\"norm\"]}: acc = {best_accs[j,i]:.3f}')\n",
    "\n",
    "\n",
    "# Print results\n",
    "mean_accs = best_accs.mean(axis=1)\n",
    "med_accs = np.median(best_accs, axis=1)\n",
    "std_accs = best_accs.std(axis=1)\n",
    "\n",
    "index_name = [f'{exp[\"name\"]}-{exp[\"norm\"]}' for exp in EXPS]\n",
    "data = np.vstack((mean_accs, med_accs, std_accs)).T\n",
    "table_comp2 = DataFrame(data, columns=['mean accs', 'med accs', 'std'], index=index_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med accs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kipf-none</th>\n",
       "      <td>0.436757</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.036405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kipf-both</th>\n",
       "      <td>0.628108</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.015815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-False</th>\n",
       "      <td>0.855135</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.016887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-False</th>\n",
       "      <td>0.861622</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.020682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-True</th>\n",
       "      <td>0.796757</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.060250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-False</th>\n",
       "      <td>0.836757</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.029089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean accs  med accs       std\n",
       "Kipf-none       0.436757  0.432432  0.036405\n",
       "Kipf-both       0.628108  0.621622  0.015815\n",
       "A-GCNN-False    0.855135  0.864865  0.016887\n",
       "A-GCNN-True     0.270270  0.270270  0.000000\n",
       "H-GCNN-False    0.861622  0.864865  0.020682\n",
       "H-GCNN-True     0.796757  0.810811  0.060250\n",
       "W-GCN-A-False   0.836757  0.837838  0.029089\n",
       "W-GCN-A-True    0.270270  0.270270  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_comp2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

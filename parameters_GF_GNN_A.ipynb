{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f43cc803e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import utils\n",
    "from gsp_utils.baselines_archs import GCNN_2L\n",
    "from gsp_utils.baselines_models import NodeClassModel, GF_NodeClassModel\n",
    "from gsp_utils.data import normalize_gso\n",
    "from src.arch import GFGCN, GFGCNLayer, GFGCN_noh_Layer, GFGCN_Spows\n",
    "\n",
    "SEED = 15\n",
    "# PATH = 'results/diff_filters/'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def summary_table(acc, index_name):\n",
    "    mean_accs = acc.mean(axis=1)\n",
    "    med_accs = np.median(acc, axis=1)\n",
    "    std_accs = acc.std(axis=1)\n",
    "    return DataFrame(np.vstack((mean_accs, med_accs, std_accs)).T, columns=['mean accs', 'med', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CornellDataset\n",
      "Number of nodes: 183\n",
      "Number of features: 1703\n",
      "Shape of signals: torch.Size([183, 1703])\n",
      "Number of classes: 5\n",
      "Norm of A: 17.262676239013672\n",
      "Max value of A: 1.0\n",
      "Proportion of validation data: 0.32\n",
      "Proportion of test data: 0.20\n",
      "Node homophily: 0.11\n",
      "Edge homophily: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Dataset must be from DGL\n",
    "dataset_name = 'CornellDataset'\n",
    "\n",
    "A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device,\n",
    "                                                     verb=True)\n",
    "N = A.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without normalizing the GSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "## Reaining params\n",
    "N_RUNS = 25\n",
    "N_EPOCHS = 200  # 500\n",
    "LR = .05\n",
    "WD = .01\n",
    "DROPOUT = 0\n",
    "\n",
    "# BEST PARAMETERS\n",
    "## Architecture params\n",
    "N_LAYERS = 2\n",
    "K = 3\n",
    "HID_DIM = 50\n",
    "\n",
    "## Model params\n",
    "h0 = 1  # 1\n",
    "NORM = False\n",
    "\n",
    "IN_DIM = feat.shape[1]\n",
    "OUT_DIM = n_class\n",
    "\n",
    "ACT = nn.ELU()  # nn.ReLU()\n",
    "LAST_ACT = nn.Softmax(dim=1)\n",
    "LOSS_FN = nn.NLLLoss() #nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting eval/test acc/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val acc: 0.864\n",
      "Test acc at best val: 0.784\n",
      "Best test acc: 0.865\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "epochs = N_EPOCHS\n",
    "epochs_h = 1\n",
    "epochs_W = 1\n",
    "lr = LR\n",
    "wd = WD\n",
    "drop = 0\n",
    "L = N_LAYERS\n",
    "K_aux = K\n",
    "hid_dim = HID_DIM\n",
    "h0_aux = 1  # 1\n",
    "norm = False\n",
    "act = ACT\n",
    "lact = LAST_ACT\n",
    "loss = LOSS_FN\n",
    "\n",
    "# Create model\n",
    "arch = GFGCN(IN_DIM, hid_dim, OUT_DIM, L, K_aux, act=act, last_act=lact,\n",
    "             dropout=drop, init_h0=h0_aux)\n",
    "S = torch.Tensor(A).to(device)\n",
    "model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "loss, acc = model.train(feat, labels, epochs, lr, wd, epochs_h=epochs_h, epochs_W=epochs_W)\n",
    "\n",
    "idx_max_acc = np.argmax(acc[\"val\"])\n",
    "print(f'Best val acc: {acc[\"val\"][idx_max_acc]:.3f}')\n",
    "print(f'Test acc at best val: {acc[\"test\"][idx_max_acc]:.3f}')\n",
    "print(f'Best test acc: {np.max(acc[\"test\"]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f43ac6f0850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(acc['train'], 'b-', label='Acc train')\n",
    "plt.plot(acc['val'], 'g-', label='Acc val')\n",
    "plt.plot(acc['test'], 'r-', label='Acc test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.plot(loss['train'], 'b-', label='Loss train')\n",
    "plt.plot(loss['val'], 'g-', label='Loss val')\n",
    "plt.plot(loss['test'], 'r-', label='Loss test')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 200-0.1-0.0005-0: 0.541 (0.595)\n",
      "-1: 200-0.05-0.0005-0: 0.459 (0.486)\n",
      "-1: 200-0.05-0.001-0: 0.703 (0.730)\n"
     ]
    }
   ],
   "source": [
    "EXPS = [\n",
    "        # {'epochs': 200, 'lr': .5, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .1, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4, 'drop': 0},\n",
    "        # {'epochs': 200, 'lr': .01, 'wd': 5e-4, 'drop': 0},\n",
    "        # {'epochs': 200, 'lr': .001, 'wd': 5e-4, 'drop': 0},\n",
    "        \n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-3, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-2, 'drop': 0},\n",
    "\n",
    "        {'epochs': 200, 'lr': .1, 'wd': 1e-3, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .1, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .1, 'wd': 5e-2, 'drop': 0},\n",
    "        \n",
    "        {'epochs': 500, 'lr': .1, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 500, 'lr': .01, 'wd': 1e-2, 'drop': 0},\n",
    "\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-2, 'drop': .25},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-2, 'drop': .5},\n",
    "        # {'epochs': 200, 'lr': .05, 'wd': 1e-2, 'drop': .75},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .25},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .5},\n",
    "        {'epochs': 750, 'lr': .05, 'wd': 1e-2, 'drop': .5},\n",
    "        {'epochs': 750, 'lr': .05, 'wd': 1e-2, 'drop': .75},\n",
    "        # {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .75},\n",
    "        ]\n",
    "\n",
    "best_accs1 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs1 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=exp['drop'], init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'])\n",
    "\n",
    "        best_accs1[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs1[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}: {best_val_accs1[j,i]:.3f} ({best_accs1[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}' for exp in EXPS]\n",
    "table_over1 = summary_table(best_accs1, index_name)\n",
    "table1 = summary_table(best_val_accs1, index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.5-0.0005-0</th>\n",
       "      <td>0.438919</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.086918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.0005-0</th>\n",
       "      <td>0.531892</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.101045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0</th>\n",
       "      <td>0.576216</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.120073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.0005-0</th>\n",
       "      <td>0.397838</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.090939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.001-0.0005-0</th>\n",
       "      <td>0.315676</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.077853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.001-0</th>\n",
       "      <td>0.616216</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.138023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0</th>\n",
       "      <td>0.754595</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.070858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.05-0</th>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.182187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.001-0</th>\n",
       "      <td>0.585946</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.097213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.01-0</th>\n",
       "      <td>0.715676</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.053576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.05-0</th>\n",
       "      <td>0.509189</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.139220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.1-0.01-0</th>\n",
       "      <td>0.727568</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.076030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0</th>\n",
       "      <td>0.769730</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.041251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.01-0</th>\n",
       "      <td>0.735135</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.035031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0.25</th>\n",
       "      <td>0.766486</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.036565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0.5</th>\n",
       "      <td>0.763243</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.083838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.25</th>\n",
       "      <td>0.764324</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.044914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.5</th>\n",
       "      <td>0.778378</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.034187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean accs       med       std\n",
       "200-0.5-0.0005-0     0.438919  0.405405  0.086918\n",
       "200-0.1-0.0005-0     0.531892  0.513514  0.101045\n",
       "200-0.05-0.0005-0    0.576216  0.567568  0.120073\n",
       "200-0.01-0.0005-0    0.397838  0.405405  0.090939\n",
       "200-0.001-0.0005-0   0.315676  0.324324  0.077853\n",
       "200-0.05-0.001-0     0.616216  0.675676  0.138023\n",
       "200-0.05-0.01-0      0.754595  0.783784  0.070858\n",
       "200-0.05-0.05-0      0.621622  0.540541  0.182187\n",
       "200-0.1-0.001-0      0.585946  0.567568  0.097213\n",
       "200-0.1-0.01-0       0.715676  0.702703  0.053576\n",
       "200-0.1-0.05-0       0.509189  0.486486  0.139220\n",
       "500-0.1-0.01-0       0.727568  0.756757  0.076030\n",
       "500-0.05-0.01-0      0.769730  0.783784  0.041251\n",
       "500-0.01-0.01-0      0.735135  0.729730  0.035031\n",
       "200-0.05-0.01-0.25   0.766486  0.756757  0.036565\n",
       "200-0.05-0.01-0.5    0.763243  0.783784  0.083838\n",
       "500-0.05-0.01-0.25   0.764324  0.756757  0.044914\n",
       "500-0.05-0.01-0.5    0.778378  0.783784  0.034187"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.5-0.0005-0</th>\n",
       "      <td>0.471351</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.086851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.0005-0</th>\n",
       "      <td>0.577297</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.095442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0</th>\n",
       "      <td>0.647568</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.125489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.0005-0</th>\n",
       "      <td>0.431351</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.083907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.001-0.0005-0</th>\n",
       "      <td>0.344865</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.073831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.001-0</th>\n",
       "      <td>0.676757</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.151251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0</th>\n",
       "      <td>0.860541</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.035594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.05-0</th>\n",
       "      <td>0.669189</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.198207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.001-0</th>\n",
       "      <td>0.632432</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.104536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.01-0</th>\n",
       "      <td>0.820541</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.055061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.05-0</th>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.134054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.1-0.01-0</th>\n",
       "      <td>0.849730</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.045917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.015441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.01-0.01-0</th>\n",
       "      <td>0.792432</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.022574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0.25</th>\n",
       "      <td>0.872432</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.019519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0.5</th>\n",
       "      <td>0.857297</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.072730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.25</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.017230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.5</th>\n",
       "      <td>0.882162</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.016887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean accs       med       std\n",
       "200-0.5-0.0005-0     0.471351  0.513514  0.086851\n",
       "200-0.1-0.0005-0     0.577297  0.540541  0.095442\n",
       "200-0.05-0.0005-0    0.647568  0.648649  0.125489\n",
       "200-0.01-0.0005-0    0.431351  0.432432  0.083907\n",
       "200-0.001-0.0005-0   0.344865  0.351351  0.073831\n",
       "200-0.05-0.001-0     0.676757  0.729730  0.151251\n",
       "200-0.05-0.01-0      0.860541  0.864865  0.035594\n",
       "200-0.05-0.05-0      0.669189  0.540541  0.198207\n",
       "200-0.1-0.001-0      0.632432  0.621622  0.104536\n",
       "200-0.1-0.01-0       0.820541  0.837838  0.055061\n",
       "200-0.1-0.05-0       0.560000  0.513514  0.134054\n",
       "500-0.1-0.01-0       0.849730  0.864865  0.045917\n",
       "500-0.05-0.01-0      0.880000  0.891892  0.015441\n",
       "500-0.01-0.01-0      0.792432  0.783784  0.022574\n",
       "200-0.05-0.01-0.25   0.872432  0.864865  0.019519\n",
       "200-0.05-0.01-0.5    0.857297  0.864865  0.072730\n",
       "500-0.05-0.01-0.25   0.880000  0.864865  0.017230\n",
       "500-0.05-0.01-0.5    0.882162  0.891892  0.016887"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_over1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 0.001-1-1-True: 0.757 (0.838)\n",
      "-1: 0.01-1-1-True: 0.811 (0.865)\n",
      "-1: 0.1-1-1-True: 0.838 (0.865)\n",
      "-1: 1-1-1-True: 0.838 (0.865)\n",
      "-1: 0.01-1-1-False: 0.838 (0.865)\n",
      "-1: 1-1-1-False: 0.703 (0.892)\n",
      "-1: 1-5-1-True: 0.730 (0.838)\n",
      "-1: 1-10-1-True: 0.757 (0.865)\n",
      "-1: 1-25-1-True: 0.784 (0.865)\n",
      "-1: 1-25-5-True: 0.730 (0.865)\n",
      "-1: 1-1-5-True: 0.811 (0.838)\n",
      "-1: 1-1-10-True: 0.703 (0.838)\n",
      "-1: 1-1-25-True: 0.784 (0.865)\n",
      "-1: 1-25-5-True: 0.757 (0.865)\n",
      "-1: 0.01-10-10-True: 0.811 (0.865)\n",
      "-1: 1-10-10-True: 0.784 (0.838)\n",
      "-1: 1-25-25-True: 0.784 (0.865)\n",
      "-1: 1-50-50-True: 0.865 (0.865)\n",
      "-2: 0.001-1-1-True: 0.757 (0.892)\n",
      "-2: 0.01-1-1-True: 0.811 (0.838)\n",
      "-2: 0.1-1-1-True: 0.757 (0.838)\n",
      "-2: 1-1-1-True: 0.784 (0.892)\n",
      "-2: 0.01-1-1-False: 0.838 (0.838)\n",
      "-2: 1-1-1-False: 0.757 (0.865)\n",
      "-2: 1-5-1-True: 0.784 (0.865)\n",
      "-2: 1-10-1-True: 0.757 (0.865)\n",
      "-2: 1-25-1-True: 0.703 (0.892)\n",
      "-2: 1-25-5-True: 0.784 (0.865)\n",
      "-2: 1-1-5-True: 0.784 (0.865)\n",
      "-2: 1-1-10-True: 0.811 (0.865)\n",
      "-2: 1-1-25-True: 0.703 (0.838)\n",
      "-2: 1-25-5-True: 0.730 (0.892)\n",
      "-2: 0.01-10-10-True: 0.757 (0.865)\n",
      "-2: 1-10-10-True: 0.865 (0.865)\n",
      "-2: 1-25-25-True: 0.811 (0.838)\n",
      "-2: 1-50-50-True: 0.730 (0.865)\n",
      "-3: 0.001-1-1-True: 0.757 (0.892)\n",
      "-3: 0.01-1-1-True: 0.784 (0.865)\n",
      "-3: 0.1-1-1-True: 0.811 (0.892)\n",
      "-3: 1-1-1-True: 0.811 (0.892)\n",
      "-3: 0.01-1-1-False: 0.784 (0.892)\n",
      "-3: 1-1-1-False: 0.811 (0.892)\n",
      "-3: 1-5-1-True: 0.784 (0.838)\n",
      "-3: 1-10-1-True: 0.757 (0.865)\n",
      "-3: 1-25-1-True: 0.784 (0.892)\n",
      "-3: 1-25-5-True: 0.811 (0.865)\n",
      "-3: 1-1-5-True: 0.703 (0.838)\n",
      "-3: 1-1-10-True: 0.811 (0.865)\n",
      "-3: 1-1-25-True: 0.784 (0.865)\n",
      "-3: 1-25-5-True: 0.703 (0.838)\n",
      "-3: 0.01-10-10-True: 0.757 (0.865)\n",
      "-3: 1-10-10-True: 0.703 (0.838)\n",
      "-3: 1-25-25-True: 0.811 (0.865)\n",
      "-3: 1-50-50-True: 0.703 (0.838)\n",
      "-4: 0.001-1-1-True: 0.811 (0.892)\n",
      "-4: 0.01-1-1-True: 0.811 (0.865)\n",
      "-4: 0.1-1-1-True: 0.757 (0.865)\n",
      "-4: 1-1-1-True: 0.838 (0.865)\n",
      "-4: 0.01-1-1-False: 0.757 (0.892)\n",
      "-4: 1-1-1-False: 0.757 (0.865)\n",
      "-4: 1-5-1-True: 0.784 (0.892)\n",
      "-4: 1-10-1-True: 0.811 (0.865)\n",
      "-4: 1-25-1-True: 0.757 (0.838)\n",
      "-4: 1-25-5-True: 0.757 (0.865)\n",
      "-4: 1-1-5-True: 0.730 (0.865)\n",
      "-4: 1-1-10-True: 0.784 (0.865)\n",
      "-4: 1-1-25-True: 0.757 (0.865)\n",
      "-4: 1-25-5-True: 0.730 (0.865)\n",
      "-4: 0.01-10-10-True: 0.784 (0.865)\n",
      "-4: 1-10-10-True: 0.784 (0.838)\n",
      "-4: 1-25-25-True: 0.703 (0.865)\n",
      "-4: 1-50-50-True: 0.730 (0.865)\n",
      "-5: 0.001-1-1-True: 0.703 (0.892)\n",
      "-5: 0.01-1-1-True: 0.784 (0.838)\n",
      "-5: 0.1-1-1-True: 0.784 (0.892)\n",
      "-5: 1-1-1-True: 0.730 (0.811)\n",
      "-5: 0.01-1-1-False: 0.811 (0.892)\n",
      "-5: 1-1-1-False: 0.757 (0.865)\n",
      "-5: 1-5-1-True: 0.703 (0.892)\n",
      "-5: 1-10-1-True: 0.784 (0.865)\n",
      "-5: 1-25-1-True: 0.703 (0.865)\n",
      "-5: 1-25-5-True: 0.811 (0.865)\n",
      "-5: 1-1-5-True: 0.811 (0.865)\n",
      "-5: 1-1-10-True: 0.811 (0.865)\n",
      "-5: 1-1-25-True: 0.784 (0.865)\n",
      "-5: 1-25-5-True: 0.784 (0.865)\n",
      "-5: 0.01-10-10-True: 0.838 (0.892)\n",
      "-5: 1-10-10-True: 0.703 (0.865)\n",
      "-5: 1-25-25-True: 0.811 (0.865)\n",
      "-5: 1-50-50-True: 0.811 (0.838)\n",
      "-6: 0.001-1-1-True: 0.757 (0.865)\n",
      "-6: 0.01-1-1-True: 0.757 (0.865)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/srey/Investigacion/robust_minmax_gnn/parameters_GF_GNN_A.ipynb Cell 14\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/parameters_GF_GNN_A.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/parameters_GF_GNN_A.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     model \u001b[39m=\u001b[39m GF_NodeClassModel(arch, S,  K, masks, LOSS_FN, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/parameters_GF_GNN_A.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     _, acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain(feat, labels, exp[\u001b[39m'\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m'\u001b[39;49m], LR, WD, epochs_h\u001b[39m=\u001b[39;49mexp[\u001b[39m'\u001b[39;49m\u001b[39mepochs_h\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/parameters_GF_GNN_A.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m                          epochs_W\u001b[39m=\u001b[39;49mexp[\u001b[39m'\u001b[39;49m\u001b[39mepochs_W\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/parameters_GF_GNN_A.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m best_accs2[j,i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(acc[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.110.1.8/home/srey/Investigacion/robust_minmax_gnn/parameters_GF_GNN_A.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m best_val_accs2[j,i] \u001b[39m=\u001b[39m acc[\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m][np\u001b[39m.\u001b[39margmax(acc[\u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m])]\n",
      "File \u001b[0;32m~/Investigacion/robust_minmax_gnn/gsp_utils/baselines_models.py:127\u001b[0m, in \u001b[0;36mGF_NodeClassModel.train\u001b[0;34m(self, X, labels, n_epochs, lr, wd, eval_freq, optim, epochs_h, epochs_W, clamp, verb)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgnn_step(X, labels, opt_W, epochs_W)\n\u001b[1;32m    126\u001b[0m \u001b[39m# Step h\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgnn_step(X, labels, opt_h, epochs_h)\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m clamp:\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39march\u001b[39m.\u001b[39mclamp_h()\n",
      "File \u001b[0;32m~/Investigacion/robust_minmax_gnn/gsp_utils/baselines_models.py:112\u001b[0m, in \u001b[0;36mGF_NodeClassModel.gnn_step\u001b[0;34m(self, X, labels, optim, iters)\u001b[0m\n\u001b[1;32m    110\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn(labels_hat[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_mask], labels[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_mask])\n\u001b[1;32m    111\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m--> 112\u001b[0m optim\u001b[39m.\u001b[39;49mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:262\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39m# Respect when the user inputs False/True for foreach or fused. We only want to change\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# the default when neither have been user-specified. Note that we default to foreach\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# and pass False to use_fused. This is not a mistake--we want to give the fused impl\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m# bake-in time before making it the default, even if it is typically faster.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m fused \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m foreach \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     _, foreach \u001b[39m=\u001b[39m _default_to_fused_or_foreach(params, differentiable, use_fused\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m fused \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     fused \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:72\u001b[0m, in \u001b[0;36m_default_to_fused_or_foreach\u001b[0;34m(params, differentiable, use_fused)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     69\u001b[0m fused \u001b[39m=\u001b[39m use_fused \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m     70\u001b[0m     p \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\u001b[39mtype\u001b[39m(p) \u001b[39min\u001b[39;00m _foreach_supported_types \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mis_cuda \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39mis_floating_point(p)) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params\n\u001b[1;32m     71\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m foreach \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m fused \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39;49m(\n\u001b[1;32m     73\u001b[0m     p \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39mor\u001b[39;49;00m (\u001b[39mtype\u001b[39;49m(p) \u001b[39min\u001b[39;49;00m _foreach_supported_types \u001b[39mand\u001b[39;49;00m p\u001b[39m.\u001b[39;49mis_cuda) \u001b[39mfor\u001b[39;49;00m p \u001b[39min\u001b[39;49;00m params\n\u001b[1;32m     74\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[39mreturn\u001b[39;00m fused, foreach\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:73\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     69\u001b[0m fused \u001b[39m=\u001b[39m use_fused \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m     70\u001b[0m     p \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\u001b[39mtype\u001b[39m(p) \u001b[39min\u001b[39;00m _foreach_supported_types \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39mis_cuda \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39mis_floating_point(p)) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params\n\u001b[1;32m     71\u001b[0m )\n\u001b[1;32m     72\u001b[0m foreach \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m fused \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m---> 73\u001b[0m     p \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\u001b[39mtype\u001b[39m(p) \u001b[39min\u001b[39;00m _foreach_supported_types \u001b[39mand\u001b[39;00m p\u001b[39m.\u001b[39;49mis_cuda) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m params\n\u001b[1;32m     74\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[39mreturn\u001b[39;00m fused, foreach\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# h0, norm (norm, not norm, norm H), sep vs joint training, optimizers iters (W vs h)\n",
    "EXPS = [\n",
    "        {'h0': .001, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        \n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 5, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 25, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 25, 'epochs_W': 5, 'alt': True},\n",
    "\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 5, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 25, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 25, 'epochs_W': 5, 'alt': True},\n",
    "        \n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 50, 'epochs_h': 50, 'epochs_W': 50, 'alt': True},\n",
    "    ]\n",
    "\n",
    "\n",
    "best_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=exp['h0'])\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        if not exp['alt']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S,  K, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD, epochs_h=exp['epochs_h'],\n",
    "                                 epochs_W=exp['epochs_W'])\n",
    "\n",
    "        best_accs2[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs2[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}: {best_val_accs2[j,i]:.3f} ({best_accs2[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}' for exp in EXPS]\n",
    "table_over2 = summary_table(best_accs2, index_name)\n",
    "table2 = summary_table(best_val_accs2, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.001-1-1-True</th>\n",
       "      <td>0.769730</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.052474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-1-1-True</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.084088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-1-1-True</th>\n",
       "      <td>0.767568</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.068374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-1-True</th>\n",
       "      <td>0.766486</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.081218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-1-1-False</th>\n",
       "      <td>0.758919</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.079413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-1-False</th>\n",
       "      <td>0.777297</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.039927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-5-1-True</th>\n",
       "      <td>0.771892</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.029685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-1-True</th>\n",
       "      <td>0.767568</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.035855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-1-True</th>\n",
       "      <td>0.767568</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.046499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-5-True</th>\n",
       "      <td>0.776216</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.039367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-5-True</th>\n",
       "      <td>0.770811</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.051349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-10-True</th>\n",
       "      <td>0.768649</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.048996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-25-True</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.048347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-5-True</th>\n",
       "      <td>0.769730</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.038314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-10-10-True</th>\n",
       "      <td>0.764324</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.047445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-10-True</th>\n",
       "      <td>0.764324</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.048056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-25-True</th>\n",
       "      <td>0.758919</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.047690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50-1-50-50-True</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.060676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean accs       med       std\n",
       "200-0.001-1-1-True    0.769730  0.783784  0.052474\n",
       "200-0.01-1-1-True     0.756757  0.756757  0.084088\n",
       "200-0.1-1-1-True      0.767568  0.783784  0.068374\n",
       "200-1-1-1-True        0.766486  0.783784  0.081218\n",
       "200-0.01-1-1-False    0.758919  0.783784  0.079413\n",
       "200-1-1-1-False       0.777297  0.783784  0.039927\n",
       "200-1-5-1-True        0.771892  0.783784  0.029685\n",
       "200-1-10-1-True       0.767568  0.756757  0.035855\n",
       "200-1-25-1-True       0.767568  0.783784  0.046499\n",
       "200-1-25-5-True       0.776216  0.783784  0.039367\n",
       "200-1-1-5-True        0.770811  0.783784  0.051349\n",
       "200-1-1-10-True       0.768649  0.783784  0.048996\n",
       "200-1-1-25-True       0.756757  0.756757  0.048347\n",
       "200-1-25-5-True       0.769730  0.783784  0.038314\n",
       "200-0.01-10-10-True   0.764324  0.756757  0.047445\n",
       "200-1-10-10-True      0.764324  0.783784  0.048056\n",
       "200-1-25-25-True      0.758919  0.756757  0.047690\n",
       "50-1-50-50-True       0.756757  0.756757  0.060676"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.001-1-1-True</th>\n",
       "      <td>0.869189</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.023784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-1-1-True</th>\n",
       "      <td>0.841081</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.069358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-1-1-True</th>\n",
       "      <td>0.851892</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.067132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-1-True</th>\n",
       "      <td>0.849730</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.067979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-1-1-False</th>\n",
       "      <td>0.848649</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.065760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-1-False</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.019459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-5-1-True</th>\n",
       "      <td>0.865946</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.017895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-1-True</th>\n",
       "      <td>0.874595</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.018537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-1-True</th>\n",
       "      <td>0.868108</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.019218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-5-True</th>\n",
       "      <td>0.870270</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.018725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-5-True</th>\n",
       "      <td>0.870270</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.017093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-10-True</th>\n",
       "      <td>0.870270</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.018725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-25-True</th>\n",
       "      <td>0.872432</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.022313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-5-True</th>\n",
       "      <td>0.870270</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.018725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-10-10-True</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.015289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-10-True</th>\n",
       "      <td>0.862703</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.016956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-25-True</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.014260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50-1-50-50-True</th>\n",
       "      <td>0.844324</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.017565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean accs       med       std\n",
       "200-0.001-1-1-True    0.869189  0.864865  0.023784\n",
       "200-0.01-1-1-True     0.841081  0.864865  0.069358\n",
       "200-0.1-1-1-True      0.851892  0.864865  0.067132\n",
       "200-1-1-1-True        0.849730  0.864865  0.067979\n",
       "200-0.01-1-1-False    0.848649  0.864865  0.065760\n",
       "200-1-1-1-False       0.863784  0.864865  0.019459\n",
       "200-1-5-1-True        0.865946  0.864865  0.017895\n",
       "200-1-10-1-True       0.874595  0.864865  0.018537\n",
       "200-1-25-1-True       0.868108  0.864865  0.019218\n",
       "200-1-25-5-True       0.870270  0.864865  0.018725\n",
       "200-1-1-5-True        0.870270  0.864865  0.017093\n",
       "200-1-1-10-True       0.870270  0.864865  0.018725\n",
       "200-1-1-25-True       0.872432  0.864865  0.022313\n",
       "200-1-25-5-True       0.870270  0.864865  0.018725\n",
       "200-0.01-10-10-True   0.864865  0.864865  0.015289\n",
       "200-1-10-10-True      0.862703  0.864865  0.016956\n",
       "200-1-25-25-True      0.863784  0.864865  0.014260\n",
       "50-1-50-50-True       0.844324  0.837838  0.017565"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_over2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 2-2-16: 0.784 (0.865)\n",
      "-1: 2-3-16: 0.784 (0.865)\n",
      "-1: 2-4-16: 0.757 (0.865)\n",
      "-1: 3-2-16: 0.622 (0.757)\n",
      "-1: 4-2-16: 0.784 (0.838)\n",
      "-1: 3-3-16: 0.784 (0.838)\n",
      "-1: 4-3-16: 0.486 (0.514)\n",
      "-1: 2-2-8: 0.811 (0.838)\n",
      "-1: 2-2-32: 0.838 (0.865)\n",
      "-1: 2-2-50: 0.784 (0.865)\n",
      "-1: 2-3-8: 0.757 (0.865)\n",
      "-1: 2-3-32: 0.757 (0.865)\n",
      "-1: 2-3-50: 0.811 (0.865)\n",
      "-1: 3-2-8: 0.784 (0.865)\n",
      "-1: 3-2-32: 0.784 (0.865)\n",
      "-1: 3-2-50: 0.703 (0.865)\n",
      "-1: 3-3-8: 0.730 (0.811)\n",
      "-1: 3-3-32: 0.730 (0.865)\n",
      "-1: 3-3-50: 0.595 (0.676)\n",
      "-2: 2-2-16: 0.784 (0.865)\n",
      "-2: 2-3-16: 0.730 (0.865)\n",
      "-2: 2-4-16: 0.730 (0.892)\n",
      "-2: 3-2-16: 0.568 (0.784)\n",
      "-2: 4-2-16: 0.595 (0.676)\n",
      "-2: 3-3-16: 0.811 (0.865)\n",
      "-2: 4-3-16: 0.514 (0.568)\n",
      "-2: 2-2-8: 0.838 (0.892)\n",
      "-2: 2-2-32: 0.811 (0.892)\n",
      "-2: 2-2-50: 0.892 (0.892)\n",
      "-2: 2-3-8: 0.703 (0.865)\n",
      "-2: 2-3-32: 0.730 (0.811)\n",
      "-2: 2-3-50: 0.811 (0.865)\n",
      "-2: 3-2-8: 0.811 (0.838)\n",
      "-2: 3-2-32: 0.757 (0.838)\n",
      "-2: 3-2-50: 0.838 (0.838)\n",
      "-2: 3-3-8: 0.811 (0.865)\n",
      "-2: 3-3-32: 0.730 (0.784)\n",
      "-2: 3-3-50: 0.568 (0.649)\n",
      "-3: 2-2-16: 0.784 (0.838)\n",
      "-3: 2-3-16: 0.811 (0.865)\n",
      "-3: 2-4-16: 0.703 (0.784)\n",
      "-3: 3-2-16: 0.784 (0.865)\n",
      "-3: 4-2-16: 0.730 (0.838)\n",
      "-3: 3-3-16: 0.757 (0.865)\n",
      "-3: 4-3-16: 0.514 (0.514)\n",
      "-3: 2-2-8: 0.838 (0.865)\n",
      "-3: 2-2-32: 0.865 (0.919)\n",
      "-3: 2-2-50: 0.838 (0.892)\n",
      "-3: 2-3-8: 0.703 (0.865)\n",
      "-3: 2-3-32: 0.757 (0.865)\n",
      "-3: 2-3-50: 0.811 (0.919)\n",
      "-3: 3-2-8: 0.649 (0.838)\n",
      "-3: 3-2-32: 0.811 (0.838)\n",
      "-3: 3-2-50: 0.757 (0.865)\n",
      "-3: 3-3-8: 0.649 (0.838)\n",
      "-3: 3-3-32: 0.811 (0.892)\n",
      "-3: 3-3-50: 0.703 (0.865)\n",
      "-4: 2-2-16: 0.784 (0.865)\n",
      "-4: 2-3-16: 0.730 (0.892)\n",
      "-4: 2-4-16: 0.757 (0.865)\n",
      "-4: 3-2-16: 0.757 (0.865)\n",
      "-4: 4-2-16: 0.622 (0.757)\n",
      "-4: 3-3-16: 0.757 (0.865)\n",
      "-4: 4-3-16: 0.811 (0.838)\n",
      "-4: 2-2-8: 0.811 (0.838)\n",
      "-4: 2-2-32: 0.757 (0.838)\n",
      "-4: 2-2-50: 0.784 (0.865)\n",
      "-4: 2-3-8: 0.730 (0.892)\n",
      "-4: 2-3-32: 0.784 (0.865)\n",
      "-4: 2-3-50: 0.784 (0.838)\n",
      "-4: 3-2-8: 0.703 (0.811)\n",
      "-4: 3-2-32: 0.784 (0.811)\n",
      "-4: 3-2-50: 0.757 (0.838)\n",
      "-4: 3-3-8: 0.730 (0.892)\n",
      "-4: 3-3-32: 0.838 (0.865)\n",
      "-4: 3-3-50: 0.757 (0.865)\n",
      "-5: 2-2-16: 0.811 (0.865)\n",
      "-5: 2-3-16: 0.784 (0.865)\n",
      "-5: 2-4-16: 0.676 (0.892)\n",
      "-5: 3-2-16: 0.811 (0.865)\n",
      "-5: 4-2-16: 0.622 (0.865)\n",
      "-5: 3-3-16: 0.649 (0.811)\n",
      "-5: 4-3-16: 0.784 (0.838)\n",
      "-5: 2-2-8: 0.784 (0.838)\n",
      "-5: 2-2-32: 0.757 (0.838)\n",
      "-5: 2-2-50: 0.784 (0.865)\n",
      "-5: 2-3-8: 0.838 (0.838)\n",
      "-5: 2-3-32: 0.811 (0.865)\n",
      "-5: 2-3-50: 0.757 (0.865)\n",
      "-5: 3-2-8: 0.757 (0.838)\n",
      "-5: 3-2-32: 0.757 (0.838)\n",
      "-5: 3-2-50: 0.730 (0.838)\n",
      "-5: 3-3-8: 0.514 (0.568)\n",
      "-5: 3-3-32: 0.622 (0.892)\n",
      "-5: 3-3-50: 0.757 (0.865)\n",
      "-6: 2-2-16: 0.703 (0.865)\n",
      "-6: 2-3-16: 0.757 (0.865)\n",
      "-6: 2-4-16: 0.757 (0.865)\n",
      "-6: 3-2-16: 0.703 (0.811)\n",
      "-6: 4-2-16: 0.730 (0.838)\n",
      "-6: 3-3-16: 0.676 (0.784)\n",
      "-6: 4-3-16: 0.568 (0.622)\n",
      "-6: 2-2-8: 0.730 (0.865)\n",
      "-6: 2-2-32: 0.703 (0.865)\n",
      "-6: 2-2-50: 0.730 (0.865)\n",
      "-6: 2-3-8: 0.784 (0.865)\n",
      "-6: 2-3-32: 0.811 (0.865)\n",
      "-6: 2-3-50: 0.784 (0.892)\n",
      "-6: 3-2-8: 0.757 (0.865)\n",
      "-6: 3-2-32: 0.784 (0.811)\n",
      "-6: 3-2-50: 0.703 (0.838)\n",
      "-6: 3-3-8: 0.595 (0.784)\n",
      "-6: 3-3-32: 0.784 (0.811)\n",
      "-6: 3-3-50: 0.757 (0.838)\n",
      "-7: 2-2-16: 0.784 (0.865)\n",
      "-7: 2-3-16: 0.676 (0.865)\n",
      "-7: 2-4-16: 0.811 (0.865)\n",
      "-7: 3-2-16: 0.703 (0.838)\n",
      "-7: 4-2-16: 0.649 (0.838)\n",
      "-7: 3-3-16: 0.676 (0.865)\n",
      "-7: 4-3-16: 0.622 (0.622)\n",
      "-7: 2-2-8: 0.730 (0.838)\n",
      "-7: 2-2-32: 0.784 (0.865)\n",
      "-7: 2-2-50: 0.838 (0.865)\n",
      "-7: 2-3-8: 0.703 (0.730)\n",
      "-7: 2-3-32: 0.703 (0.811)\n",
      "-7: 2-3-50: 0.730 (0.865)\n",
      "-7: 3-2-8: 0.757 (0.865)\n",
      "-7: 3-2-32: 0.595 (0.757)\n",
      "-7: 3-2-50: 0.703 (0.811)\n",
      "-7: 3-3-8: 0.622 (0.784)\n",
      "-7: 3-3-32: 0.730 (0.784)\n",
      "-7: 3-3-50: 0.838 (0.865)\n",
      "-8: 2-2-16: 0.757 (0.838)\n",
      "-8: 2-3-16: 0.811 (0.865)\n",
      "-8: 2-4-16: 0.676 (0.838)\n",
      "-8: 3-2-16: 0.811 (0.838)\n",
      "-8: 4-2-16: 0.649 (0.730)\n",
      "-8: 3-3-16: 0.757 (0.811)\n",
      "-8: 4-3-16: 0.703 (0.838)\n",
      "-8: 2-2-8: 0.730 (0.838)\n",
      "-8: 2-2-32: 0.784 (0.865)\n",
      "-8: 2-2-50: 0.784 (0.865)\n",
      "-8: 2-3-8: 0.703 (0.865)\n",
      "-8: 2-3-32: 0.757 (0.919)\n",
      "-8: 2-3-50: 0.838 (0.892)\n",
      "-8: 3-2-8: 0.649 (0.757)\n",
      "-8: 3-2-32: 0.730 (0.811)\n",
      "-8: 3-2-50: 0.595 (0.649)\n",
      "-8: 3-3-8: 0.703 (0.865)\n",
      "-8: 3-3-32: 0.811 (0.838)\n",
      "-8: 3-3-50: 0.784 (0.838)\n",
      "-9: 2-2-16: 0.811 (0.865)\n",
      "-9: 2-3-16: 0.784 (0.838)\n",
      "-9: 2-4-16: 0.838 (0.838)\n",
      "-9: 3-2-16: 0.811 (0.811)\n",
      "-9: 4-2-16: 0.514 (0.514)\n",
      "-9: 3-3-16: 0.649 (0.811)\n",
      "-9: 4-3-16: 0.486 (0.514)\n",
      "-9: 2-2-8: 0.757 (0.838)\n",
      "-9: 2-2-32: 0.811 (0.865)\n",
      "-9: 2-2-50: 0.730 (0.865)\n",
      "-9: 2-3-8: 0.784 (0.865)\n",
      "-9: 2-3-32: 0.757 (0.892)\n",
      "-9: 2-3-50: 0.811 (0.865)\n",
      "-9: 3-2-8: 0.676 (0.865)\n",
      "-9: 3-2-32: 0.703 (0.865)\n",
      "-9: 3-2-50: 0.784 (0.784)\n",
      "-9: 3-3-8: 0.811 (0.892)\n",
      "-9: 3-3-32: 0.514 (0.541)\n",
      "-9: 3-3-50: 0.676 (0.703)\n",
      "-10: 2-2-16: 0.811 (0.865)\n",
      "-10: 2-3-16: 0.811 (0.865)\n",
      "-10: 2-4-16: 0.757 (0.838)\n",
      "-10: 3-2-16: 0.784 (0.865)\n",
      "-10: 4-2-16: 0.676 (0.784)\n",
      "-10: 3-3-16: 0.784 (0.865)\n",
      "-10: 4-3-16: 0.622 (0.784)\n",
      "-10: 2-2-8: 0.784 (0.865)\n",
      "-10: 2-2-32: 0.703 (0.865)\n",
      "-10: 2-2-50: 0.784 (0.865)\n",
      "-10: 2-3-8: 0.784 (0.838)\n",
      "-10: 2-3-32: 0.784 (0.892)\n",
      "-10: 2-3-50: 0.838 (0.892)\n",
      "-10: 3-2-8: 0.784 (0.838)\n",
      "-10: 3-2-32: 0.865 (0.865)\n",
      "-10: 3-2-50: 0.730 (0.838)\n",
      "-10: 3-3-8: 0.703 (0.811)\n",
      "-10: 3-3-32: 0.838 (0.865)\n",
      "-10: 3-3-50: 0.784 (0.919)\n",
      "-11: 2-2-16: 0.784 (0.865)\n",
      "-11: 2-3-16: 0.757 (0.892)\n",
      "-11: 2-4-16: 0.730 (0.865)\n",
      "-11: 3-2-16: 0.757 (0.892)\n",
      "-11: 4-2-16: 0.730 (0.838)\n",
      "-11: 3-3-16: 0.757 (0.919)\n",
      "-11: 4-3-16: 0.514 (0.514)\n",
      "-11: 2-2-8: 0.838 (0.838)\n",
      "-11: 2-2-32: 0.703 (0.865)\n",
      "-11: 2-2-50: 0.784 (0.865)\n",
      "-11: 2-3-8: 0.811 (0.865)\n",
      "-11: 2-3-32: 0.838 (0.865)\n",
      "-11: 2-3-50: 0.811 (0.892)\n",
      "-11: 3-2-8: 0.811 (0.865)\n",
      "-11: 3-2-32: 0.757 (0.865)\n",
      "-11: 3-2-50: 0.595 (0.784)\n",
      "-11: 3-3-8: 0.730 (0.784)\n",
      "-11: 3-3-32: 0.757 (0.865)\n",
      "-11: 3-3-50: 0.757 (0.865)\n",
      "-12: 2-2-16: 0.757 (0.838)\n",
      "-12: 2-3-16: 0.703 (0.892)\n",
      "-12: 2-4-16: 0.811 (0.811)\n",
      "-12: 3-2-16: 0.757 (0.838)\n",
      "-12: 4-2-16: 0.784 (0.784)\n",
      "-12: 3-3-16: 0.703 (0.811)\n",
      "-12: 4-3-16: 0.676 (0.784)\n",
      "-12: 2-2-8: 0.811 (0.892)\n",
      "-12: 2-2-32: 0.811 (0.865)\n",
      "-12: 2-2-50: 0.865 (0.865)\n",
      "-12: 2-3-8: 0.784 (0.892)\n",
      "-12: 2-3-32: 0.811 (0.865)\n",
      "-12: 2-3-50: 0.811 (0.838)\n",
      "-12: 3-2-8: 0.784 (0.838)\n",
      "-12: 3-2-32: 0.784 (0.865)\n",
      "-12: 3-2-50: 0.649 (0.784)\n",
      "-12: 3-3-8: 0.757 (0.892)\n",
      "-12: 3-3-32: 0.676 (0.865)\n",
      "-12: 3-3-50: 0.811 (0.838)\n",
      "-13: 2-2-16: 0.730 (0.865)\n",
      "-13: 2-3-16: 0.757 (0.892)\n",
      "-13: 2-4-16: 0.757 (0.865)\n",
      "-13: 3-2-16: 0.622 (0.676)\n",
      "-13: 4-2-16: 0.730 (0.811)\n",
      "-13: 3-3-16: 0.784 (0.811)\n",
      "-13: 4-3-16: 0.568 (0.730)\n",
      "-13: 2-2-8: 0.784 (0.838)\n",
      "-13: 2-2-32: 0.784 (0.865)\n",
      "-13: 2-2-50: 0.784 (0.865)\n",
      "-13: 2-3-8: 0.784 (0.865)\n",
      "-13: 2-3-32: 0.757 (0.892)\n",
      "-13: 2-3-50: 0.811 (0.865)\n",
      "-13: 3-2-8: 0.676 (0.811)\n",
      "-13: 3-2-32: 0.703 (0.892)\n",
      "-13: 3-2-50: 0.811 (0.892)\n",
      "-13: 3-3-8: 0.568 (0.703)\n",
      "-13: 3-3-32: 0.432 (0.541)\n",
      "-13: 3-3-50: 0.730 (0.838)\n",
      "-14: 2-2-16: 0.757 (0.865)\n",
      "-14: 2-3-16: 0.838 (0.838)\n",
      "-14: 2-4-16: 0.811 (0.892)\n",
      "-14: 3-2-16: 0.784 (0.892)\n",
      "-14: 4-2-16: 0.676 (0.865)\n",
      "-14: 3-3-16: 0.459 (0.541)\n",
      "-14: 4-3-16: 0.784 (0.811)\n",
      "-14: 2-2-8: 0.730 (0.811)\n",
      "-14: 2-2-32: 0.757 (0.865)\n",
      "-14: 2-2-50: 0.757 (0.892)\n",
      "-14: 2-3-8: 0.730 (0.811)\n",
      "-14: 2-3-32: 0.757 (0.865)\n",
      "-14: 2-3-50: 0.703 (0.865)\n",
      "-14: 3-2-8: 0.703 (0.838)\n",
      "-14: 3-2-32: 0.676 (0.838)\n",
      "-14: 3-2-50: 0.703 (0.811)\n",
      "-14: 3-3-8: 0.730 (0.811)\n",
      "-14: 3-3-32: 0.703 (0.838)\n",
      "-14: 3-3-50: 0.486 (0.568)\n",
      "-15: 2-2-16: 0.838 (0.865)\n",
      "-15: 2-3-16: 0.811 (0.892)\n",
      "-15: 2-4-16: 0.757 (0.811)\n",
      "-15: 3-2-16: 0.676 (0.811)\n",
      "-15: 4-2-16: 0.649 (0.730)\n",
      "-15: 3-3-16: 0.838 (0.838)\n",
      "-15: 4-3-16: 0.514 (0.514)\n",
      "-15: 2-2-8: 0.838 (0.838)\n",
      "-15: 2-2-32: 0.811 (0.838)\n",
      "-15: 2-2-50: 0.784 (0.865)\n",
      "-15: 2-3-8: 0.757 (0.865)\n",
      "-15: 2-3-32: 0.838 (0.865)\n",
      "-15: 2-3-50: 0.757 (0.865)\n",
      "-15: 3-2-8: 0.757 (0.784)\n",
      "-15: 3-2-32: 0.730 (0.811)\n",
      "-15: 3-2-50: 0.622 (0.811)\n",
      "-15: 3-3-8: 0.514 (0.514)\n",
      "-15: 3-3-32: 0.757 (0.838)\n",
      "-15: 3-3-50: 0.757 (0.784)\n",
      "-16: 2-2-16: 0.784 (0.865)\n",
      "-16: 2-3-16: 0.784 (0.865)\n",
      "-16: 2-4-16: 0.757 (0.811)\n",
      "-16: 3-2-16: 0.730 (0.838)\n",
      "-16: 4-2-16: 0.730 (0.784)\n",
      "-16: 3-3-16: 0.703 (0.757)\n",
      "-16: 4-3-16: 0.703 (0.784)\n",
      "-16: 2-2-8: 0.730 (0.811)\n",
      "-16: 2-2-32: 0.838 (0.838)\n",
      "-16: 2-2-50: 0.730 (0.865)\n",
      "-16: 2-3-8: 0.784 (0.865)\n",
      "-16: 2-3-32: 0.757 (0.865)\n",
      "-16: 2-3-50: 0.865 (0.892)\n",
      "-16: 3-2-8: 0.757 (0.892)\n",
      "-16: 3-2-32: 0.703 (0.892)\n",
      "-16: 3-2-50: 0.649 (0.757)\n",
      "-16: 3-3-8: 0.784 (0.865)\n",
      "-16: 3-3-32: 0.784 (0.811)\n",
      "-16: 3-3-50: 0.541 (0.676)\n",
      "-17: 2-2-16: 0.811 (0.838)\n",
      "-17: 2-3-16: 0.757 (0.892)\n",
      "-17: 2-4-16: 0.757 (0.892)\n",
      "-17: 3-2-16: 0.730 (0.865)\n",
      "-17: 4-2-16: 0.838 (0.838)\n",
      "-17: 3-3-16: 0.649 (0.757)\n",
      "-17: 4-3-16: 0.676 (0.757)\n",
      "-17: 2-2-8: 0.811 (0.838)\n",
      "-17: 2-2-32: 0.757 (0.892)\n",
      "-17: 2-2-50: 0.757 (0.838)\n",
      "-17: 2-3-8: 0.676 (0.811)\n",
      "-17: 2-3-32: 0.811 (0.892)\n",
      "-17: 2-3-50: 0.757 (0.892)\n",
      "-17: 3-2-8: 0.784 (0.811)\n",
      "-17: 3-2-32: 0.757 (0.865)\n",
      "-17: 3-2-50: 0.757 (0.838)\n",
      "-17: 3-3-8: 0.622 (0.811)\n",
      "-17: 3-3-32: 0.730 (0.919)\n",
      "-17: 3-3-50: 0.703 (0.838)\n",
      "-18: 2-2-16: 0.757 (0.865)\n",
      "-18: 2-3-16: 0.757 (0.865)\n",
      "-18: 2-4-16: 0.730 (0.865)\n",
      "-18: 3-2-16: 0.514 (0.568)\n",
      "-18: 4-2-16: 0.784 (0.865)\n",
      "-18: 3-3-16: 0.676 (0.703)\n",
      "-18: 4-3-16: 0.595 (0.649)\n",
      "-18: 2-2-8: 0.784 (0.838)\n",
      "-18: 2-2-32: 0.784 (0.865)\n",
      "-18: 2-2-50: 0.730 (0.865)\n",
      "-18: 2-3-8: 0.784 (0.892)\n",
      "-18: 2-3-32: 0.757 (0.838)\n",
      "-18: 2-3-50: 0.757 (0.838)\n",
      "-18: 3-2-8: 0.811 (0.865)\n",
      "-18: 3-2-32: 0.649 (0.838)\n",
      "-18: 3-2-50: 0.784 (0.865)\n",
      "-18: 3-3-8: 0.784 (0.838)\n",
      "-18: 3-3-32: 0.784 (0.811)\n",
      "-18: 3-3-50: 0.730 (0.784)\n",
      "-19: 2-2-16: 0.784 (0.865)\n",
      "-19: 2-3-16: 0.865 (0.865)\n",
      "-19: 2-4-16: 0.811 (0.865)\n",
      "-19: 3-2-16: 0.730 (0.892)\n",
      "-19: 4-2-16: 0.757 (0.865)\n",
      "-19: 3-3-16: 0.811 (0.865)\n",
      "-19: 4-3-16: 0.730 (0.757)\n",
      "-19: 2-2-8: 0.838 (0.892)\n",
      "-19: 2-2-32: 0.784 (0.865)\n",
      "-19: 2-2-50: 0.811 (0.892)\n",
      "-19: 2-3-8: 0.676 (0.865)\n",
      "-19: 2-3-32: 0.784 (0.838)\n",
      "-19: 2-3-50: 0.784 (0.892)\n",
      "-19: 3-2-8: 0.811 (0.892)\n",
      "-19: 3-2-32: 0.757 (0.892)\n",
      "-19: 3-2-50: 0.676 (0.838)\n",
      "-19: 3-3-8: 0.703 (0.838)\n",
      "-19: 3-3-32: 0.730 (0.865)\n",
      "-19: 3-3-50: 0.730 (0.757)\n",
      "-20: 2-2-16: 0.757 (0.865)\n",
      "-20: 2-3-16: 0.730 (0.892)\n",
      "-20: 2-4-16: 0.757 (0.838)\n",
      "-20: 3-2-16: 0.811 (0.865)\n",
      "-20: 4-2-16: 0.730 (0.784)\n",
      "-20: 3-3-16: 0.541 (0.541)\n",
      "-20: 4-3-16: 0.703 (0.811)\n",
      "-20: 2-2-8: 0.811 (0.838)\n",
      "-20: 2-2-32: 0.730 (0.838)\n",
      "-20: 2-2-50: 0.811 (0.919)\n",
      "-20: 2-3-8: 0.784 (0.838)\n",
      "-20: 2-3-32: 0.811 (0.865)\n",
      "-20: 2-3-50: 0.784 (0.838)\n",
      "-20: 3-2-8: 0.703 (0.838)\n",
      "-20: 3-2-32: 0.730 (0.865)\n",
      "-20: 3-2-50: 0.622 (0.865)\n",
      "-20: 3-3-8: 0.730 (0.838)\n",
      "-20: 3-3-32: 0.865 (0.865)\n",
      "-20: 3-3-50: 0.676 (0.784)\n",
      "-21: 2-2-16: 0.811 (0.838)\n",
      "-21: 2-3-16: 0.784 (0.838)\n",
      "-21: 2-4-16: 0.784 (0.865)\n",
      "-21: 3-2-16: 0.811 (0.892)\n",
      "-21: 4-2-16: 0.730 (0.838)\n",
      "-21: 3-3-16: 0.703 (0.757)\n",
      "-21: 4-3-16: 0.514 (0.514)\n",
      "-21: 2-2-8: 0.730 (0.865)\n",
      "-21: 2-2-32: 0.784 (0.865)\n",
      "-21: 2-2-50: 0.784 (0.865)\n",
      "-21: 2-3-8: 0.784 (0.892)\n",
      "-21: 2-3-32: 0.649 (0.703)\n",
      "-21: 2-3-50: 0.784 (0.865)\n",
      "-21: 3-2-8: 0.676 (0.811)\n",
      "-21: 3-2-32: 0.595 (0.838)\n",
      "-21: 3-2-50: 0.757 (0.865)\n",
      "-21: 3-3-8: 0.730 (0.784)\n",
      "-21: 3-3-32: 0.784 (0.784)\n",
      "-21: 3-3-50: 0.757 (0.811)\n",
      "-22: 2-2-16: 0.784 (0.865)\n",
      "-22: 2-3-16: 0.757 (0.865)\n",
      "-22: 2-4-16: 0.811 (0.811)\n",
      "-22: 3-2-16: 0.811 (0.811)\n",
      "-22: 4-2-16: 0.703 (0.838)\n",
      "-22: 3-3-16: 0.514 (0.568)\n",
      "-22: 4-3-16: 0.541 (0.649)\n",
      "-22: 2-2-8: 0.757 (0.838)\n",
      "-22: 2-2-32: 0.865 (0.892)\n",
      "-22: 2-2-50: 0.838 (0.865)\n",
      "-22: 2-3-8: 0.784 (0.838)\n",
      "-22: 2-3-32: 0.811 (0.838)\n",
      "-22: 2-3-50: 0.784 (0.865)\n",
      "-22: 3-2-8: 0.838 (0.865)\n",
      "-22: 3-2-32: 0.757 (0.892)\n",
      "-22: 3-2-50: 0.730 (0.838)\n",
      "-22: 3-3-8: 0.811 (0.892)\n",
      "-22: 3-3-32: 0.730 (0.892)\n",
      "-22: 3-3-50: 0.811 (0.865)\n",
      "-23: 2-2-16: 0.811 (0.865)\n",
      "-23: 2-3-16: 0.811 (0.865)\n",
      "-23: 2-4-16: 0.784 (0.865)\n",
      "-23: 3-2-16: 0.784 (0.838)\n",
      "-23: 4-2-16: 0.703 (0.757)\n",
      "-23: 3-3-16: 0.730 (0.838)\n",
      "-23: 4-3-16: 0.730 (0.811)\n",
      "-23: 2-2-8: 0.838 (0.865)\n",
      "-23: 2-2-32: 0.811 (0.865)\n",
      "-23: 2-2-50: 0.784 (0.865)\n",
      "-23: 2-3-8: 0.757 (0.865)\n",
      "-23: 2-3-32: 0.784 (0.811)\n",
      "-23: 2-3-50: 0.757 (0.838)\n",
      "-23: 3-2-8: 0.676 (0.784)\n",
      "-23: 3-2-32: 0.757 (0.838)\n",
      "-23: 3-2-50: 0.757 (0.865)\n",
      "-23: 3-3-8: 0.649 (0.757)\n",
      "-23: 3-3-32: 0.730 (0.838)\n",
      "-23: 3-3-50: 0.486 (0.514)\n",
      "-24: 2-2-16: 0.811 (0.838)\n",
      "-24: 2-3-16: 0.757 (0.892)\n",
      "-24: 2-4-16: 0.838 (0.865)\n",
      "-24: 3-2-16: 0.730 (0.838)\n",
      "-24: 4-2-16: 0.568 (0.622)\n",
      "-24: 3-3-16: 0.649 (0.811)\n",
      "-24: 4-3-16: 0.703 (0.757)\n",
      "-24: 2-2-8: 0.730 (0.838)\n",
      "-24: 2-2-32: 0.811 (0.865)\n",
      "-24: 2-2-50: 0.838 (0.892)\n",
      "-24: 2-3-8: 0.757 (0.865)\n",
      "-24: 2-3-32: 0.811 (0.865)\n",
      "-24: 2-3-50: 0.838 (0.865)\n",
      "-24: 3-2-8: 0.757 (0.865)\n",
      "-24: 3-2-32: 0.784 (0.838)\n",
      "-24: 3-2-50: 0.595 (0.865)\n",
      "-24: 3-3-8: 0.784 (0.865)\n",
      "-24: 3-3-32: 0.703 (0.838)\n",
      "-24: 3-3-50: 0.730 (0.865)\n",
      "-25: 2-2-16: 0.784 (0.865)\n",
      "-25: 2-3-16: 0.811 (0.892)\n",
      "-25: 2-4-16: 0.730 (0.838)\n",
      "-25: 3-2-16: 0.838 (0.892)\n",
      "-25: 4-2-16: 0.730 (0.784)\n",
      "-25: 3-3-16: 0.730 (0.838)\n",
      "-25: 4-3-16: 0.703 (0.784)\n",
      "-25: 2-2-8: 0.838 (0.838)\n",
      "-25: 2-2-32: 0.784 (0.892)\n",
      "-25: 2-2-50: 0.784 (0.865)\n",
      "-25: 2-3-8: 0.784 (0.838)\n",
      "-25: 2-3-32: 0.784 (0.865)\n",
      "-25: 2-3-50: 0.757 (0.892)\n",
      "-25: 3-2-8: 0.757 (0.811)\n",
      "-25: 3-2-32: 0.892 (0.892)\n",
      "-25: 3-2-50: 0.730 (0.838)\n",
      "-25: 3-3-8: 0.595 (0.703)\n",
      "-25: 3-3-32: 0.730 (0.865)\n",
      "-25: 3-3-50: 0.703 (0.865)\n",
      "----- 10.96 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'L': 2, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 4, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 3, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 50},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 75},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 100},\n",
    "\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 50},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 75},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 100},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 50},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 50},\n",
    "        ]\n",
    "\n",
    "best_accs3 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs3 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, exp['hid_dim'], OUT_DIM, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  exp['K'], masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs3[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs3[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}: {best_val_accs3[j,i]:.3f} ({best_accs3[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}' for exp in EXPS]\n",
    "table_over3 = summary_table(best_accs3, index_name)\n",
    "table3 = summary_table(best_val_accs3, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-2-16</th>\n",
       "      <td>0.782703</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.029089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-16</th>\n",
       "      <td>0.774054</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.041786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-4-16</th>\n",
       "      <td>0.763243</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.043432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-16</th>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.081088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2-16</th>\n",
       "      <td>0.696216</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.073434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-16</th>\n",
       "      <td>0.701622</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.091567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-3-16</th>\n",
       "      <td>0.630270</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.101334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-8</th>\n",
       "      <td>0.787027</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.042781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-32</th>\n",
       "      <td>0.784865</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.044232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-50</th>\n",
       "      <td>0.791351</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.041534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-8</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.041870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-32</th>\n",
       "      <td>0.776216</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.041534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-50</th>\n",
       "      <td>0.789189</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.036661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-8</th>\n",
       "      <td>0.744865</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.055167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-32</th>\n",
       "      <td>0.743784</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.067565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-50</th>\n",
       "      <td>0.709189</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.067635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-8</th>\n",
       "      <td>0.694054</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.087734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-32</th>\n",
       "      <td>0.731892</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.093599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-50</th>\n",
       "      <td>0.704865</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.095147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean accs       med       std\n",
       "2-2-16   0.782703  0.783784  0.029089\n",
       "2-3-16   0.774054  0.783784  0.041786\n",
       "2-4-16   0.763243  0.756757  0.043432\n",
       "3-2-16   0.737297  0.756757  0.081088\n",
       "4-2-16   0.696216  0.729730  0.073434\n",
       "3-3-16   0.701622  0.702703  0.091567\n",
       "4-3-16   0.630270  0.621622  0.101334\n",
       "2-2-8    0.787027  0.783784  0.042781\n",
       "2-2-32   0.784865  0.783784  0.044232\n",
       "2-2-50   0.791351  0.783784  0.041534\n",
       "2-3-8    0.756757  0.783784  0.041870\n",
       "2-3-32   0.776216  0.783784  0.041534\n",
       "2-3-50   0.789189  0.783784  0.036661\n",
       "3-2-8    0.744865  0.756757  0.055167\n",
       "3-2-32   0.743784  0.756757  0.067565\n",
       "3-2-50   0.709189  0.729730  0.067635\n",
       "3-3-8    0.694054  0.729730  0.087734\n",
       "3-3-32   0.731892  0.729730  0.093599\n",
       "3-3-50   0.704865  0.729730  0.095147"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-2-16</th>\n",
       "      <td>0.858378</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.011543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-16</th>\n",
       "      <td>0.871351</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.017565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-4-16</th>\n",
       "      <td>0.851892</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.028725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-16</th>\n",
       "      <td>0.828108</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.071662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2-16</th>\n",
       "      <td>0.787027</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.082091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-16</th>\n",
       "      <td>0.789189</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.099377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-3-16</th>\n",
       "      <td>0.690811</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.122329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-8</th>\n",
       "      <td>0.847568</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.021459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-32</th>\n",
       "      <td>0.865946</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.019459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-50</th>\n",
       "      <td>0.871351</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.015815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-8</th>\n",
       "      <td>0.854054</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.033321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-32</th>\n",
       "      <td>0.855135</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.040364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-50</th>\n",
       "      <td>0.870270</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-8</th>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.033321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-32</th>\n",
       "      <td>0.848649</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.032432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-50</th>\n",
       "      <td>0.827027</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.048347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-8</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.092683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-32</th>\n",
       "      <td>0.822703</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.090152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-50</th>\n",
       "      <td>0.789189</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.100837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean accs       med       std\n",
       "2-2-16   0.858378  0.864865  0.011543\n",
       "2-3-16   0.871351  0.864865  0.017565\n",
       "2-4-16   0.851892  0.864865  0.028725\n",
       "3-2-16   0.828108  0.837838  0.071662\n",
       "4-2-16   0.787027  0.810811  0.082091\n",
       "3-3-16   0.789189  0.810811  0.099377\n",
       "4-3-16   0.690811  0.756757  0.122329\n",
       "2-2-8    0.847568  0.837838  0.021459\n",
       "2-2-32   0.865946  0.864865  0.019459\n",
       "2-2-50   0.871351  0.864865  0.015815\n",
       "2-3-8    0.854054  0.864865  0.033321\n",
       "2-3-32   0.855135  0.864865  0.040364\n",
       "2-3-50   0.870270  0.864865  0.021622\n",
       "3-2-8    0.837838  0.837838  0.033321\n",
       "3-2-32   0.848649  0.837838  0.032432\n",
       "3-2-50   0.827027  0.837838  0.048347\n",
       "3-3-8    0.800000  0.810811  0.092683\n",
       "3-3-32   0.822703  0.837838  0.090152\n",
       "3-3-50   0.789189  0.837838  0.100837"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_over3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearities and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.865)\n",
      "-1: ReLU()-Softmax(dim=1)-NLLLoss(): 0.730 (0.865)\n",
      "-1: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.730 (0.784)\n",
      "-1: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.784 (0.784)\n",
      "-1: ReLU()-Identity()-CrossEntropyLoss(): 0.676 (0.757)\n",
      "-1: ReLU()-Identity()-NLLLoss(): 0.378 (0.405)\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.838)\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.865)\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.811 (0.838)\n",
      "-1: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.838)\n",
      "-1: Identity()-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-1: Identity()-Identity()-CrossEntropyLoss(): 0.757 (0.757)\n",
      "-2: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-2: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-2: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.649 (0.649)\n",
      "-2: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730 (0.730)\n",
      "-2: ReLU()-Identity()-CrossEntropyLoss(): 0.622 (0.649)\n",
      "-2: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.865)\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.730 (0.919)\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.892)\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-2: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.703 (0.892)\n",
      "-2: Identity()-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-2: Identity()-Identity()-CrossEntropyLoss(): 0.703 (0.703)\n",
      "-3: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-3: ReLU()-Softmax(dim=1)-NLLLoss(): 0.784 (0.865)\n",
      "-3: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.622 (0.676)\n",
      "-3: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730 (0.757)\n",
      "-3: ReLU()-Identity()-CrossEntropyLoss(): 0.757 (0.811)\n",
      "-3: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.892)\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.730 (0.811)\n",
      "-3: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.838)\n",
      "-3: Identity()-Softmax(dim=1)-NLLLoss(): 0.703 (0.865)\n",
      "-3: Identity()-Identity()-CrossEntropyLoss(): 0.676 (0.703)\n",
      "-4: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.865)\n",
      "-4: ReLU()-Softmax(dim=1)-NLLLoss(): 0.784 (0.838)\n",
      "-4: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.811 (0.811)\n",
      "-4: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730 (0.757)\n",
      "-4: ReLU()-Identity()-CrossEntropyLoss(): 0.622 (0.676)\n",
      "-4: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838 (0.865)\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.892)\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.730 (0.865)\n",
      "-4: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.919)\n",
      "-4: Identity()-Softmax(dim=1)-NLLLoss(): 0.730 (0.865)\n",
      "-4: Identity()-Identity()-CrossEntropyLoss(): 0.703 (0.730)\n",
      "-5: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.892)\n",
      "-5: ReLU()-Softmax(dim=1)-NLLLoss(): 0.703 (0.865)\n",
      "-5: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.865 (0.865)\n",
      "-5: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.622 (0.757)\n",
      "-5: ReLU()-Identity()-CrossEntropyLoss(): 0.838 (0.892)\n",
      "-5: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.892)\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811 (0.838)\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.865)\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-5: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.838)\n",
      "-5: Identity()-Softmax(dim=1)-NLLLoss(): 0.784 (0.865)\n",
      "-5: Identity()-Identity()-CrossEntropyLoss(): 0.514 (0.541)\n",
      "-6: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-6: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-6: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.622 (0.703)\n",
      "-6: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.595 (0.622)\n",
      "-6: ReLU()-Identity()-CrossEntropyLoss(): 0.649 (0.676)\n",
      "-6: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.703 (0.865)\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-6: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.892)\n",
      "-6: Identity()-Softmax(dim=1)-NLLLoss(): 0.784 (0.892)\n",
      "-6: Identity()-Identity()-CrossEntropyLoss(): 0.784 (0.784)\n",
      "-7: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.892)\n",
      "-7: ReLU()-Softmax(dim=1)-NLLLoss(): 0.757 (0.892)\n",
      "-7: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.730 (0.784)\n",
      "-7: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.757 (0.784)\n",
      "-7: ReLU()-Identity()-CrossEntropyLoss(): 0.649 (0.757)\n",
      "-7: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.892)\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838 (0.892)\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838 (0.838)\n",
      "-7: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.703 (0.865)\n",
      "-7: Identity()-Softmax(dim=1)-NLLLoss(): 0.784 (0.865)\n",
      "-7: Identity()-Identity()-CrossEntropyLoss(): 0.649 (0.649)\n",
      "-8: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.892)\n",
      "-8: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811 (0.838)\n",
      "-8: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.649 (0.703)\n",
      "-8: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.703 (0.730)\n",
      "-8: ReLU()-Identity()-CrossEntropyLoss(): 0.811 (0.838)\n",
      "-8: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.892)\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.892)\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-8: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.838)\n",
      "-8: Identity()-Softmax(dim=1)-NLLLoss(): 0.703 (0.811)\n",
      "-8: Identity()-Identity()-CrossEntropyLoss(): 0.676 (0.676)\n",
      "-9: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.865)\n",
      "-9: ReLU()-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-9: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.784 (0.784)\n",
      "-9: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.784 (0.811)\n",
      "-9: ReLU()-Identity()-CrossEntropyLoss(): 0.649 (0.676)\n",
      "-9: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.865)\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.784 (0.838)\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.784 (0.838)\n",
      "-9: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.865)\n",
      "-9: Identity()-Softmax(dim=1)-NLLLoss(): 0.568 (0.622)\n",
      "-9: Identity()-Identity()-CrossEntropyLoss(): 0.703 (0.703)\n",
      "-10: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.811)\n",
      "-10: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-10: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.757 (0.757)\n",
      "-10: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.703 (0.730)\n",
      "-10: ReLU()-Identity()-CrossEntropyLoss(): 0.622 (0.649)\n",
      "-10: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.784 (0.919)\n",
      "-10: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-10: Identity()-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-10: Identity()-Identity()-CrossEntropyLoss(): 0.730 (0.730)\n",
      "-11: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-11: ReLU()-Softmax(dim=1)-NLLLoss(): 0.703 (0.892)\n",
      "-11: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.784 (0.838)\n",
      "-11: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.811 (0.838)\n",
      "-11: ReLU()-Identity()-CrossEntropyLoss(): 0.622 (0.703)\n",
      "-11: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.838)\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.676 (0.865)\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.838)\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-11: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-11: Identity()-Softmax(dim=1)-NLLLoss(): 0.730 (0.865)\n",
      "-11: Identity()-Identity()-CrossEntropyLoss(): 0.757 (0.757)\n",
      "-12: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.865)\n",
      "-12: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-12: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.676 (0.730)\n",
      "-12: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.622 (0.703)\n",
      "-12: ReLU()-Identity()-CrossEntropyLoss(): 0.676 (0.703)\n",
      "-12: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.865)\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.730 (0.865)\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.838)\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-12: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-12: Identity()-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-12: Identity()-Identity()-CrossEntropyLoss(): 0.595 (0.622)\n",
      "-13: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.865)\n",
      "-13: ReLU()-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-13: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.622 (0.676)\n",
      "-13: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730 (0.730)\n",
      "-13: ReLU()-Identity()-CrossEntropyLoss(): 0.811 (0.811)\n",
      "-13: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.892)\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.676 (0.919)\n",
      "-13: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.892)\n",
      "-13: Identity()-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-13: Identity()-Identity()-CrossEntropyLoss(): 0.622 (0.649)\n",
      "-14: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-14: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811 (0.838)\n",
      "-14: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.703 (0.730)\n",
      "-14: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.514 (0.649)\n",
      "-14: ReLU()-Identity()-CrossEntropyLoss(): 0.703 (0.757)\n",
      "-14: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.514 (0.541)\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.784 (0.892)\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.892)\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.784 (0.865)\n",
      "-14: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-14: Identity()-Softmax(dim=1)-NLLLoss(): 0.649 (0.811)\n",
      "-14: Identity()-Identity()-CrossEntropyLoss(): 0.703 (0.703)\n",
      "-15: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-15: ReLU()-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-15: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.757 (0.811)\n",
      "-15: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649 (0.676)\n",
      "-15: ReLU()-Identity()-CrossEntropyLoss(): 0.703 (0.703)\n",
      "-15: ReLU()-Identity()-NLLLoss(): 0.378 (0.405)\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838 (0.892)\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-15: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.865 (0.865)\n",
      "-15: Identity()-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-15: Identity()-Identity()-CrossEntropyLoss(): 0.405 (0.541)\n",
      "-16: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.838)\n",
      "-16: ReLU()-Softmax(dim=1)-NLLLoss(): 0.757 (0.865)\n",
      "-16: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.784 (0.811)\n",
      "-16: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730 (0.757)\n",
      "-16: ReLU()-Identity()-CrossEntropyLoss(): 0.595 (0.676)\n",
      "-16: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.784)\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.784 (0.892)\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.838)\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.784 (0.865)\n",
      "-16: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.703 (0.838)\n",
      "-16: Identity()-Softmax(dim=1)-NLLLoss(): 0.703 (0.811)\n",
      "-16: Identity()-Identity()-CrossEntropyLoss(): 0.757 (0.784)\n",
      "-17: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.838)\n",
      "-17: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-17: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.784 (0.811)\n",
      "-17: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.622 (0.676)\n",
      "-17: ReLU()-Identity()-CrossEntropyLoss(): 0.784 (0.784)\n",
      "-17: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.784 (0.865)\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.784 (0.865)\n",
      "-17: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.892)\n",
      "-17: Identity()-Softmax(dim=1)-NLLLoss(): 0.757 (0.892)\n",
      "-17: Identity()-Identity()-CrossEntropyLoss(): 0.730 (0.730)\n",
      "-18: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.838)\n",
      "-18: ReLU()-Softmax(dim=1)-NLLLoss(): 0.784 (0.892)\n",
      "-18: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.622 (0.622)\n",
      "-18: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.838 (0.838)\n",
      "-18: ReLU()-Identity()-CrossEntropyLoss(): 0.730 (0.784)\n",
      "-18: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.811)\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.838 (0.892)\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.892)\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.757 (0.892)\n",
      "-18: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.622 (0.703)\n",
      "-18: Identity()-Softmax(dim=1)-NLLLoss(): 0.730 (0.838)\n",
      "-18: Identity()-Identity()-CrossEntropyLoss(): 0.568 (0.595)\n",
      "-19: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-19: ReLU()-Softmax(dim=1)-NLLLoss(): 0.784 (0.865)\n",
      "-19: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.703 (0.757)\n",
      "-19: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730 (0.757)\n",
      "-19: ReLU()-Identity()-CrossEntropyLoss(): 0.703 (0.730)\n",
      "-19: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.865)\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.730 (0.865)\n",
      "-19: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-19: Identity()-Softmax(dim=1)-NLLLoss(): 0.514 (0.703)\n",
      "-19: Identity()-Identity()-CrossEntropyLoss(): 0.730 (0.730)\n",
      "-20: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-20: ReLU()-Softmax(dim=1)-NLLLoss(): 0.730 (0.865)\n",
      "-20: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.595 (0.649)\n",
      "-20: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.757 (0.757)\n",
      "-20: ReLU()-Identity()-CrossEntropyLoss(): 0.784 (0.811)\n",
      "-20: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.892)\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.703 (0.865)\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.892)\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.703 (0.892)\n",
      "-20: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.865)\n",
      "-20: Identity()-Softmax(dim=1)-NLLLoss(): 0.730 (0.865)\n",
      "-20: Identity()-Identity()-CrossEntropyLoss(): 0.784 (0.784)\n",
      "-21: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.838 (0.865)\n",
      "-21: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811 (0.838)\n",
      "-21: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.676 (0.703)\n",
      "-21: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730 (0.757)\n",
      "-21: ReLU()-Identity()-CrossEntropyLoss(): 0.649 (0.703)\n",
      "-21: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.676 (0.838)\n",
      "-21: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811 (0.838)\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-21: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.757 (0.892)\n",
      "-21: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.892)\n",
      "-21: Identity()-Softmax(dim=1)-NLLLoss(): 0.703 (0.838)\n",
      "-21: Identity()-Identity()-CrossEntropyLoss(): 0.649 (0.703)\n",
      "-22: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.838)\n",
      "-22: ReLU()-Softmax(dim=1)-NLLLoss(): 0.703 (0.838)\n",
      "-22: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.676 (0.676)\n",
      "-22: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.649 (0.703)\n",
      "-22: ReLU()-Identity()-CrossEntropyLoss(): 0.622 (0.730)\n",
      "-22: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.703 (0.865)\n",
      "-22: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.757 (0.892)\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-22: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.757 (0.838)\n",
      "-22: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-22: Identity()-Softmax(dim=1)-NLLLoss(): 0.730 (0.838)\n",
      "-22: Identity()-Identity()-CrossEntropyLoss(): 0.568 (0.811)\n",
      "-23: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-23: ReLU()-Softmax(dim=1)-NLLLoss(): 0.784 (0.892)\n",
      "-23: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.703 (0.757)\n",
      "-23: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.757 (0.784)\n",
      "-23: ReLU()-Identity()-CrossEntropyLoss(): 0.676 (0.703)\n",
      "-23: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.757 (0.892)\n",
      "-23: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.865)\n",
      "-23: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.811 (0.865)\n",
      "-23: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-23: Identity()-Softmax(dim=1)-NLLLoss(): 0.784 (0.919)\n",
      "-23: Identity()-Identity()-CrossEntropyLoss(): 0.676 (0.676)\n",
      "-24: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.514 (0.541)\n",
      "-24: ReLU()-Softmax(dim=1)-NLLLoss(): 0.703 (0.865)\n",
      "-24: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.622 (0.676)\n",
      "-24: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.676 (0.703)\n",
      "-24: ReLU()-Identity()-CrossEntropyLoss(): 0.730 (0.757)\n",
      "-24: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.892)\n",
      "-24: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.811 (0.919)\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.865)\n",
      "-24: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-24: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.730 (0.838)\n",
      "-24: Identity()-Softmax(dim=1)-NLLLoss(): 0.730 (0.811)\n",
      "-24: Identity()-Identity()-CrossEntropyLoss(): 0.514 (0.568)\n",
      "-25: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.703 (0.865)\n",
      "-25: ReLU()-Softmax(dim=1)-NLLLoss(): 0.811 (0.892)\n",
      "-25: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.811 (0.811)\n",
      "-25: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.730 (0.757)\n",
      "-25: ReLU()-Identity()-CrossEntropyLoss(): 0.622 (0.622)\n",
      "-25: ReLU()-Identity()-NLLLoss(): 0.405 (0.405)\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.811 (0.865)\n",
      "-25: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.784 (0.892)\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.892)\n",
      "-25: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.838 (0.865)\n",
      "-25: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.676 (0.892)\n",
      "-25: Identity()-Softmax(dim=1)-NLLLoss(): 0.730 (0.838)\n",
      "-25: Identity()-Identity()-CrossEntropyLoss(): 0.703 (0.703)\n",
      "----- 6.55 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},]\n",
    "\n",
    "best_accs4 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs4 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=exp['act'], last_act=exp['lact'],\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  K, masks, exp['loss'], device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs4[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs4[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}: {best_val_accs4[j,i]:.3f} ({best_accs4[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}' for exp in EXPS]\n",
    "table_over4 = summary_table(best_accs4, index_name)\n",
    "table4 = summary_table(best_val_accs4, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.789189</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.064413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.770811</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.039069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.709189</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.073434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.707027</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.072392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.691892</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.069644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-NLLLoss()</th>\n",
       "      <td>0.403243</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.007332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.765405</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.070362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.787027</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.042093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.775135</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.031258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.775135</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.040248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.751351</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.050128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.727568</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.066607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.665946</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.092330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean accs       med  \\\n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()             0.789189  0.783784   \n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                      0.770811  0.783784   \n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()          0.709189  0.702703   \n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                   0.707027  0.729730   \n",
       "ReLU()-Identity()-CrossEntropyLoss()                 0.691892  0.675676   \n",
       "ReLU()-Identity()-NLLLoss()                          0.403243  0.405405   \n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()     0.765405  0.783784   \n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()              0.787027  0.810811   \n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...   0.775135  0.783784   \n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...   0.775135  0.783784   \n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()         0.751351  0.756757   \n",
       "Identity()-Softmax(dim=1)-NLLLoss()                  0.727568  0.729730   \n",
       "Identity()-Identity()-CrossEntropyLoss()             0.665946  0.702703   \n",
       "\n",
       "                                                         std  \n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()            0.064413  \n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                     0.039069  \n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()         0.073434  \n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                  0.072392  \n",
       "ReLU()-Identity()-CrossEntropyLoss()                0.069644  \n",
       "ReLU()-Identity()-NLLLoss()                         0.007332  \n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()    0.070362  \n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()             0.042093  \n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...  0.031258  \n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...  0.040248  \n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()        0.050128  \n",
       "Identity()-Softmax(dim=1)-NLLLoss()                 0.066607  \n",
       "Identity()-Identity()-CrossEntropyLoss()            0.092330  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_over4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the GSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 3\n",
    "NORM = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 200-0.1-0.0005-0: 0.270 (0.270)\n",
      "-1: 200-0.05-0.0005-0: 0.270 (0.270)\n",
      "-1: 200-0.01-0.0005-0: 0.270 (0.270)\n",
      "-1: 200-0.005-0.0005-0: 0.270 (0.270)\n",
      "-1: 200-0.001-0.0005-0: 0.270 (0.270)\n",
      "-1: 200-0.05-0.001-0: 0.270 (0.270)\n",
      "-1: 200-0.01-0.001-0: 0.270 (0.270)\n",
      "-1: 200-0.05-0.01-0: 0.270 (0.270)\n",
      "-1: 200-0.01-0.01-0: 0.270 (0.270)\n",
      "-1: 200-0.05-0.05-0: 0.270 (0.270)\n",
      "-1: 200-0.01-0.05-0: 0.270 (0.270)\n",
      "-1: 200-0.05-0.0005-0.25: 0.270 (0.270)\n",
      "-1: 200-0.05-0.0005-0.5: 0.270 (0.270)\n",
      "-1: 500-0.05-0.01-0.25: 0.270 (0.270)\n",
      "-1: 500-0.05-0.01-0.5: 0.270 (0.270)\n",
      "-2: 200-0.1-0.0005-0: 0.270 (0.270)\n",
      "-2: 200-0.05-0.0005-0: 0.270 (0.270)\n",
      "-2: 200-0.01-0.0005-0: 0.270 (0.270)\n",
      "-2: 200-0.005-0.0005-0: 0.270 (0.270)\n",
      "-2: 200-0.001-0.0005-0: 0.270 (0.270)\n",
      "-2: 200-0.05-0.001-0: 0.270 (0.270)\n",
      "-2: 200-0.01-0.001-0: 0.270 (0.270)\n",
      "-2: 200-0.05-0.01-0: 0.270 (0.270)\n",
      "-2: 200-0.01-0.01-0: 0.270 (0.270)\n",
      "-2: 200-0.05-0.05-0: 0.270 (0.270)\n",
      "-2: 200-0.01-0.05-0: 0.270 (0.270)\n",
      "-2: 200-0.05-0.0005-0.25: 0.270 (0.270)\n",
      "-2: 200-0.05-0.0005-0.5: 0.270 (0.270)\n",
      "-2: 500-0.05-0.01-0.25: 0.270 (0.270)\n",
      "-2: 500-0.05-0.01-0.5: 0.270 (0.270)\n",
      "-3: 200-0.1-0.0005-0: 0.270 (0.270)\n",
      "-3: 200-0.05-0.0005-0: 0.270 (0.270)\n",
      "-3: 200-0.01-0.0005-0: 0.270 (0.270)\n",
      "-3: 200-0.005-0.0005-0: 0.270 (0.270)\n",
      "-3: 200-0.001-0.0005-0: 0.270 (0.270)\n",
      "-3: 200-0.05-0.001-0: 0.270 (0.270)\n",
      "-3: 200-0.01-0.001-0: 0.270 (0.270)\n",
      "-3: 200-0.05-0.01-0: 0.270 (0.270)\n",
      "-3: 200-0.01-0.01-0: 0.270 (0.270)\n",
      "-3: 200-0.05-0.05-0: 0.270 (0.270)\n",
      "-3: 200-0.01-0.05-0: 0.270 (0.270)\n",
      "-3: 200-0.05-0.0005-0.25: 0.270 (0.270)\n",
      "-3: 200-0.05-0.0005-0.5: 0.270 (0.270)\n",
      "-3: 500-0.05-0.01-0.25: 0.270 (0.270)\n",
      "-3: 500-0.05-0.01-0.5: 0.270 (0.270)\n",
      "----- 0.98 mins -----\n"
     ]
    }
   ],
   "source": [
    "EXPS = [{'epochs': 200, 'lr': .1, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .001, 'wd': 5e-4, 'drop': 0},\n",
    "        \n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-3, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 1e-3, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 1e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-2, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .01, 'wd': 5e-2, 'drop': 0},\n",
    "        \n",
    "        # {'epochs': 500, 'lr': .05, 'wd': 5e-4, 'drop': 0},\n",
    "        # {'epochs': 500, 'lr': .01, 'wd': 5e-4, 'drop': 0},\n",
    "        # {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': 0},\n",
    "        # {'epochs': 500, 'lr': .01, 'wd': 1e-2, 'drop': 0},\n",
    "\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4, 'drop': .25},\n",
    "        {'epochs': 200, 'lr': .05, 'wd': 5e-4, 'drop': .5},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .25},\n",
    "        {'epochs': 500, 'lr': .05, 'wd': 1e-2, 'drop': .5},\n",
    "        ]\n",
    "\n",
    "best_accs5 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs5 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=exp['drop'], init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'])\n",
    "\n",
    "        best_accs5[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs5[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}: {best_val_accs5[j,i]:.3f} ({best_accs5[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}' for exp in EXPS]\n",
    "table_over5 = summary_table(best_accs5, index_name)\n",
    "table5 = summary_table(best_val_accs5, index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.1-0.0005-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.0005-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.0005-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.001-0.0005-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.001-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.001-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.01-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.05-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.05-0</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0.25</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.0005-0.5</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.25</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.05-0.01-0.5</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean accs      med  std\n",
       "200-0.1-0.0005-0        0.27027  0.27027  0.0\n",
       "200-0.05-0.0005-0       0.27027  0.27027  0.0\n",
       "200-0.01-0.0005-0       0.27027  0.27027  0.0\n",
       "200-0.005-0.0005-0      0.27027  0.27027  0.0\n",
       "200-0.001-0.0005-0      0.27027  0.27027  0.0\n",
       "200-0.05-0.001-0        0.27027  0.27027  0.0\n",
       "200-0.01-0.001-0        0.27027  0.27027  0.0\n",
       "200-0.05-0.01-0         0.27027  0.27027  0.0\n",
       "200-0.01-0.01-0         0.27027  0.27027  0.0\n",
       "200-0.05-0.05-0         0.27027  0.27027  0.0\n",
       "200-0.01-0.05-0         0.27027  0.27027  0.0\n",
       "200-0.05-0.0005-0.25    0.27027  0.27027  0.0\n",
       "200-0.05-0.0005-0.5     0.27027  0.27027  0.0\n",
       "500-0.05-0.01-0.25      0.27027  0.27027  0.0\n",
       "500-0.05-0.01-0.5       0.27027  0.27027  0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 0.001-1-1-True: 0.270 (0.270)\n",
      "-1: 0.01-1-1-True: 0.270 (0.270)\n",
      "-1: 0.1-1-1-True: 0.270 (0.270)\n",
      "-1: 1-1-1-True: 0.270 (0.270)\n",
      "-1: 0.01-1-1-False: 0.270 (0.270)\n",
      "-1: 1-1-1-False: 0.270 (0.270)\n",
      "-1: 1-10-1-True: 0.270 (0.270)\n",
      "-1: 1-1-10-True: 0.270 (0.270)\n",
      "-1: 0.01-10-10-True: 0.270 (0.270)\n",
      "-1: 1-10-10-True: 0.270 (0.270)\n",
      "-1: 1-25-25-True: 0.270 (0.270)\n",
      "-1: 1-50-50-True: 0.270 (0.270)\n",
      "-2: 0.001-1-1-True: 0.270 (0.270)\n",
      "-2: 0.01-1-1-True: 0.270 (0.270)\n",
      "-2: 0.1-1-1-True: 0.270 (0.270)\n",
      "-2: 1-1-1-True: 0.270 (0.270)\n",
      "-2: 0.01-1-1-False: 0.270 (0.270)\n",
      "-2: 1-1-1-False: 0.270 (0.270)\n",
      "-2: 1-10-1-True: 0.270 (0.270)\n",
      "-2: 1-1-10-True: 0.270 (0.270)\n",
      "-2: 0.01-10-10-True: 0.270 (0.270)\n",
      "-2: 1-10-10-True: 0.270 (0.270)\n",
      "-2: 1-25-25-True: 0.270 (0.270)\n",
      "-2: 1-50-50-True: 0.270 (0.270)\n",
      "-3: 0.001-1-1-True: 0.270 (0.270)\n",
      "-3: 0.01-1-1-True: 0.270 (0.270)\n",
      "-3: 0.1-1-1-True: 0.270 (0.270)\n",
      "-3: 1-1-1-True: 0.270 (0.270)\n",
      "-3: 0.01-1-1-False: 0.270 (0.270)\n",
      "-3: 1-1-1-False: 0.270 (0.270)\n",
      "-3: 1-10-1-True: 0.270 (0.270)\n",
      "-3: 1-1-10-True: 0.270 (0.270)\n",
      "-3: 0.01-10-10-True: 0.270 (0.270)\n",
      "-3: 1-10-10-True: 0.270 (0.270)\n",
      "-3: 1-25-25-True: 0.270 (0.270)\n",
      "-3: 1-50-50-True: 0.270 (0.270)\n",
      "----- 3.11 mins -----\n"
     ]
    }
   ],
   "source": [
    "# h0, norm (norm, not norm, norm H), sep vs joint training, optimizers iters (W vs h)\n",
    "EXPS = [{'h0': .001, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': .1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},\n",
    "        \n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 1, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 1, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': .01, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 200, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        {'h0': 1, 'epochs': 50, 'epochs_h': 50, 'epochs_W': 50, 'alt': True},]\n",
    "\n",
    "\n",
    "best_accs6 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs6 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=exp['h0'])\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        if not exp['alt']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S,  K, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD, epochs_h=exp['epochs_h'],\n",
    "                                 epochs_W=exp['epochs_W'])\n",
    "\n",
    "        best_accs6[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs6[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}: {best_val_accs6[j,i]:.3f} ({best_accs6[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"h0\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}' for exp in EXPS]\n",
    "table_over6 = summary_table(best_accs6, index_name)\n",
    "table6 = summary_table(best_val_accs6, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.001-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.1-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-1-1-False</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-1-False</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-1-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-1-10-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-10-10-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-10-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-25-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50-1-50-50-True</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean accs      med  std\n",
       "200-0.001-1-1-True     0.27027  0.27027  0.0\n",
       "200-0.01-1-1-True      0.27027  0.27027  0.0\n",
       "200-0.1-1-1-True       0.27027  0.27027  0.0\n",
       "200-1-1-1-True         0.27027  0.27027  0.0\n",
       "200-0.01-1-1-False     0.27027  0.27027  0.0\n",
       "200-1-1-1-False        0.27027  0.27027  0.0\n",
       "200-1-10-1-True        0.27027  0.27027  0.0\n",
       "200-1-1-10-True        0.27027  0.27027  0.0\n",
       "200-0.01-10-10-True    0.27027  0.27027  0.0\n",
       "200-1-10-10-True       0.27027  0.27027  0.0\n",
       "200-1-25-25-True       0.27027  0.27027  0.0\n",
       "50-1-50-50-True        0.27027  0.27027  0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 2-2-16: 0.270 (0.270)\n",
      "-1: 2-3-16: 0.270 (0.270)\n",
      "-1: 2-4-16: 0.270 (0.270)\n",
      "-1: 3-2-16: 0.270 (0.270)\n",
      "-1: 4-2-16: 0.270 (0.270)\n",
      "-1: 3-3-16: 0.270 (0.270)\n",
      "-1: 4-3-16: 0.270 (0.270)\n",
      "-1: 2-2-8: 0.270 (0.270)\n",
      "-1: 2-2-32: 0.270 (0.270)\n",
      "-1: 2-2-50: 0.270 (0.270)\n",
      "-1: 2-3-8: 0.270 (0.270)\n",
      "-1: 2-3-32: 0.270 (0.270)\n",
      "-1: 2-3-50: 0.270 (0.270)\n",
      "-1: 3-2-8: 0.270 (0.270)\n",
      "-1: 3-2-32: 0.270 (0.270)\n",
      "-1: 3-2-50: 0.270 (0.270)\n",
      "-1: 3-3-8: 0.270 (0.270)\n",
      "-1: 3-3-32: 0.270 (0.270)\n",
      "-1: 3-3-50: 0.270 (0.270)\n",
      "-2: 2-2-16: 0.270 (0.270)\n",
      "-2: 2-3-16: 0.270 (0.270)\n",
      "-2: 2-4-16: 0.270 (0.270)\n",
      "-2: 3-2-16: 0.270 (0.270)\n",
      "-2: 4-2-16: 0.270 (0.270)\n",
      "-2: 3-3-16: 0.270 (0.270)\n",
      "-2: 4-3-16: 0.270 (0.270)\n",
      "-2: 2-2-8: 0.270 (0.270)\n",
      "-2: 2-2-32: 0.270 (0.270)\n",
      "-2: 2-2-50: 0.270 (0.270)\n",
      "-2: 2-3-8: 0.270 (0.270)\n",
      "-2: 2-3-32: 0.270 (0.270)\n",
      "-2: 2-3-50: 0.270 (0.270)\n",
      "-2: 3-2-8: 0.270 (0.270)\n",
      "-2: 3-2-32: 0.270 (0.270)\n",
      "-2: 3-2-50: 0.270 (0.270)\n",
      "-2: 3-3-8: 0.270 (0.270)\n",
      "-2: 3-3-32: 0.270 (0.270)\n",
      "-2: 3-3-50: 0.270 (0.270)\n",
      "-3: 2-2-16: 0.270 (0.270)\n",
      "-3: 2-3-16: 0.270 (0.270)\n",
      "-3: 2-4-16: 0.270 (0.270)\n",
      "-3: 3-2-16: 0.270 (0.270)\n",
      "-3: 4-2-16: 0.270 (0.270)\n",
      "-3: 3-3-16: 0.270 (0.270)\n",
      "-3: 4-3-16: 0.270 (0.270)\n",
      "-3: 2-2-8: 0.270 (0.270)\n",
      "-3: 2-2-32: 0.270 (0.270)\n",
      "-3: 2-2-50: 0.270 (0.270)\n",
      "-3: 2-3-8: 0.270 (0.270)\n",
      "-3: 2-3-32: 0.270 (0.270)\n",
      "-3: 2-3-50: 0.270 (0.270)\n",
      "-3: 3-2-8: 0.270 (0.270)\n",
      "-3: 3-2-32: 0.270 (0.270)\n",
      "-3: 3-2-50: 0.270 (0.270)\n",
      "-3: 3-3-8: 0.270 (0.270)\n",
      "-3: 3-3-32: 0.270 (0.270)\n",
      "-3: 3-3-50: 0.270 (0.270)\n",
      "----- 1.18 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'L': 2, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 4, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 3, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 50},\n",
    "\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 50},\n",
    "        ]\n",
    "\n",
    "best_accs7 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs7 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, exp['hid_dim'], OUT_DIM, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  exp['K'], masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs7[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs7[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}: {best_val_accs7[j,i]:.3f} ({best_accs7[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}' for exp in EXPS]\n",
    "table_over7 = summary_table(best_accs7, index_name)\n",
    "table7 = summary_table(best_val_accs7, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-2-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-4-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-3-16</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-8</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-32</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-50</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean accs      med  std\n",
       "2-2-16    0.27027  0.27027  0.0\n",
       "2-3-16    0.27027  0.27027  0.0\n",
       "2-4-16    0.27027  0.27027  0.0\n",
       "3-2-16    0.27027  0.27027  0.0\n",
       "4-2-16    0.27027  0.27027  0.0\n",
       "3-3-16    0.27027  0.27027  0.0\n",
       "4-3-16    0.27027  0.27027  0.0\n",
       "2-2-8     0.27027  0.27027  0.0\n",
       "2-2-32    0.27027  0.27027  0.0\n",
       "2-2-50    0.27027  0.27027  0.0\n",
       "2-3-8     0.27027  0.27027  0.0\n",
       "2-3-32    0.27027  0.27027  0.0\n",
       "2-3-50    0.27027  0.27027  0.0\n",
       "3-2-8     0.27027  0.27027  0.0\n",
       "3-2-32    0.27027  0.27027  0.0\n",
       "3-2-50    0.27027  0.27027  0.0\n",
       "3-3-8     0.27027  0.27027  0.0\n",
       "3-3-32    0.27027  0.27027  0.0\n",
       "3-3-50    0.27027  0.27027  0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearities and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-1: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-1: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-1: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-1: ReLU()-Identity()-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-1: ReLU()-Identity()-NLLLoss(): 0.270 (0.270)\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-1: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-1: Identity()-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-1: Identity()-Identity()-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-2: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-2: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-2: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-2: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-2: ReLU()-Identity()-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-2: ReLU()-Identity()-NLLLoss(): 0.270 (0.270)\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-2: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-2: Identity()-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-2: Identity()-Identity()-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-3: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-3: ReLU()-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-3: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-3: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-3: ReLU()-Identity()-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-3: ReLU()-Identity()-NLLLoss(): 0.270 (0.270)\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-3: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.270 (0.270)\n",
      "-3: Identity()-Softmax(dim=1)-NLLLoss(): 0.270 (0.270)\n",
      "-3: Identity()-Identity()-CrossEntropyLoss(): 0.270 (0.270)\n",
      "----- 0.74 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},]\n",
    "\n",
    "best_accs8 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs8 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=exp['act'], last_act=exp['lact'],\n",
    "                     dropout=DROPOUT, init_h0=h0)\n",
    "        if NORM:\n",
    "            S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "        else:\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  K, masks, exp['loss'], device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs8[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs8[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}: {best_val_accs8[j,i]:.3f} ({best_accs8[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}' for exp in EXPS]\n",
    "table_over8 = summary_table(best_accs8, index_name)\n",
    "table8 = summary_table(best_val_accs8, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.27027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean accs      med  std\n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()              0.27027  0.27027  0.0\n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                       0.27027  0.27027  0.0\n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()           0.27027  0.27027  0.0\n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                    0.27027  0.27027  0.0\n",
       "ReLU()-Identity()-CrossEntropyLoss()                  0.27027  0.27027  0.0\n",
       "ReLU()-Identity()-NLLLoss()                           0.27027  0.27027  0.0\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()      0.27027  0.27027  0.0\n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()               0.27027  0.27027  0.0\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...    0.27027  0.27027  0.0\n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...    0.27027  0.27027  0.0\n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()          0.27027  0.27027  0.0\n",
       "Identity()-Softmax(dim=1)-NLLLoss()                   0.27027  0.27027  0.0\n",
       "Identity()-Identity()-CrossEntropyLoss()              0.27027  0.27027  0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPS = [\n",
    "        {'name': 'Kipf', 'norm': 'none'},\n",
    "        {'name': 'Kipf', 'norm': 'both'},\n",
    "\n",
    "        {'name': 'A-GCNN', 'norm': False},\n",
    "        {'name': 'A-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'H-GCNN', 'norm': False}, # This should be the same as A-GCNN not norm\n",
    "        {'name': 'H-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'W-GCN-A', 'norm': False},\n",
    "        {'name': 'W-GCN-A', 'norm': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RUN: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.568  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.784  -  acc (over) = 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:43: RuntimeWarning: divide by zero encountered in divide\n",
      "  D_inv = np.diag(1/S.sum(1))\n",
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:51: RuntimeWarning: invalid value encountered in matmul\n",
      "  return D_inv_sqr @ S @ D_inv_sqr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.811  -  acc (over) = 0.865\n",
      "\tH-GCNN-True: acc = 0.541  -  acc (over) = 0.568\n",
      "\tW-GCN-A-False: acc = 0.568  -  acc (over) = 0.649\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 2\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.432\n",
      "\tKipf-both: acc = 0.541  -  acc (over) = 0.649\n",
      "\tA-GCNN-False: acc = 0.784  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.811  -  acc (over) = 0.892\n",
      "\tH-GCNN-True: acc = 0.703  -  acc (over) = 0.838\n",
      "\tW-GCN-A-False: acc = 0.595  -  acc (over) = 0.622\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 3\n",
      "\tKipf-none: acc = 0.378  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.568  -  acc (over) = 0.568\n",
      "\tA-GCNN-False: acc = 0.784  -  acc (over) = 0.892\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.757  -  acc (over) = 0.892\n",
      "\tH-GCNN-True: acc = 0.703  -  acc (over) = 0.730\n",
      "\tW-GCN-A-False: acc = 0.568  -  acc (over) = 0.568\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 4\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.514  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.784  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.838  -  acc (over) = 0.865\n",
      "\tH-GCNN-True: acc = 0.676  -  acc (over) = 0.757\n",
      "\tW-GCN-A-False: acc = 0.514  -  acc (over) = 0.568\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 5\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.568  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.811  -  acc (over) = 0.838\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.730  -  acc (over) = 0.838\n",
      "\tH-GCNN-True: acc = 0.595  -  acc (over) = 0.622\n",
      "\tW-GCN-A-False: acc = 0.649  -  acc (over) = 0.676\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 6\n",
      "\tKipf-none: acc = 0.432  -  acc (over) = 0.514\n",
      "\tKipf-both: acc = 0.514  -  acc (over) = 0.649\n",
      "\tA-GCNN-False: acc = 0.649  -  acc (over) = 0.838\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.811  -  acc (over) = 0.838\n",
      "\tH-GCNN-True: acc = 0.324  -  acc (over) = 0.459\n",
      "\tW-GCN-A-False: acc = 0.541  -  acc (over) = 0.622\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 7\n",
      "\tKipf-none: acc = 0.378  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.514  -  acc (over) = 0.649\n",
      "\tA-GCNN-False: acc = 0.784  -  acc (over) = 0.892\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.784  -  acc (over) = 0.892\n",
      "\tH-GCNN-True: acc = 0.486  -  acc (over) = 0.622\n",
      "\tW-GCN-A-False: acc = 0.595  -  acc (over) = 0.595\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 8\n",
      "\tKipf-none: acc = 0.378  -  acc (over) = 0.432\n",
      "\tKipf-both: acc = 0.514  -  acc (over) = 0.595\n",
      "\tA-GCNN-False: acc = 0.811  -  acc (over) = 0.892\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.784  -  acc (over) = 0.865\n",
      "\tH-GCNN-True: acc = 0.649  -  acc (over) = 0.676\n",
      "\tW-GCN-A-False: acc = 0.703  -  acc (over) = 0.703\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 9\n",
      "\tKipf-none: acc = 0.432  -  acc (over) = 0.432\n",
      "\tKipf-both: acc = 0.595  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.784  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.811  -  acc (over) = 0.865\n",
      "\tH-GCNN-True: acc = 0.784  -  acc (over) = 0.811\n",
      "\tW-GCN-A-False: acc = 0.541  -  acc (over) = 0.595\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 10\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.432\n",
      "\tKipf-both: acc = 0.595  -  acc (over) = 0.649\n",
      "\tA-GCNN-False: acc = 0.730  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.784  -  acc (over) = 0.865\n",
      "\tH-GCNN-True: acc = 0.486  -  acc (over) = 0.514\n",
      "\tW-GCN-A-False: acc = 0.541  -  acc (over) = 0.595\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 11\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.622  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.784  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.703  -  acc (over) = 0.865\n",
      "\tH-GCNN-True: acc = 0.703  -  acc (over) = 0.757\n",
      "\tW-GCN-A-False: acc = 0.568  -  acc (over) = 0.649\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 12\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.541  -  acc (over) = 0.649\n",
      "\tA-GCNN-False: acc = 0.757  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.649  -  acc (over) = 0.838\n",
      "\tH-GCNN-True: acc = 0.730  -  acc (over) = 0.865\n",
      "\tW-GCN-A-False: acc = 0.541  -  acc (over) = 0.595\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 13\n",
      "\tKipf-none: acc = 0.378  -  acc (over) = 0.541\n",
      "\tKipf-both: acc = 0.595  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.865  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.865  -  acc (over) = 0.892\n",
      "\tH-GCNN-True: acc = 0.703  -  acc (over) = 0.838\n",
      "\tW-GCN-A-False: acc = 0.649  -  acc (over) = 0.649\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 14\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.432\n",
      "\tKipf-both: acc = 0.514  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.784  -  acc (over) = 0.892\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.757  -  acc (over) = 0.838\n",
      "\tH-GCNN-True: acc = 0.541  -  acc (over) = 0.595\n",
      "\tW-GCN-A-False: acc = 0.568  -  acc (over) = 0.649\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 15\n",
      "\tKipf-none: acc = 0.486  -  acc (over) = 0.486\n",
      "\tKipf-both: acc = 0.541  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.838  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.730  -  acc (over) = 0.865\n",
      "\tH-GCNN-True: acc = 0.676  -  acc (over) = 0.784\n",
      "\tW-GCN-A-False: acc = 0.595  -  acc (over) = 0.595\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 16\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.514\n",
      "\tKipf-both: acc = 0.622  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.730  -  acc (over) = 0.838\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.676  -  acc (over) = 0.892\n",
      "\tH-GCNN-True: acc = 0.757  -  acc (over) = 0.757\n",
      "\tW-GCN-A-False: acc = 0.541  -  acc (over) = 0.595\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 17\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.405  -  acc (over) = 0.568\n",
      "\tA-GCNN-False: acc = 0.703  -  acc (over) = 0.838\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.811  -  acc (over) = 0.892\n",
      "\tH-GCNN-True: acc = 0.730  -  acc (over) = 0.811\n",
      "\tW-GCN-A-False: acc = 0.568  -  acc (over) = 0.595\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 18\n",
      "\tKipf-none: acc = 0.514  -  acc (over) = 0.514\n",
      "\tKipf-both: acc = 0.568  -  acc (over) = 0.595\n",
      "\tA-GCNN-False: acc = 0.811  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.757  -  acc (over) = 0.838\n",
      "\tH-GCNN-True: acc = 0.595  -  acc (over) = 0.595\n",
      "\tW-GCN-A-False: acc = 0.568  -  acc (over) = 0.622\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 19\n",
      "\tKipf-none: acc = 0.432  -  acc (over) = 0.432\n",
      "\tKipf-both: acc = 0.541  -  acc (over) = 0.649\n",
      "\tA-GCNN-False: acc = 0.757  -  acc (over) = 0.892\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.730  -  acc (over) = 0.838\n",
      "\tH-GCNN-True: acc = 0.784  -  acc (over) = 0.784\n",
      "\tW-GCN-A-False: acc = 0.514  -  acc (over) = 0.595\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 20\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.541  -  acc (over) = 0.649\n",
      "\tA-GCNN-False: acc = 0.784  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.730  -  acc (over) = 0.838\n",
      "\tH-GCNN-True: acc = 0.514  -  acc (over) = 0.622\n",
      "\tW-GCN-A-False: acc = 0.622  -  acc (over) = 0.649\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 21\n",
      "\tKipf-none: acc = 0.405  -  acc (over) = 0.405\n",
      "\tKipf-both: acc = 0.568  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.811  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.730  -  acc (over) = 0.865\n",
      "\tH-GCNN-True: acc = 0.568  -  acc (over) = 0.703\n",
      "\tW-GCN-A-False: acc = 0.541  -  acc (over) = 0.622\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 22\n",
      "\tKipf-none: acc = 0.432  -  acc (over) = 0.514\n",
      "\tKipf-both: acc = 0.541  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.757  -  acc (over) = 0.865\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.811  -  acc (over) = 0.838\n",
      "\tH-GCNN-True: acc = 0.784  -  acc (over) = 0.784\n",
      "\tW-GCN-A-False: acc = 0.514  -  acc (over) = 0.622\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 23\n",
      "\tKipf-none: acc = 0.378  -  acc (over) = 0.432\n",
      "\tKipf-both: acc = 0.514  -  acc (over) = 0.595\n",
      "\tA-GCNN-False: acc = 0.757  -  acc (over) = 0.838\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.486  -  acc (over) = 0.595\n",
      "\tH-GCNN-True: acc = 0.568  -  acc (over) = 0.622\n",
      "\tW-GCN-A-False: acc = 0.486  -  acc (over) = 0.649\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 24\n",
      "\tKipf-none: acc = 0.432  -  acc (over) = 0.432\n",
      "\tKipf-both: acc = 0.514  -  acc (over) = 0.622\n",
      "\tA-GCNN-False: acc = 0.703  -  acc (over) = 0.811\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.757  -  acc (over) = 0.892\n",
      "\tH-GCNN-True: acc = 0.649  -  acc (over) = 0.649\n",
      "\tW-GCN-A-False: acc = 0.541  -  acc (over) = 0.622\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n",
      "- RUN: 25\n",
      "\tKipf-none: acc = 0.432  -  acc (over) = 0.459\n",
      "\tKipf-both: acc = 0.568  -  acc (over) = 0.649\n",
      "\tA-GCNN-False: acc = 0.757  -  acc (over) = 0.892\n",
      "\tA-GCNN-True: acc = 0.270  -  acc (over) = 0.270\n",
      "\tH-GCNN-False: acc = 0.811  -  acc (over) = 0.892\n",
      "\tH-GCNN-True: acc = 0.595  -  acc (over) = 0.595\n",
      "\tW-GCN-A-False: acc = 0.595  -  acc (over) = 0.595\n",
      "\tW-GCN-A-True: acc = 0.270  -  acc (over) = 0.270\n"
     ]
    }
   ],
   "source": [
    "N_RUNS = 25\n",
    "\n",
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "for i in range(N_RUNS):\n",
    "    print(f'- RUN: {i+1}')\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        # t_i = time.time()\n",
    "        if exp['name'] == 'Kipf':\n",
    "            arch = GCNN_2L(IN_DIM, HID_DIM, OUT_DIM, act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=exp['norm'])\n",
    "            S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "            \n",
    "        elif exp['name'] == 'A-GCNN':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "            dropout=DROPOUT, diff_layer=GFGCNLayer, init_h0=h0)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'H-GCNN':\n",
    "            arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=DROPOUT, norm=exp['norm'], dev=device)\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'W-GCN-A':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=DROPOUT, diff_layer=GFGCN_noh_Layer)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)  \n",
    "            \n",
    "        else:\n",
    "            raise Exception(f'ERROR: Unknown architecture: {exp[\"name\"]}')\n",
    "\n",
    "        if exp['name'] in ['Kipf', 'W-GCN-A']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "\n",
    "        loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'\\t{exp[\"name\"]}-{exp[\"norm\"]}: acc = {best_val_accs[j,i]:.3f}  -  acc (over) = {best_accs[j,i]:.3f}')\n",
    "\n",
    "\n",
    "# Print results\n",
    "index_name = [f'{exp[\"name\"]}-{exp[\"norm\"]}' for exp in EXPS]\n",
    "table_comp_over = summary_table(best_accs, index_name)\n",
    "table_comp = summary_table(best_val_accs, index_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kipf-none</th>\n",
       "      <td>0.414054</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.031258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kipf-both</th>\n",
       "      <td>0.547027</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.044100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-False</th>\n",
       "      <td>0.771892</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.044627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-False</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.074508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-True</th>\n",
       "      <td>0.633514</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.111062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-False</th>\n",
       "      <td>0.568649</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.048032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean accs       med       std\n",
       "Kipf-none       0.414054  0.405405  0.031258\n",
       "Kipf-both       0.547027  0.540541  0.044100\n",
       "A-GCNN-False    0.771892  0.783784  0.044627\n",
       "A-GCNN-True     0.270270  0.270270  0.000000\n",
       "H-GCNN-False    0.756757  0.756757  0.074508\n",
       "H-GCNN-True     0.633514  0.648649  0.111062\n",
       "W-GCN-A-False   0.568649  0.567568  0.048032\n",
       "W-GCN-A-True    0.270270  0.270270  0.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kipf-none</th>\n",
       "      <td>0.442162</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.043162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kipf-both</th>\n",
       "      <td>0.622703</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.023537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-False</th>\n",
       "      <td>0.863784</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.020907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-False</th>\n",
       "      <td>0.854054</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.057205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-True</th>\n",
       "      <td>0.694054</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.108032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-False</th>\n",
       "      <td>0.619459</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.032360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-True</th>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean accs       med       std\n",
       "Kipf-none       0.442162  0.432432  0.043162\n",
       "Kipf-both       0.622703  0.621622  0.023537\n",
       "A-GCNN-False    0.863784  0.864865  0.020907\n",
       "A-GCNN-True     0.270270  0.270270  0.000000\n",
       "H-GCNN-False    0.854054  0.864865  0.057205\n",
       "H-GCNN-True     0.694054  0.702703  0.108032\n",
       "W-GCN-A-False   0.619459  0.621622  0.032360\n",
       "W-GCN-A-True    0.270270  0.270270  0.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_comp_over"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

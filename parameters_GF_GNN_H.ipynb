{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efc9ea52870>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import utils\n",
    "from gsp_utils.baselines_archs import GCNN_2L\n",
    "from gsp_utils.baselines_models import NodeClassModel, GF_NodeClassModel\n",
    "from gsp_utils.data import normalize_gso\n",
    "from src.arch import GFGCN, GFGCNLayer, GFGCN_noh_Layer, GFGCN_Spows\n",
    "\n",
    "SEED = 15\n",
    "# PATH = 'results/diff_filters/'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def summary_table(acc, index_name):\n",
    "    mean_accs = acc.mean(axis=1)\n",
    "    med_accs = np.median(acc, axis=1)\n",
    "    std_accs = acc.std(axis=1)\n",
    "    return DataFrame(np.vstack((mean_accs, med_accs, std_accs)).T, columns=['mean accs', 'med', 'std'], index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def compute_S_pows(S, K, device):\n",
    "    N = S.shape[0]\n",
    "    S_pows = torch.Tensor(torch.empty(K-1, N, N)).to(device)\n",
    "    S_pows[0,:,:] = torch.Tensor(S).to(device)\n",
    "    for k in range(1,K-1):\n",
    "        S_pows[k,:,:] = S_pows[0,:,:] @ S_pows[k-1,:,:]\n",
    "\n",
    "    return S_pows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: WisconsinDataset\n",
      "Number of nodes: 251\n",
      "Number of features: 1703\n",
      "Shape of signals: torch.Size([251, 1703])\n",
      "Number of classes: 5\n",
      "Norm of A: 22.69361114501953\n",
      "Max value of A: 1.0\n",
      "Proportion of validation data: 0.32\n",
      "Proportion of test data: 0.20\n",
      "Node homophily: 0.13\n",
      "Edge homophily: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Dataset must be from DGL\n",
    "dataset_name = 'WisconsinDataset'\n",
    "\n",
    "A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device,\n",
    "                                                     verb=True)\n",
    "N = A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PARAMETERS\n",
    "## Reaining params\n",
    "N_RUNS = 10\n",
    "N_EPOCHS = 200  # 5000\n",
    "EPOCHS_h = 5 # 5 # 5\n",
    "EPOCHS_W = 25 # 5 # 25\n",
    "LR = .005\n",
    "WD = 1e-4  # .001\n",
    "DROPOUT = .25\n",
    "\n",
    "# BEST PARAMETERS\n",
    "## Architecture params\n",
    "N_LAYERS = 3\n",
    "K = 2\n",
    "HID_DIM = 32 # 100\n",
    "\n",
    "## Model params\n",
    "NORM = True\n",
    "\n",
    "IN_DIM = feat.shape[1]\n",
    "OUT_DIM = n_class\n",
    "\n",
    "ACT = nn.ELU()  # nn.ELU()\n",
    "LAST_ACT = nn.Softmax()\n",
    "LOSS_FN = nn.CrossEntropyLoss()  # nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting eval/test acc/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/src/arch.py:190: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.last_act(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc at best val: 0.804  -  Best test acc: 0.863\n",
      "Test acc (based on loss): 0.804\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "epochs = N_EPOCHS\n",
    "epochs_h = EPOCHS_h\n",
    "epochs_W = EPOCHS_W\n",
    "lr = LR\n",
    "wd = WD\n",
    "drop = DROPOUT\n",
    "L = N_LAYERS\n",
    "K_aux = K\n",
    "hid_dim = HID_DIM\n",
    "norm = True\n",
    "act = ACT\n",
    "lact = LAST_ACT\n",
    "loss_fn = LOSS_FN\n",
    "bias = True\n",
    "patience = 200\n",
    "\n",
    "iters_aux = 1\n",
    "\n",
    "err1 = np.zeros(iters_aux)\n",
    "err2 = np.zeros(iters_aux)\n",
    "for i in range(iters_aux):\n",
    "    A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device, idx=i%10)\n",
    "\n",
    "    arch = GFGCN_Spows(IN_DIM, hid_dim, OUT_DIM, L, K_aux, act=act, last_act=lact,\n",
    "                dropout=drop, norm=norm, bias=bias, dev=device)\n",
    "    S = torch.Tensor(A).to(device)\n",
    "    model = GF_NodeClassModel(arch, S, K_aux, masks, loss_fn, device=device)\n",
    "    loss, acc = model.train(feat, labels, epochs, lr, wd, epochs_h=epochs_h, epochs_W=epochs_W,\n",
    "                            patience=patience)\n",
    "\n",
    "    idx_max_acc = np.argmax(acc[\"val\"])\n",
    "    print(f'Test acc at best val: {acc[\"test\"][idx_max_acc]:.3f}  -  Best test acc: {np.max(acc[\"test\"]):.3f}')\n",
    "    acc_val = model.test(feat, model.S, labels, masks['val'])\n",
    "    acc_test = model.test(feat, model.S, labels, masks['test'])\n",
    "    print(f'Test acc (based on loss): {acc_test:.3f}')\n",
    "\n",
    "    err1[i] = acc[\"test\"][idx_max_acc]\n",
    "    err2[i] = acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc at best val acc: 0.804 +- 0.000\n",
      "Acc at test: 0.804 +- 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efbcf63abe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Acc at best val acc: {err1.mean():.3f} +- {err1.std():.3f}')\n",
    "print(f'Acc at test: {err2.mean():.3f} +- {err1.std():.3f}')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=[6,4])\n",
    "plt.plot(acc['train'], 'b-', label='Acc train')\n",
    "plt.plot(acc['val'], 'g-', label='Acc val')\n",
    "plt.plot(acc['test'], 'r-', label='Acc test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=[6,4])\n",
    "plt.plot(loss['train'], 'b-', label='Loss train')\n",
    "plt.plot(loss['val'], 'g-', label='Loss val')\n",
    "plt.plot(loss['test'], 'r-', label='Loss test')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 200-0.005-0.0001-0.25: 0.804 (0.863)\n",
      "-1: 200-0.005-0.0005-0.25: 0.843 (0.863)\n",
      "-1: 200-0.01-0.001-0.25: 0.824 (0.863)\n",
      "-1: 200-0.005-0.001-0.25: 0.784 (0.902)\n",
      "-1: 200-0.005-0.001-0.5: 0.843 (0.902)\n",
      "-1: 200-0.001-0.001-0.25: 0.765 (0.824)\n",
      "-1: 200-0.05-0.005-0.25: 0.784 (0.882)\n",
      "-1: 200-0.01-0.005-0.25: 0.804 (0.824)\n",
      "-1: 200-0.005-0.005-0.25: 0.843 (0.843)\n",
      "-1: 200-0.001-0.005-0.25: 0.804 (0.843)\n",
      "-1: 200-0.05-0.01-0.25: 0.725 (0.824)\n",
      "-1: 200-0.005-0.01-0.25: 0.745 (0.882)\n",
      "-1: 200-0.05-0.01-0.5: 0.824 (0.843)\n",
      "-1: 200-0.05-0.005-0.5: 0.784 (0.784)\n",
      "-1: 200-0.01-0.005-0.5: 0.863 (0.863)\n",
      "-1: 200-0.05-0.01-0: 0.804 (0.824)\n",
      "-1: 200-0.05-0.005-0: 0.824 (0.843)\n",
      "-1: 200-0.01-0.005-0: 0.804 (0.843)\n",
      "-1: 500-0.005-0.001-0.5: 0.765 (0.882)\n",
      "-2: 200-0.005-0.0001-0.25: 0.765 (0.941)\n",
      "-2: 200-0.005-0.0005-0.25: 0.843 (0.941)\n",
      "-2: 200-0.01-0.001-0.25: 0.843 (0.922)\n",
      "-2: 200-0.005-0.001-0.25: 0.902 (0.922)\n",
      "-2: 200-0.005-0.001-0.5: 0.843 (0.922)\n",
      "-2: 200-0.001-0.001-0.25: 0.863 (0.922)\n",
      "-2: 200-0.05-0.005-0.25: 0.863 (0.902)\n",
      "-2: 200-0.01-0.005-0.25: 0.765 (0.941)\n",
      "-2: 200-0.005-0.005-0.25: 0.843 (0.922)\n",
      "-2: 200-0.001-0.005-0.25: 0.882 (0.941)\n",
      "-2: 200-0.05-0.01-0.25: 0.725 (0.765)\n",
      "-2: 200-0.005-0.01-0.25: 0.882 (0.922)\n",
      "-2: 200-0.05-0.01-0.5: 0.863 (0.863)\n",
      "-2: 200-0.05-0.005-0.5: 0.843 (0.922)\n",
      "-2: 200-0.01-0.005-0.5: 0.863 (0.922)\n",
      "-2: 200-0.05-0.01-0: 0.765 (0.882)\n",
      "-2: 200-0.05-0.005-0: 0.725 (0.804)\n",
      "-2: 200-0.01-0.005-0: 0.922 (0.922)\n",
      "-2: 500-0.005-0.001-0.5: 0.922 (0.922)\n",
      "-3: 200-0.005-0.0001-0.25: 0.824 (0.941)\n",
      "-3: 200-0.005-0.0005-0.25: 0.882 (0.922)\n",
      "-3: 200-0.01-0.001-0.25: 0.863 (0.941)\n",
      "-3: 200-0.005-0.001-0.25: 0.843 (0.922)\n",
      "-3: 200-0.005-0.001-0.5: 0.902 (0.922)\n",
      "-3: 200-0.001-0.001-0.25: 0.882 (0.902)\n",
      "-3: 200-0.05-0.005-0.25: 0.824 (0.902)\n",
      "-3: 200-0.01-0.005-0.25: 0.902 (0.902)\n",
      "-3: 200-0.005-0.005-0.25: 0.902 (0.922)\n",
      "-3: 200-0.001-0.005-0.25: 0.863 (0.882)\n",
      "-3: 200-0.05-0.01-0.25: 0.882 (0.882)\n",
      "-3: 200-0.005-0.01-0.25: 0.863 (0.902)\n",
      "-3: 200-0.05-0.01-0.5: 0.824 (0.843)\n",
      "-3: 200-0.05-0.005-0.5: 0.608 (0.686)\n",
      "-3: 200-0.01-0.005-0.5: 0.882 (0.902)\n",
      "-3: 200-0.05-0.01-0: 0.843 (0.863)\n",
      "-3: 200-0.05-0.005-0: 0.824 (0.843)\n",
      "-3: 200-0.01-0.005-0: 0.824 (0.863)\n",
      "-3: 500-0.005-0.001-0.5: 0.863 (0.922)\n",
      "-4: 200-0.005-0.0001-0.25: 0.882 (0.961)\n",
      "-4: 200-0.005-0.0005-0.25: 0.882 (0.980)\n",
      "-4: 200-0.01-0.001-0.25: 0.706 (0.922)\n",
      "-4: 200-0.005-0.001-0.25: 0.922 (0.941)\n",
      "-4: 200-0.005-0.001-0.5: 0.882 (0.941)\n",
      "-4: 200-0.001-0.001-0.25: 0.843 (0.902)\n",
      "-4: 200-0.05-0.005-0.25: 0.843 (0.882)\n",
      "-4: 200-0.01-0.005-0.25: 0.843 (0.882)\n",
      "-4: 200-0.005-0.005-0.25: 0.863 (0.922)\n",
      "-4: 200-0.001-0.005-0.25: 0.824 (0.882)\n",
      "-4: 200-0.05-0.01-0.25: 0.824 (0.863)\n",
      "-4: 200-0.005-0.01-0.25: 0.765 (0.863)\n",
      "-4: 200-0.05-0.01-0.5: 0.804 (0.863)\n",
      "-4: 200-0.05-0.005-0.5: 0.706 (0.843)\n",
      "-4: 200-0.01-0.005-0.5: 0.863 (0.902)\n",
      "-4: 200-0.05-0.01-0: 0.824 (0.882)\n",
      "-4: 200-0.05-0.005-0: 0.745 (0.804)\n",
      "-4: 200-0.01-0.005-0: 0.843 (0.843)\n",
      "-4: 500-0.005-0.001-0.5: 0.863 (0.941)\n",
      "-5: 200-0.005-0.0001-0.25: 0.922 (0.941)\n",
      "-5: 200-0.005-0.0005-0.25: 0.882 (0.922)\n",
      "-5: 200-0.01-0.001-0.25: 0.863 (0.922)\n",
      "-5: 200-0.005-0.001-0.25: 0.804 (0.941)\n",
      "-5: 200-0.005-0.001-0.5: 0.843 (0.902)\n",
      "-5: 200-0.001-0.001-0.25: 0.784 (0.902)\n",
      "-5: 200-0.05-0.005-0.25: 0.412 (0.588)\n",
      "-5: 200-0.01-0.005-0.25: 0.824 (0.922)\n",
      "-5: 200-0.005-0.005-0.25: 0.843 (0.922)\n",
      "-5: 200-0.001-0.005-0.25: 0.804 (0.863)\n",
      "-5: 200-0.05-0.01-0.25: 0.765 (0.824)\n",
      "-5: 200-0.005-0.01-0.25: 0.765 (0.882)\n",
      "-5: 200-0.05-0.01-0.5: 0.804 (0.804)\n",
      "-5: 200-0.05-0.005-0.5: 0.549 (0.608)\n",
      "-5: 200-0.01-0.005-0.5: 0.902 (0.922)\n",
      "-5: 200-0.05-0.01-0: 0.667 (0.784)\n",
      "-5: 200-0.05-0.005-0: 0.804 (0.824)\n",
      "-5: 200-0.01-0.005-0: 0.843 (0.863)\n",
      "-5: 500-0.005-0.001-0.5: 0.902 (0.922)\n",
      "-6: 200-0.005-0.0001-0.25: 0.863 (0.902)\n",
      "-6: 200-0.005-0.0005-0.25: 0.843 (0.902)\n",
      "-6: 200-0.01-0.001-0.25: 0.804 (0.863)\n",
      "-6: 200-0.005-0.001-0.25: 0.824 (0.902)\n",
      "-6: 200-0.005-0.001-0.5: 0.863 (0.902)\n",
      "-6: 200-0.001-0.001-0.25: 0.784 (0.863)\n",
      "-6: 200-0.05-0.005-0.25: 0.804 (0.863)\n",
      "-6: 200-0.01-0.005-0.25: 0.843 (0.843)\n",
      "-6: 200-0.005-0.005-0.25: 0.745 (0.882)\n",
      "-6: 200-0.001-0.005-0.25: 0.745 (0.843)\n",
      "-6: 200-0.05-0.01-0.25: 0.765 (0.804)\n",
      "-6: 200-0.005-0.01-0.25: 0.804 (0.902)\n",
      "-6: 200-0.05-0.01-0.5: 0.569 (0.686)\n",
      "-6: 200-0.05-0.005-0.5: 0.784 (0.804)\n",
      "-6: 200-0.01-0.005-0.5: 0.765 (0.824)\n",
      "-6: 200-0.05-0.01-0: 0.765 (0.804)\n",
      "-6: 200-0.05-0.005-0: 0.569 (0.725)\n",
      "-6: 200-0.01-0.005-0: 0.863 (0.882)\n",
      "-6: 500-0.005-0.001-0.5: 0.882 (0.902)\n",
      "-7: 200-0.005-0.0001-0.25: 0.882 (0.941)\n",
      "-7: 200-0.005-0.0005-0.25: 0.882 (0.922)\n",
      "-7: 200-0.01-0.001-0.25: 0.863 (0.922)\n",
      "-7: 200-0.005-0.001-0.25: 0.863 (0.902)\n",
      "-7: 200-0.005-0.001-0.5: 0.843 (0.922)\n",
      "-7: 200-0.001-0.001-0.25: 0.863 (0.882)\n",
      "-7: 200-0.05-0.005-0.25: 0.863 (0.902)\n",
      "-7: 200-0.01-0.005-0.25: 0.863 (0.902)\n",
      "-7: 200-0.005-0.005-0.25: 0.843 (0.882)\n",
      "-7: 200-0.001-0.005-0.25: 0.824 (0.863)\n",
      "-7: 200-0.05-0.01-0.25: 0.804 (0.882)\n",
      "-7: 200-0.005-0.01-0.25: 0.824 (0.863)\n",
      "-7: 200-0.05-0.01-0.5: 0.882 (0.882)\n",
      "-7: 200-0.05-0.005-0.5: 0.882 (0.882)\n",
      "-7: 200-0.01-0.005-0.5: 0.863 (0.902)\n",
      "-7: 200-0.05-0.01-0: 0.745 (0.745)\n",
      "-7: 200-0.05-0.005-0: 0.549 (0.706)\n",
      "-7: 200-0.01-0.005-0: 0.824 (0.863)\n",
      "-7: 500-0.005-0.001-0.5: 0.843 (0.902)\n",
      "-8: 200-0.005-0.0001-0.25: 0.882 (0.922)\n",
      "-8: 200-0.005-0.0005-0.25: 0.863 (0.902)\n",
      "-8: 200-0.01-0.001-0.25: 0.824 (0.902)\n",
      "-8: 200-0.005-0.001-0.25: 0.863 (0.902)\n",
      "-8: 200-0.005-0.001-0.5: 0.804 (0.902)\n",
      "-8: 200-0.001-0.001-0.25: 0.765 (0.824)\n",
      "-8: 200-0.05-0.005-0.25: 0.686 (0.784)\n",
      "-8: 200-0.01-0.005-0.25: 0.824 (0.882)\n",
      "-8: 200-0.005-0.005-0.25: 0.804 (0.863)\n",
      "-8: 200-0.001-0.005-0.25: 0.824 (0.824)\n",
      "-8: 200-0.05-0.01-0.25: 0.686 (0.725)\n",
      "-8: 200-0.005-0.01-0.25: 0.804 (0.824)\n",
      "-8: 200-0.05-0.01-0.5: 0.784 (0.843)\n",
      "-8: 200-0.05-0.005-0.5: 0.647 (0.725)\n",
      "-8: 200-0.01-0.005-0.5: 0.706 (0.824)\n",
      "-8: 200-0.05-0.01-0: 0.824 (0.824)\n",
      "-8: 200-0.05-0.005-0: 0.725 (0.765)\n",
      "-8: 200-0.01-0.005-0: 0.843 (0.843)\n",
      "-8: 500-0.005-0.001-0.5: 0.824 (0.863)\n",
      "-9: 200-0.005-0.0001-0.25: 0.843 (0.882)\n",
      "-9: 200-0.005-0.0005-0.25: 0.824 (0.902)\n",
      "-9: 200-0.01-0.001-0.25: 0.745 (0.843)\n",
      "-9: 200-0.005-0.001-0.25: 0.824 (0.863)\n",
      "-9: 200-0.005-0.001-0.5: 0.824 (0.863)\n",
      "-9: 200-0.001-0.001-0.25: 0.784 (0.863)\n",
      "-9: 200-0.05-0.005-0.25: 0.804 (0.804)\n",
      "-9: 200-0.01-0.005-0.25: 0.784 (0.824)\n",
      "-9: 200-0.005-0.005-0.25: 0.843 (0.863)\n",
      "-9: 200-0.001-0.005-0.25: 0.843 (0.843)\n",
      "-9: 200-0.05-0.01-0.25: 0.725 (0.804)\n",
      "-9: 200-0.005-0.01-0.25: 0.765 (0.804)\n",
      "-9: 200-0.05-0.01-0.5: 0.706 (0.706)\n",
      "-9: 200-0.05-0.005-0.5: 0.843 (0.843)\n",
      "-9: 200-0.01-0.005-0.5: 0.804 (0.863)\n",
      "-9: 200-0.05-0.01-0: 0.706 (0.706)\n",
      "-9: 200-0.05-0.005-0: 0.627 (0.627)\n",
      "-9: 200-0.01-0.005-0: 0.784 (0.824)\n",
      "-9: 500-0.005-0.001-0.5: 0.863 (0.882)\n",
      "-10: 200-0.005-0.0001-0.25: 0.902 (0.922)\n",
      "-10: 200-0.005-0.0005-0.25: 0.902 (0.922)\n",
      "-10: 200-0.01-0.001-0.25: 0.922 (0.922)\n",
      "-10: 200-0.005-0.001-0.25: 0.902 (0.922)\n",
      "-10: 200-0.005-0.001-0.5: 0.902 (0.941)\n",
      "-10: 200-0.001-0.001-0.25: 0.843 (0.902)\n",
      "-10: 200-0.05-0.005-0.25: 0.725 (0.784)\n",
      "-10: 200-0.01-0.005-0.25: 0.765 (0.863)\n",
      "-10: 200-0.005-0.005-0.25: 0.882 (0.922)\n",
      "-10: 200-0.001-0.005-0.25: 0.804 (0.882)\n",
      "-10: 200-0.05-0.01-0.25: 0.745 (0.843)\n",
      "-10: 200-0.005-0.01-0.25: 0.882 (0.902)\n",
      "-10: 200-0.05-0.01-0.5: 0.843 (0.882)\n",
      "-10: 200-0.05-0.005-0.5: 0.667 (0.706)\n",
      "-10: 200-0.01-0.005-0.5: 0.902 (0.922)\n",
      "-10: 200-0.05-0.01-0: 0.588 (0.725)\n",
      "-10: 200-0.05-0.005-0: 0.902 (0.902)\n",
      "-10: 200-0.01-0.005-0: 0.863 (0.902)\n",
      "-10: 500-0.005-0.001-0.5: 0.902 (0.902)\n",
      "-11: 200-0.005-0.0001-0.25: 0.765 (0.863)\n",
      "-11: 200-0.005-0.0005-0.25: 0.843 (0.863)\n",
      "-11: 200-0.01-0.001-0.25: 0.824 (0.882)\n",
      "-11: 200-0.005-0.001-0.25: 0.765 (0.863)\n",
      "-11: 200-0.005-0.001-0.5: 0.824 (0.863)\n",
      "-11: 200-0.001-0.001-0.25: 0.824 (0.824)\n",
      "-11: 200-0.05-0.005-0.25: 0.765 (0.804)\n",
      "-11: 200-0.01-0.005-0.25: 0.843 (0.843)\n",
      "-11: 200-0.005-0.005-0.25: 0.882 (0.882)\n",
      "-11: 200-0.001-0.005-0.25: 0.804 (0.824)\n",
      "-11: 200-0.05-0.01-0.25: 0.765 (0.843)\n",
      "-11: 200-0.005-0.01-0.25: 0.667 (0.863)\n",
      "-11: 200-0.05-0.01-0.5: 0.608 (0.627)\n",
      "-11: 200-0.05-0.005-0.5: 0.784 (0.824)\n",
      "-11: 200-0.01-0.005-0.5: 0.804 (0.863)\n",
      "-11: 200-0.05-0.01-0: 0.667 (0.745)\n",
      "-11: 200-0.05-0.005-0: 0.824 (0.824)\n",
      "-11: 200-0.01-0.005-0: 0.784 (0.863)\n",
      "-11: 500-0.005-0.001-0.5: 0.882 (0.882)\n",
      "-12: 200-0.005-0.0001-0.25: 0.863 (0.941)\n",
      "-12: 200-0.005-0.0005-0.25: 0.922 (0.922)\n",
      "-12: 200-0.01-0.001-0.25: 0.843 (0.922)\n",
      "-12: 200-0.005-0.001-0.25: 0.863 (0.922)\n",
      "-12: 200-0.005-0.001-0.5: 0.843 (0.922)\n",
      "-12: 200-0.001-0.001-0.25: 0.882 (0.922)\n",
      "-12: 200-0.05-0.005-0.25: 0.843 (0.902)\n",
      "-12: 200-0.01-0.005-0.25: 0.882 (0.902)\n",
      "-12: 200-0.005-0.005-0.25: 0.902 (0.902)\n",
      "-12: 200-0.001-0.005-0.25: 0.902 (0.922)\n",
      "-12: 200-0.05-0.01-0.25: 0.843 (0.843)\n",
      "-12: 200-0.005-0.01-0.25: 0.922 (0.922)\n",
      "-12: 200-0.05-0.01-0.5: 0.804 (0.882)\n",
      "-12: 200-0.05-0.005-0.5: 0.588 (0.725)\n",
      "-12: 200-0.01-0.005-0.5: 0.863 (0.902)\n",
      "-12: 200-0.05-0.01-0: 0.627 (0.765)\n",
      "-12: 200-0.05-0.005-0: 0.902 (0.902)\n",
      "-12: 200-0.01-0.005-0: 0.902 (0.902)\n",
      "-12: 500-0.005-0.001-0.5: 0.863 (0.941)\n",
      "-13: 200-0.005-0.0001-0.25: 0.922 (0.941)\n",
      "-13: 200-0.005-0.0005-0.25: 0.902 (0.941)\n",
      "-13: 200-0.01-0.001-0.25: 0.902 (0.922)\n",
      "-13: 200-0.005-0.001-0.25: 0.882 (0.941)\n",
      "-13: 200-0.005-0.001-0.5: 0.863 (0.922)\n",
      "-13: 200-0.001-0.001-0.25: 0.882 (0.902)\n",
      "-13: 200-0.05-0.005-0.25: 0.588 (0.745)\n",
      "-13: 200-0.01-0.005-0.25: 0.824 (0.922)\n",
      "-13: 200-0.005-0.005-0.25: 0.882 (0.922)\n",
      "-13: 200-0.001-0.005-0.25: 0.843 (0.882)\n",
      "-13: 200-0.05-0.01-0.25: 0.882 (0.882)\n",
      "-13: 200-0.005-0.01-0.25: 0.863 (0.902)\n",
      "-13: 200-0.05-0.01-0.5: 0.627 (0.686)\n",
      "-13: 200-0.05-0.005-0.5: 0.804 (0.804)\n",
      "-13: 200-0.01-0.005-0.5: 0.863 (0.902)\n",
      "-13: 200-0.05-0.01-0: 0.706 (0.804)\n",
      "-13: 200-0.05-0.005-0: 0.863 (0.882)\n",
      "-13: 200-0.01-0.005-0: 0.882 (0.902)\n",
      "-13: 500-0.005-0.001-0.5: 0.902 (0.922)\n",
      "-14: 200-0.005-0.0001-0.25: 0.902 (0.961)\n",
      "-14: 200-0.005-0.0005-0.25: 0.902 (0.961)\n",
      "-14: 200-0.01-0.001-0.25: 0.922 (0.922)\n",
      "-14: 200-0.005-0.001-0.25: 0.824 (0.922)\n",
      "-14: 200-0.005-0.001-0.5: 0.902 (0.961)\n",
      "-14: 200-0.001-0.001-0.25: 0.922 (0.922)\n",
      "-14: 200-0.05-0.005-0.25: 0.765 (0.804)\n",
      "-14: 200-0.01-0.005-0.25: 0.882 (0.902)\n",
      "-14: 200-0.005-0.005-0.25: 0.765 (0.941)\n",
      "-14: 200-0.001-0.005-0.25: 0.843 (0.882)\n",
      "-14: 200-0.05-0.01-0.25: 0.725 (0.765)\n",
      "-14: 200-0.005-0.01-0.25: 0.765 (0.882)\n",
      "-14: 200-0.05-0.01-0.5: 0.667 (0.784)\n",
      "-14: 200-0.05-0.005-0.5: 0.784 (0.784)\n",
      "-14: 200-0.01-0.005-0.5: 0.843 (0.902)\n",
      "-14: 200-0.05-0.01-0: 0.725 (0.765)\n",
      "-14: 200-0.05-0.005-0: 0.784 (0.922)\n",
      "-14: 200-0.01-0.005-0: 0.804 (0.922)\n",
      "-14: 500-0.005-0.001-0.5: 0.902 (0.922)\n",
      "-15: 200-0.005-0.0001-0.25: 0.843 (0.941)\n",
      "-15: 200-0.005-0.0005-0.25: 0.765 (0.922)\n",
      "-15: 200-0.01-0.001-0.25: 0.804 (0.941)\n",
      "-15: 200-0.005-0.001-0.25: 0.843 (0.922)\n",
      "-15: 200-0.005-0.001-0.5: 0.824 (0.941)\n",
      "-15: 200-0.001-0.001-0.25: 0.765 (0.882)\n",
      "-15: 200-0.05-0.005-0.25: 0.706 (0.706)\n",
      "-15: 200-0.01-0.005-0.25: 0.745 (0.902)\n",
      "-15: 200-0.005-0.005-0.25: 0.667 (0.902)\n",
      "-15: 200-0.001-0.005-0.25: 0.824 (0.882)\n",
      "-15: 200-0.05-0.01-0.25: 0.784 (0.804)\n",
      "-15: 200-0.005-0.01-0.25: 0.784 (0.902)\n",
      "-15: 200-0.05-0.01-0.5: 0.549 (0.549)\n",
      "-15: 200-0.05-0.005-0.5: 0.627 (0.706)\n",
      "-15: 200-0.01-0.005-0.5: 0.765 (0.882)\n",
      "-15: 200-0.05-0.01-0: 0.843 (0.843)\n",
      "-15: 200-0.05-0.005-0: 0.725 (0.725)\n",
      "-15: 200-0.01-0.005-0: 0.706 (0.843)\n",
      "-15: 500-0.005-0.001-0.5: 0.843 (0.922)\n",
      "-16: 200-0.005-0.0001-0.25: 0.863 (0.902)\n",
      "-16: 200-0.005-0.0005-0.25: 0.824 (0.882)\n",
      "-16: 200-0.01-0.001-0.25: 0.863 (0.882)\n",
      "-16: 200-0.005-0.001-0.25: 0.843 (0.902)\n",
      "-16: 200-0.005-0.001-0.5: 0.824 (0.882)\n",
      "-16: 200-0.001-0.001-0.25: 0.882 (0.882)\n",
      "-16: 200-0.05-0.005-0.25: 0.784 (0.784)\n",
      "-16: 200-0.01-0.005-0.25: 0.725 (0.824)\n",
      "-16: 200-0.005-0.005-0.25: 0.784 (0.843)\n",
      "-16: 200-0.001-0.005-0.25: 0.824 (0.843)\n",
      "-16: 200-0.05-0.01-0.25: 0.784 (0.824)\n",
      "-16: 200-0.005-0.01-0.25: 0.784 (0.882)\n",
      "-16: 200-0.05-0.01-0.5: 0.745 (0.784)\n",
      "-16: 200-0.05-0.005-0.5: 0.725 (0.784)\n",
      "-16: 200-0.01-0.005-0.5: 0.863 (0.863)\n",
      "-16: 200-0.05-0.01-0: 0.765 (0.765)\n",
      "-16: 200-0.05-0.005-0: 0.745 (0.784)\n",
      "-16: 200-0.01-0.005-0: 0.843 (0.863)\n",
      "-16: 500-0.005-0.001-0.5: 0.863 (0.922)\n",
      "-17: 200-0.005-0.0001-0.25: 0.863 (0.902)\n",
      "-17: 200-0.005-0.0005-0.25: 0.843 (0.941)\n",
      "-17: 200-0.01-0.001-0.25: 0.882 (0.922)\n",
      "-17: 200-0.005-0.001-0.25: 0.843 (0.902)\n",
      "-17: 200-0.005-0.001-0.5: 0.843 (0.902)\n",
      "-17: 200-0.001-0.001-0.25: 0.882 (0.882)\n",
      "-17: 200-0.05-0.005-0.25: 0.765 (0.765)\n",
      "-17: 200-0.01-0.005-0.25: 0.863 (0.922)\n",
      "-17: 200-0.005-0.005-0.25: 0.863 (0.902)\n",
      "-17: 200-0.001-0.005-0.25: 0.843 (0.863)\n",
      "-17: 200-0.05-0.01-0.25: 0.784 (0.824)\n",
      "-17: 200-0.005-0.01-0.25: 0.843 (0.863)\n",
      "-17: 200-0.05-0.01-0.5: 0.843 (0.882)\n",
      "-17: 200-0.05-0.005-0.5: 0.706 (0.706)\n",
      "-17: 200-0.01-0.005-0.5: 0.882 (0.882)\n",
      "-17: 200-0.05-0.01-0: 0.686 (0.745)\n",
      "-17: 200-0.05-0.005-0: 0.902 (0.902)\n",
      "-17: 200-0.01-0.005-0: 0.843 (0.843)\n",
      "-17: 500-0.005-0.001-0.5: 0.902 (0.922)\n",
      "-18: 200-0.005-0.0001-0.25: 0.863 (0.922)\n",
      "-18: 200-0.005-0.0005-0.25: 0.804 (0.902)\n",
      "-18: 200-0.01-0.001-0.25: 0.863 (0.902)\n",
      "-18: 200-0.005-0.001-0.25: 0.843 (0.882)\n",
      "-18: 200-0.005-0.001-0.5: 0.843 (0.902)\n",
      "-18: 200-0.001-0.001-0.25: 0.784 (0.863)\n",
      "-18: 200-0.05-0.005-0.25: 0.824 (0.863)\n",
      "-18: 200-0.01-0.005-0.25: 0.824 (0.863)\n",
      "-18: 200-0.005-0.005-0.25: 0.824 (0.863)\n",
      "-18: 200-0.001-0.005-0.25: 0.843 (0.843)\n",
      "-18: 200-0.05-0.01-0.25: 0.725 (0.784)\n",
      "-18: 200-0.005-0.01-0.25: 0.824 (0.843)\n",
      "-18: 200-0.05-0.01-0.5: 0.804 (0.804)\n",
      "-18: 200-0.05-0.005-0.5: 0.608 (0.647)\n",
      "-18: 200-0.01-0.005-0.5: 0.784 (0.843)\n",
      "-18: 200-0.05-0.01-0: 0.765 (0.804)\n",
      "-18: 200-0.05-0.005-0: 0.804 (0.824)\n",
      "-18: 200-0.01-0.005-0: 0.725 (0.824)\n",
      "-18: 500-0.005-0.001-0.5: 0.804 (0.902)\n",
      "-19: 200-0.005-0.0001-0.25: 0.863 (0.941)\n",
      "-19: 200-0.005-0.0005-0.25: 0.843 (0.863)\n",
      "-19: 200-0.01-0.001-0.25: 0.824 (0.882)\n",
      "-19: 200-0.005-0.001-0.25: 0.784 (0.882)\n",
      "-19: 200-0.005-0.001-0.5: 0.843 (0.902)\n",
      "-19: 200-0.001-0.001-0.25: 0.804 (0.843)\n",
      "-19: 200-0.05-0.005-0.25: 0.804 (0.843)\n",
      "-19: 200-0.01-0.005-0.25: 0.843 (0.882)\n",
      "-19: 200-0.005-0.005-0.25: 0.843 (0.863)\n",
      "-19: 200-0.001-0.005-0.25: 0.765 (0.824)\n",
      "-19: 200-0.05-0.01-0.25: 0.804 (0.804)\n",
      "-19: 200-0.005-0.01-0.25: 0.824 (0.863)\n",
      "-19: 200-0.05-0.01-0.5: 0.471 (0.510)\n",
      "-19: 200-0.05-0.005-0.5: 0.686 (0.706)\n",
      "-19: 200-0.01-0.005-0.5: 0.843 (0.843)\n",
      "-19: 200-0.05-0.01-0: 0.667 (0.745)\n",
      "-19: 200-0.05-0.005-0: 0.804 (0.843)\n",
      "-19: 200-0.01-0.005-0: 0.765 (0.784)\n",
      "-19: 500-0.005-0.001-0.5: 0.843 (0.882)\n",
      "-20: 200-0.005-0.0001-0.25: 0.922 (0.941)\n",
      "-20: 200-0.005-0.0005-0.25: 0.922 (0.941)\n",
      "-20: 200-0.01-0.001-0.25: 0.902 (0.922)\n",
      "-20: 200-0.005-0.001-0.25: 0.882 (0.902)\n",
      "-20: 200-0.005-0.001-0.5: 0.902 (0.922)\n",
      "-20: 200-0.001-0.001-0.25: 0.843 (0.882)\n",
      "-20: 200-0.05-0.005-0.25: 0.686 (0.745)\n",
      "-20: 200-0.01-0.005-0.25: 0.882 (0.922)\n",
      "-20: 200-0.005-0.005-0.25: 0.882 (0.922)\n",
      "-20: 200-0.001-0.005-0.25: 0.784 (0.863)\n",
      "-20: 200-0.05-0.01-0.25: 0.686 (0.725)\n",
      "-20: 200-0.005-0.01-0.25: 0.882 (0.902)\n",
      "-20: 200-0.05-0.01-0.5: 0.667 (0.745)\n",
      "-20: 200-0.05-0.005-0.5: 0.549 (0.627)\n",
      "-20: 200-0.01-0.005-0.5: 0.804 (0.902)\n",
      "-20: 200-0.05-0.01-0: 0.725 (0.804)\n",
      "-20: 200-0.05-0.005-0: 0.765 (0.804)\n",
      "-20: 200-0.01-0.005-0: 0.882 (0.882)\n",
      "-20: 500-0.005-0.001-0.5: 0.882 (0.922)\n",
      "----- 192.34 mins -----\n"
     ]
    }
   ],
   "source": [
    "EXPS = [\n",
    "        {'epochs': 200, 'lr': .001, 'wd': 1e-4, 'drop': .25},\n",
    "        {'epochs': 200, 'lr': .001, 'wd': 5e-4, 'drop': .25},\n",
    "        {'epochs': 200, 'lr': .001, 'wd': 1e-3, 'drop': .25},\n",
    "        {'epochs': 200, 'lr': .001, 'wd': 5e-3, 'drop': .25},\n",
    "\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 1e-4, 'drop': .25},\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 5e-4, 'drop': .25},\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 1e-3, 'drop': .25},\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 5e-3, 'drop': .25},\n",
    "\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 1e-3, 'drop': .5},\n",
    "\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 5e-4, 'drop': 0},\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 5e-4, 'drop': .5},\n",
    "        {'epochs': 200, 'lr': .005, 'wd': 5e-4, 'drop': .75},\n",
    "\n",
    "        {'epochs': 500, 'lr': .005, 'wd': 5e-4, 'drop': .25},\n",
    "        {'epochs': 750, 'lr': .005, 'wd': 5e-4, 'drop': .25},\n",
    "        {'epochs': 1000, 'lr': .001, 'wd': 5e-5, 'drop': .25},\n",
    "        ]\n",
    "\n",
    "best_accs1 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs1 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device, idx=i%10)\n",
    "    for j, exp in enumerate(EXPS):        \n",
    "        arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=exp['drop'], norm=NORM, dev=device)\n",
    "        S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, exp['epochs'], exp['lr'], exp['wd'],\n",
    "                             epochs_h=EPOCHS_h, epochs_W=EPOCHS_W)\n",
    "\n",
    "        best_accs1[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs1[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}: {best_val_accs1[j,i]:.3f} ({best_accs1[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"lr\"]}-{exp[\"wd\"]}-{exp[\"drop\"]}' for exp in EXPS]\n",
    "table_over1 = summary_table(best_accs1, index_name)\n",
    "table1 = summary_table(best_val_accs1, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.0001-0.25</th>\n",
       "      <td>0.861765</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.044486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.0005-0.25</th>\n",
       "      <td>0.860784</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.039654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.001-0.25</th>\n",
       "      <td>0.844118</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.052787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.001-0.25</th>\n",
       "      <td>0.845098</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.040612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.001-0.5</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.001-0.001-0.25</th>\n",
       "      <td>0.832353</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.048219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.005-0.25</th>\n",
       "      <td>0.756863</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.103829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.005-0.25</th>\n",
       "      <td>0.826471</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.047738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.005-0.25</th>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.056964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.001-0.005-0.25</th>\n",
       "      <td>0.824510</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.035875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0.25</th>\n",
       "      <td>0.771569</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.055207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.005-0.01-0.25</th>\n",
       "      <td>0.812745</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.058979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0.5</th>\n",
       "      <td>0.734314</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.115915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.005-0.5</th>\n",
       "      <td>0.708824</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.099262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.005-0.5</th>\n",
       "      <td>0.836275</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.050478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.01-0</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.070288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.05-0.005-0</th>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.097469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-0.01-0.005-0</th>\n",
       "      <td>0.827451</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.053913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-0.005-0.001-0.5</th>\n",
       "      <td>0.865686</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.037345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean accs       med       std\n",
       "200-0.005-0.0001-0.25   0.861765  0.862745  0.044486\n",
       "200-0.005-0.0005-0.25   0.860784  0.852941  0.039654\n",
       "200-0.01-0.001-0.25     0.844118  0.852941  0.052787\n",
       "200-0.005-0.001-0.25    0.845098  0.843137  0.040612\n",
       "200-0.005-0.001-0.5     0.852941  0.843137  0.029412\n",
       "200-0.001-0.001-0.25    0.832353  0.843137  0.048219\n",
       "200-0.05-0.005-0.25     0.756863  0.784314  0.103829\n",
       "200-0.01-0.005-0.25     0.826471  0.833333  0.047738\n",
       "200-0.005-0.005-0.25    0.835294  0.843137  0.056964\n",
       "200-0.001-0.005-0.25    0.824510  0.823529  0.035875\n",
       "200-0.05-0.01-0.25      0.771569  0.764706  0.055207\n",
       "200-0.005-0.01-0.25     0.812745  0.813725  0.058979\n",
       "200-0.05-0.01-0.5       0.734314  0.794118  0.115915\n",
       "200-0.05-0.005-0.5      0.708824  0.705882  0.099262\n",
       "200-0.01-0.005-0.5      0.836275  0.862745  0.050478\n",
       "200-0.05-0.01-0         0.735294  0.735294  0.070288\n",
       "200-0.05-0.005-0        0.770588  0.794118  0.097469\n",
       "200-0.01-0.005-0        0.827451  0.843137  0.053913\n",
       "500-0.005-0.001-0.5     0.865686  0.862745  0.037345"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/src/arch.py:190: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.last_act(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 1-1-True: 0.588 (0.588)\n",
      "-1: 1-1-False: 0.804 (0.843)\n",
      "-1: 5-1-True: 0.804 (0.843)\n",
      "-1: 10-1-True: 0.804 (0.824)\n",
      "-1: 25-1-True: 0.765 (0.843)\n",
      "-1: 25-5-True: 0.765 (0.843)\n",
      "-1: 5-1-True: 0.745 (0.843)\n",
      "-1: 10-10-True: 0.824 (0.843)\n",
      "-1: 25-25-True: 0.765 (0.863)\n",
      "-1: 10-10-True: 0.843 (0.863)\n",
      "-1: 25-25-True: 0.843 (0.882)\n",
      "-1: 1-5-True: 0.549 (0.588)\n",
      "-1: 1-10-True: 0.529 (0.569)\n",
      "-1: 1-25-True: 0.471 (0.569)\n",
      "-1: 5-25-True: 0.824 (0.882)\n",
      "-1: 10-10-True: 0.824 (0.882)\n",
      "-1: 25-25-True: 0.843 (0.902)\n",
      "-1: 10-10-True: 0.804 (0.863)\n",
      "-1: 25-25-True: 0.804 (0.882)\n",
      "-1: 50-50-True: 0.843 (0.882)\n",
      "-1: 10-10-True: 0.843 (0.882)\n",
      "-2: 1-1-True: 0.647 (0.706)\n",
      "-2: 1-1-False: 0.608 (0.667)\n",
      "-2: 5-1-True: 0.784 (0.882)\n",
      "-2: 10-1-True: 0.863 (0.902)\n",
      "-2: 25-1-True: 0.902 (0.902)\n",
      "-2: 25-5-True: 0.882 (0.922)\n",
      "-2: 5-1-True: 0.843 (0.922)\n",
      "-2: 10-10-True: 0.882 (0.902)\n",
      "-2: 25-25-True: 0.824 (0.902)\n",
      "-2: 10-10-True: 0.882 (0.941)\n",
      "-2: 25-25-True: 0.902 (0.922)\n",
      "-2: 1-5-True: 0.569 (0.667)\n",
      "-2: 1-10-True: 0.627 (0.627)\n",
      "-2: 1-25-True: 0.588 (0.647)\n",
      "-2: 5-25-True: 0.882 (0.922)\n",
      "-2: 10-10-True: 0.922 (0.941)\n",
      "-2: 25-25-True: 0.863 (0.941)\n",
      "-2: 10-10-True: 0.824 (0.941)\n",
      "-2: 25-25-True: 0.902 (0.922)\n",
      "-2: 50-50-True: 0.804 (0.922)\n",
      "-2: 10-10-True: 0.843 (0.922)\n",
      "-3: 1-1-True: 0.510 (0.549)\n",
      "-3: 1-1-False: 0.882 (0.922)\n",
      "-3: 5-1-True: 0.824 (0.843)\n",
      "-3: 10-1-True: 0.843 (0.882)\n",
      "-3: 25-1-True: 0.863 (0.902)\n",
      "-3: 25-5-True: 0.824 (0.941)\n",
      "-3: 5-1-True: 0.824 (0.922)\n",
      "-3: 10-10-True: 0.902 (0.922)\n",
      "-3: 25-25-True: 0.863 (0.922)\n",
      "-3: 10-10-True: 0.863 (0.922)\n",
      "-3: 25-25-True: 0.882 (0.941)\n",
      "-3: 1-5-True: 0.490 (0.608)\n",
      "-3: 1-10-True: 0.490 (0.569)\n",
      "-3: 1-25-True: 0.510 (0.569)\n",
      "-3: 5-25-True: 0.922 (0.922)\n",
      "-3: 10-10-True: 0.902 (0.922)\n",
      "-3: 25-25-True: 0.863 (0.922)\n",
      "-3: 10-10-True: 0.882 (0.922)\n",
      "-3: 25-25-True: 0.902 (0.922)\n",
      "-3: 50-50-True: 0.922 (0.941)\n",
      "-3: 10-10-True: 0.824 (0.941)\n",
      "-4: 1-1-True: 0.490 (0.667)\n",
      "-4: 1-1-False: 0.902 (0.922)\n",
      "-4: 5-1-True: 0.863 (0.902)\n",
      "-4: 10-1-True: 0.902 (0.902)\n",
      "-4: 25-1-True: 0.765 (0.784)\n",
      "-4: 25-5-True: 0.784 (0.863)\n",
      "-4: 5-1-True: 0.824 (0.863)\n",
      "-4: 10-10-True: 0.882 (0.922)\n",
      "-4: 25-25-True: 0.902 (0.941)\n",
      "-4: 10-10-True: 0.922 (0.961)\n",
      "-4: 25-25-True: 0.902 (0.941)\n",
      "-4: 1-5-True: 0.510 (0.569)\n",
      "-4: 1-10-True: 0.510 (0.529)\n",
      "-4: 1-25-True: 0.529 (0.549)\n",
      "-4: 5-25-True: 0.843 (0.941)\n",
      "-4: 10-10-True: 0.863 (0.882)\n",
      "-4: 25-25-True: 0.902 (0.961)\n",
      "-4: 10-10-True: 0.922 (0.961)\n",
      "-4: 25-25-True: 0.882 (0.961)\n",
      "-4: 50-50-True: 0.941 (0.961)\n",
      "-4: 10-10-True: 0.902 (0.961)\n",
      "-5: 1-1-True: 0.451 (0.510)\n",
      "-5: 1-1-False: 0.373 (0.431)\n",
      "-5: 5-1-True: 0.765 (0.824)\n",
      "-5: 10-1-True: 0.882 (0.902)\n",
      "-5: 25-1-True: 0.765 (0.824)\n",
      "-5: 25-5-True: 0.882 (0.922)\n",
      "-5: 5-1-True: 0.824 (0.843)\n",
      "-5: 10-10-True: 0.902 (0.902)\n",
      "-5: 25-25-True: 0.882 (0.882)\n",
      "-5: 10-10-True: 0.824 (0.882)\n",
      "-5: 25-25-True: 0.824 (0.922)\n",
      "-5: 1-5-True: 0.451 (0.490)\n",
      "-5: 1-10-True: 0.373 (0.490)\n",
      "-5: 1-25-True: 0.451 (0.471)\n",
      "-5: 5-25-True: 0.863 (0.902)\n",
      "-5: 10-10-True: 0.902 (0.941)\n",
      "-5: 25-25-True: 0.824 (0.941)\n",
      "-5: 10-10-True: 0.882 (0.922)\n",
      "-5: 25-25-True: 0.882 (0.922)\n",
      "-5: 50-50-True: 0.804 (0.922)\n",
      "-5: 10-10-True: 0.824 (0.941)\n",
      "-6: 1-1-True: 0.510 (0.569)\n",
      "-6: 1-1-False: 0.569 (0.608)\n",
      "-6: 5-1-True: 0.843 (0.843)\n",
      "-6: 10-1-True: 0.804 (0.843)\n",
      "-6: 25-1-True: 0.745 (0.824)\n",
      "-6: 25-5-True: 0.804 (0.882)\n",
      "-6: 5-1-True: 0.824 (0.902)\n",
      "-6: 10-10-True: 0.882 (0.922)\n",
      "-6: 25-25-True: 0.824 (0.882)\n",
      "-6: 10-10-True: 0.882 (0.922)\n",
      "-6: 25-25-True: 0.843 (0.902)\n",
      "-6: 1-5-True: 0.451 (0.647)\n",
      "-6: 1-10-True: 0.529 (0.569)\n",
      "-6: 1-25-True: 0.451 (0.529)\n",
      "-6: 5-25-True: 0.863 (0.922)\n",
      "-6: 10-10-True: 0.804 (0.902)\n",
      "-6: 25-25-True: 0.843 (0.882)\n",
      "-6: 10-10-True: 0.804 (0.922)\n",
      "-6: 25-25-True: 0.804 (0.882)\n",
      "-6: 50-50-True: 0.824 (0.902)\n",
      "-6: 10-10-True: 0.804 (0.863)\n",
      "-7: 1-1-True: 0.804 (0.843)\n",
      "-7: 1-1-False: 0.902 (0.902)\n",
      "-7: 5-1-True: 0.902 (0.902)\n",
      "-7: 10-1-True: 0.843 (0.863)\n",
      "-7: 25-1-True: 0.863 (0.863)\n",
      "-7: 25-5-True: 0.882 (0.902)\n",
      "-7: 5-1-True: 0.882 (0.902)\n",
      "-7: 10-10-True: 0.882 (0.882)\n",
      "-7: 25-25-True: 0.843 (0.902)\n",
      "-7: 10-10-True: 0.824 (0.902)\n",
      "-7: 25-25-True: 0.843 (0.902)\n",
      "-7: 1-5-True: 0.510 (0.549)\n",
      "-7: 1-10-True: 0.647 (0.706)\n",
      "-7: 1-25-True: 0.451 (0.549)\n",
      "-7: 5-25-True: 0.863 (0.882)\n",
      "-7: 10-10-True: 0.843 (0.902)\n",
      "-7: 25-25-True: 0.902 (0.902)\n",
      "-7: 10-10-True: 0.863 (0.922)\n",
      "-7: 25-25-True: 0.843 (0.922)\n",
      "-7: 50-50-True: 0.824 (0.902)\n",
      "-7: 10-10-True: 0.863 (0.882)\n",
      "-8: 1-1-True: 0.569 (0.608)\n",
      "-8: 1-1-False: 0.549 (0.549)\n",
      "-8: 5-1-True: 0.784 (0.804)\n",
      "-8: 10-1-True: 0.725 (0.745)\n",
      "-8: 25-1-True: 0.745 (0.804)\n",
      "-8: 25-5-True: 0.824 (0.863)\n",
      "-8: 5-1-True: 0.824 (0.882)\n",
      "-8: 10-10-True: 0.843 (0.863)\n",
      "-8: 25-25-True: 0.843 (0.882)\n",
      "-8: 10-10-True: 0.843 (0.863)\n",
      "-8: 25-25-True: 0.804 (0.863)\n",
      "-8: 1-5-True: 0.529 (0.608)\n",
      "-8: 1-10-True: 0.569 (0.588)\n",
      "-8: 1-25-True: 0.549 (0.549)\n",
      "-8: 5-25-True: 0.863 (0.902)\n",
      "-8: 10-10-True: 0.843 (0.882)\n",
      "-8: 25-25-True: 0.804 (0.882)\n",
      "-8: 10-10-True: 0.863 (0.882)\n",
      "-8: 25-25-True: 0.863 (0.882)\n",
      "-8: 50-50-True: 0.863 (0.902)\n",
      "-8: 10-10-True: 0.882 (0.902)\n",
      "-9: 1-1-True: 0.745 (0.745)\n",
      "-9: 1-1-False: 0.588 (0.588)\n",
      "-9: 5-1-True: 0.824 (0.843)\n",
      "-9: 10-1-True: 0.804 (0.863)\n",
      "-9: 25-1-True: 0.843 (0.902)\n",
      "-9: 25-5-True: 0.824 (0.843)\n",
      "-9: 5-1-True: 0.843 (0.882)\n",
      "-9: 10-10-True: 0.824 (0.882)\n",
      "-9: 25-25-True: 0.863 (0.863)\n",
      "-9: 10-10-True: 0.824 (0.902)\n",
      "-9: 25-25-True: 0.824 (0.863)\n",
      "-9: 1-5-True: 0.490 (0.549)\n",
      "-9: 1-10-True: 0.451 (0.627)\n",
      "-9: 1-25-True: 0.510 (0.549)\n",
      "-9: 5-25-True: 0.824 (0.902)\n",
      "-9: 10-10-True: 0.824 (0.882)\n",
      "-9: 25-25-True: 0.804 (0.863)\n",
      "-9: 10-10-True: 0.824 (0.902)\n",
      "-9: 25-25-True: 0.824 (0.882)\n",
      "-9: 50-50-True: 0.824 (0.882)\n",
      "-9: 10-10-True: 0.804 (0.882)\n",
      "-10: 1-1-True: 0.667 (0.686)\n",
      "-10: 1-1-False: 0.510 (0.588)\n",
      "-10: 5-1-True: 0.902 (0.902)\n",
      "-10: 10-1-True: 0.843 (0.902)\n",
      "-10: 25-1-True: 0.706 (0.765)\n",
      "-10: 25-5-True: 0.922 (0.922)\n",
      "-10: 5-1-True: 0.902 (0.922)\n",
      "-10: 10-10-True: 0.843 (0.902)\n",
      "-10: 25-25-True: 0.882 (0.902)\n",
      "-10: 10-10-True: 0.902 (0.902)\n",
      "-10: 25-25-True: 0.863 (0.941)\n",
      "-10: 1-5-True: 0.706 (0.706)\n",
      "-10: 1-10-True: 0.824 (0.824)\n",
      "-10: 1-25-True: 0.863 (0.863)\n",
      "-10: 5-25-True: 0.882 (0.922)\n",
      "-10: 10-10-True: 0.902 (0.922)\n",
      "-10: 25-25-True: 0.902 (0.922)\n",
      "-10: 10-10-True: 0.882 (0.922)\n",
      "-10: 25-25-True: 0.902 (0.922)\n",
      "-10: 50-50-True: 0.882 (0.941)\n",
      "-10: 10-10-True: 0.863 (0.922)\n",
      "-11: 1-1-True: 0.471 (0.529)\n",
      "-11: 1-1-False: 0.745 (0.804)\n",
      "-11: 5-1-True: 0.784 (0.784)\n",
      "-11: 10-1-True: 0.765 (0.804)\n",
      "-11: 25-1-True: 0.804 (0.843)\n",
      "-11: 25-5-True: 0.843 (0.863)\n",
      "-11: 5-1-True: 0.765 (0.843)\n",
      "-11: 10-10-True: 0.824 (0.824)\n",
      "-11: 25-25-True: 0.804 (0.882)\n",
      "-11: 10-10-True: 0.804 (0.863)\n",
      "-11: 25-25-True: 0.843 (0.863)\n",
      "-11: 1-5-True: 0.451 (0.588)\n",
      "-11: 1-10-True: 0.471 (0.569)\n",
      "-11: 1-25-True: 0.471 (0.549)\n",
      "-11: 5-25-True: 0.843 (0.882)\n",
      "-11: 10-10-True: 0.784 (0.863)\n",
      "-11: 25-25-True: 0.824 (0.843)\n",
      "-11: 10-10-True: 0.863 (0.882)\n",
      "-11: 25-25-True: 0.824 (0.863)\n",
      "-11: 50-50-True: 0.843 (0.863)\n",
      "-11: 10-10-True: 0.843 (0.863)\n",
      "-12: 1-1-True: 0.863 (0.863)\n",
      "-12: 1-1-False: 0.627 (0.667)\n",
      "-12: 5-1-True: 0.843 (0.941)\n",
      "-12: 10-1-True: 0.863 (0.922)\n",
      "-12: 25-1-True: 0.843 (0.863)\n",
      "-12: 25-5-True: 0.843 (0.902)\n",
      "-12: 5-1-True: 0.863 (0.941)\n",
      "-12: 10-10-True: 0.922 (0.941)\n",
      "-12: 25-25-True: 0.863 (0.922)\n",
      "-12: 10-10-True: 0.863 (0.902)\n",
      "-12: 25-25-True: 0.902 (0.922)\n",
      "-12: 1-5-True: 0.882 (0.882)\n",
      "-12: 1-10-True: 0.627 (0.667)\n",
      "-12: 1-25-True: 0.588 (0.667)\n",
      "-12: 5-25-True: 0.902 (0.922)\n",
      "-12: 10-10-True: 0.922 (0.922)\n",
      "-12: 25-25-True: 0.882 (0.922)\n",
      "-12: 10-10-True: 0.804 (0.922)\n",
      "-12: 25-25-True: 0.843 (0.922)\n",
      "-12: 50-50-True: 0.824 (0.941)\n",
      "-12: 10-10-True: 0.843 (0.922)\n",
      "-13: 1-1-True: 0.765 (0.784)\n",
      "-13: 1-1-False: 0.471 (0.529)\n",
      "-13: 5-1-True: 0.843 (0.882)\n",
      "-13: 10-1-True: 0.510 (0.549)\n",
      "-13: 25-1-True: 0.588 (0.647)\n",
      "-13: 25-5-True: 0.922 (0.922)\n",
      "-13: 5-1-True: 0.863 (0.882)\n",
      "-13: 10-10-True: 0.902 (0.922)\n",
      "-13: 25-25-True: 0.922 (0.922)\n",
      "-13: 10-10-True: 0.902 (0.922)\n",
      "-13: 25-25-True: 0.804 (0.922)\n",
      "-13: 1-5-True: 0.627 (0.647)\n",
      "-13: 1-10-True: 0.706 (0.745)\n",
      "-13: 1-25-True: 0.765 (0.824)\n",
      "-13: 5-25-True: 0.902 (0.922)\n",
      "-13: 10-10-True: 0.824 (0.922)\n",
      "-13: 25-25-True: 0.882 (0.902)\n",
      "-13: 10-10-True: 0.863 (0.941)\n",
      "-13: 25-25-True: 0.863 (0.922)\n",
      "-13: 50-50-True: 0.902 (0.922)\n",
      "-13: 10-10-True: 0.882 (0.941)\n",
      "-14: 1-1-True: 0.667 (0.686)\n",
      "-14: 1-1-False: 0.902 (0.902)\n",
      "-14: 5-1-True: 0.725 (0.784)\n",
      "-14: 10-1-True: 0.745 (0.824)\n",
      "-14: 25-1-True: 0.490 (0.588)\n",
      "-14: 25-5-True: 0.824 (0.922)\n",
      "-14: 5-1-True: 0.902 (0.922)\n",
      "-14: 10-10-True: 0.863 (0.922)\n",
      "-14: 25-25-True: 0.882 (0.941)\n",
      "-14: 10-10-True: 0.863 (0.941)\n",
      "-14: 25-25-True: 0.863 (0.941)\n",
      "-14: 1-5-True: 0.471 (0.608)\n",
      "-14: 1-10-True: 0.471 (0.529)\n",
      "-14: 1-25-True: 0.510 (0.529)\n",
      "-14: 5-25-True: 0.961 (0.961)\n",
      "-14: 10-10-True: 0.882 (0.902)\n",
      "-14: 25-25-True: 0.863 (0.941)\n",
      "-14: 10-10-True: 0.863 (0.941)\n",
      "-14: 25-25-True: 0.902 (0.922)\n",
      "-14: 50-50-True: 0.902 (0.961)\n",
      "-14: 10-10-True: 0.941 (0.961)\n",
      "-15: 1-1-True: 0.392 (0.490)\n",
      "-15: 1-1-False: 0.431 (0.490)\n",
      "-15: 5-1-True: 0.765 (0.784)\n",
      "-15: 10-1-True: 0.784 (0.863)\n",
      "-15: 25-1-True: 0.804 (0.824)\n",
      "-15: 25-5-True: 0.863 (0.902)\n",
      "-15: 5-1-True: 0.843 (0.902)\n",
      "-15: 10-10-True: 0.784 (0.843)\n",
      "-15: 25-25-True: 0.863 (0.922)\n",
      "-15: 10-10-True: 0.784 (0.941)\n",
      "-15: 25-25-True: 0.804 (0.941)\n",
      "-15: 1-5-True: 0.373 (0.471)\n",
      "-15: 1-10-True: 0.412 (0.490)\n",
      "-15: 1-25-True: 0.333 (0.451)\n",
      "-15: 5-25-True: 0.882 (0.941)\n",
      "-15: 10-10-True: 0.784 (0.882)\n",
      "-15: 25-25-True: 0.804 (0.922)\n",
      "-15: 10-10-True: 0.863 (0.922)\n",
      "-15: 25-25-True: 0.882 (0.922)\n",
      "-15: 50-50-True: 0.863 (0.941)\n",
      "-15: 10-10-True: 0.882 (0.922)\n",
      "-16: 1-1-True: 0.529 (0.647)\n",
      "-16: 1-1-False: 0.510 (0.529)\n",
      "-16: 5-1-True: 0.784 (0.863)\n",
      "-16: 10-1-True: 0.824 (0.843)\n",
      "-16: 25-1-True: 0.745 (0.824)\n",
      "-16: 25-5-True: 0.784 (0.804)\n",
      "-16: 5-1-True: 0.843 (0.902)\n",
      "-16: 10-10-True: 0.843 (0.843)\n",
      "-16: 25-25-True: 0.824 (0.902)\n",
      "-16: 10-10-True: 0.843 (0.902)\n",
      "-16: 25-25-True: 0.804 (0.902)\n",
      "-16: 1-5-True: 0.490 (0.588)\n",
      "-16: 1-10-True: 0.549 (0.549)\n",
      "-16: 1-25-True: 0.451 (0.510)\n",
      "-16: 5-25-True: 0.863 (0.902)\n",
      "-16: 10-10-True: 0.824 (0.863)\n",
      "-16: 25-25-True: 0.824 (0.922)\n",
      "-16: 10-10-True: 0.882 (0.902)\n",
      "-16: 25-25-True: 0.882 (0.922)\n",
      "-16: 50-50-True: 0.824 (0.882)\n",
      "-16: 10-10-True: 0.804 (0.922)\n",
      "-17: 1-1-True: 0.569 (0.569)\n",
      "-17: 1-1-False: 0.824 (0.882)\n",
      "-17: 5-1-True: 0.784 (0.863)\n",
      "-17: 10-1-True: 0.804 (0.843)\n",
      "-17: 25-1-True: 0.843 (0.902)\n",
      "-17: 25-5-True: 0.843 (0.922)\n",
      "-17: 5-1-True: 0.863 (0.882)\n",
      "-17: 10-10-True: 0.843 (0.882)\n",
      "-17: 25-25-True: 0.824 (0.882)\n",
      "-17: 10-10-True: 0.804 (0.882)\n",
      "-17: 25-25-True: 0.863 (0.902)\n",
      "-17: 1-5-True: 0.529 (0.569)\n",
      "-17: 1-10-True: 0.863 (0.863)\n",
      "-17: 1-25-True: 0.510 (0.549)\n",
      "-17: 5-25-True: 0.843 (0.882)\n",
      "-17: 10-10-True: 0.863 (0.902)\n",
      "-17: 25-25-True: 0.843 (0.882)\n",
      "-17: 10-10-True: 0.843 (0.941)\n",
      "-17: 25-25-True: 0.882 (0.941)\n",
      "-17: 50-50-True: 0.843 (0.902)\n",
      "-17: 10-10-True: 0.882 (0.902)\n",
      "-18: 1-1-True: 0.471 (0.569)\n",
      "-18: 1-1-False: 0.451 (0.529)\n",
      "-18: 5-1-True: 0.824 (0.843)\n",
      "-18: 10-1-True: 0.725 (0.824)\n",
      "-18: 25-1-True: 0.745 (0.843)\n",
      "-18: 25-5-True: 0.804 (0.824)\n",
      "-18: 5-1-True: 0.804 (0.863)\n",
      "-18: 10-10-True: 0.784 (0.824)\n",
      "-18: 25-25-True: 0.824 (0.882)\n",
      "-18: 10-10-True: 0.824 (0.922)\n",
      "-18: 25-25-True: 0.824 (0.882)\n",
      "-18: 1-5-True: 0.490 (0.569)\n",
      "-18: 1-10-True: 0.510 (0.549)\n",
      "-18: 1-25-True: 0.529 (0.588)\n",
      "-18: 5-25-True: 0.843 (0.882)\n",
      "-18: 10-10-True: 0.804 (0.882)\n",
      "-18: 25-25-True: 0.804 (0.863)\n",
      "-18: 10-10-True: 0.843 (0.882)\n",
      "-18: 25-25-True: 0.902 (0.902)\n",
      "-18: 50-50-True: 0.863 (0.882)\n",
      "-18: 10-10-True: 0.824 (0.902)\n",
      "-19: 1-1-True: 0.569 (0.647)\n",
      "-19: 1-1-False: 0.451 (0.451)\n",
      "-19: 5-1-True: 0.824 (0.882)\n",
      "-19: 10-1-True: 0.765 (0.784)\n",
      "-19: 25-1-True: 0.451 (0.529)\n",
      "-19: 25-5-True: 0.824 (0.882)\n",
      "-19: 5-1-True: 0.863 (0.902)\n",
      "-19: 10-10-True: 0.804 (0.843)\n",
      "-19: 25-25-True: 0.863 (0.882)\n",
      "-19: 10-10-True: 0.824 (0.882)\n",
      "-19: 25-25-True: 0.863 (0.863)\n",
      "-19: 1-5-True: 0.667 (0.706)\n",
      "-19: 1-10-True: 0.529 (0.588)\n",
      "-19: 1-25-True: 0.451 (0.529)\n",
      "-19: 5-25-True: 0.863 (0.882)\n",
      "-19: 10-10-True: 0.824 (0.902)\n",
      "-19: 25-25-True: 0.784 (0.863)\n",
      "-19: 10-10-True: 0.784 (0.843)\n",
      "-19: 25-25-True: 0.784 (0.882)\n",
      "-19: 50-50-True: 0.824 (0.882)\n",
      "-19: 10-10-True: 0.824 (0.882)\n",
      "-20: 1-1-True: 0.569 (0.588)\n",
      "-20: 1-1-False: 0.922 (0.922)\n",
      "-20: 5-1-True: 0.824 (0.882)\n",
      "-20: 10-1-True: 0.882 (0.882)\n",
      "-20: 25-1-True: 0.706 (0.882)\n",
      "-20: 25-5-True: 0.922 (0.941)\n",
      "-20: 5-1-True: 0.863 (0.922)\n",
      "-20: 10-10-True: 0.784 (0.882)\n",
      "-20: 25-25-True: 0.863 (0.902)\n",
      "-20: 10-10-True: 0.902 (0.922)\n",
      "-20: 25-25-True: 0.843 (0.902)\n",
      "-20: 1-5-True: 0.549 (0.588)\n",
      "-20: 1-10-True: 0.804 (0.843)\n",
      "-20: 1-25-True: 0.843 (0.843)\n",
      "-20: 5-25-True: 0.882 (0.922)\n",
      "-20: 10-10-True: 0.804 (0.902)\n",
      "-20: 25-25-True: 0.843 (0.922)\n",
      "-20: 10-10-True: 0.882 (0.922)\n",
      "-20: 25-25-True: 0.784 (0.882)\n",
      "-20: 50-50-True: 0.843 (0.922)\n",
      "-20: 10-10-True: 0.882 (0.902)\n",
      "----- 107.82 mins -----\n"
     ]
    }
   ],
   "source": [
    "# h0, norm (norm, not norm, norm H), sep vs joint training, optimizers iters (W vs h)\n",
    "EXPS = [\n",
    "        {'epochs': 200, 'epochs_h': 1, 'epochs_W': 1, 'alt': True},        \n",
    "        {'epochs': 1000, 'epochs_h': 1, 'epochs_W': 1, 'alt': False},\n",
    "\n",
    "        {'epochs': 200, 'epochs_h': 5, 'epochs_W': 1, 'alt': True},\n",
    "        {'epochs': 200, 'epochs_h': 15, 'epochs_W': 1, 'alt': True},\n",
    "        {'epochs': 200, 'epochs_h': 25, 'epochs_W': 5, 'alt': True},\n",
    "\n",
    "        {'epochs': 5000, 'epochs_h': 5, 'epochs_W': 1, 'alt': True},\n",
    "\n",
    "        {'epochs': 50, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'epochs': 50, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        {'epochs': 100, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'epochs': 100, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "\n",
    "        {'epochs': 200, 'epochs_h': 1, 'epochs_W': 5, 'alt': True},\n",
    "        {'epochs': 200, 'epochs_h': 1, 'epochs_W': 10, 'alt': True},\n",
    "        {'epochs': 200, 'epochs_h': 1, 'epochs_W': 25, 'alt': True},\n",
    "        {'epochs': 200, 'epochs_h': 5, 'epochs_W': 25, 'alt': True},\n",
    "\n",
    "        {'epochs': 100, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'epochs': 100, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        {'epochs': 200, 'epochs_h': 10, 'epochs_W': 10, 'alt': True},\n",
    "        {'epochs': 200, 'epochs_h': 25, 'epochs_W': 25, 'alt': True},\n",
    "        ]\n",
    "\n",
    "\n",
    "best_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device, idx=i%10)\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=NORM, dev=device)\n",
    "        S = torch.Tensor(A).to(device)\n",
    "\n",
    "        if not exp['alt']:\n",
    "            S_pows = compute_S_pows(A, K, device)\n",
    "            model = NodeClassModel(arch, S_pows, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S,  K, masks, LOSS_FN, device=device)\n",
    "            _, acc = model.train(feat, labels, exp['epochs'], LR, WD, epochs_h=exp['epochs_h'],\n",
    "                                 epochs_W=exp['epochs_W'])\n",
    "\n",
    "        best_accs2[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs2[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}: {best_val_accs2[j,i]:.3f} ({best_accs2[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"epochs\"]}-{exp[\"epochs_h\"]}-{exp[\"epochs_W\"]}-{exp[\"alt\"]}' for exp in EXPS]\n",
    "table_over2 = summary_table(best_accs2, index_name)\n",
    "table2 = summary_table(best_val_accs2, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200-1-1-True</th>\n",
       "      <td>0.592157</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.123483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000-1-1-False</th>\n",
       "      <td>0.650980</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.184314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-5-1-True</th>\n",
       "      <td>0.814706</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.043614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-10-1-True</th>\n",
       "      <td>0.799020</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.083391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-25-1-True</th>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.115769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-25-5-True</th>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.045565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000-5-1-True</th>\n",
       "      <td>0.840196</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.038361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50-10-10-True</th>\n",
       "      <td>0.850980</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.041779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50-25-25-True</th>\n",
       "      <td>0.850980</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.035294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100-10-10-True</th>\n",
       "      <td>0.850980</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.037409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100-25-25-True</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.031979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-5-True</th>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.109084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-10-True</th>\n",
       "      <td>0.574510</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.132712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-1-25-True</th>\n",
       "      <td>0.541176</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.131738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-5-25-True</th>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.032457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100-10-10-True</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.043669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100-25-25-True</th>\n",
       "      <td>0.845098</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.035565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-10-10-True</th>\n",
       "      <td>0.851961</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.034230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-25-25-True</th>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.872549</td>\n",
       "      <td>0.040124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200-50-50-True</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.037970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500-10-10-True</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.035888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean accs       med       std\n",
       "200-1-1-True     0.592157  0.568627  0.123483\n",
       "1000-1-1-False   0.650980  0.598039  0.184314\n",
       "200-5-1-True     0.814706  0.823529  0.043614\n",
       "200-10-1-True    0.799020  0.803922  0.083391\n",
       "200-25-1-True    0.749020  0.764706  0.115769\n",
       "200-25-5-True    0.843137  0.833333  0.045565\n",
       "5000-5-1-True    0.840196  0.843137  0.038361\n",
       "50-10-10-True    0.850980  0.843137  0.041779\n",
       "50-25-25-True    0.850980  0.862745  0.035294\n",
       "100-10-10-True   0.850980  0.843137  0.037409\n",
       "100-25-25-True   0.847059  0.843137  0.031979\n",
       "200-1-5-True     0.539216  0.509804  0.109084\n",
       "200-1-10-True    0.574510  0.529412  0.132712\n",
       "200-1-25-True    0.541176  0.509804  0.131738\n",
       "200-5-25-True    0.870588  0.862745  0.032457\n",
       "100-10-10-True   0.847059  0.833333  0.043669\n",
       "100-25-25-True   0.845098  0.843137  0.035565\n",
       "200-10-10-True   0.851961  0.862745  0.034230\n",
       "200-25-25-True   0.857843  0.872549  0.040124\n",
       "200-50-50-True   0.852941  0.843137  0.037970\n",
       "500-10-10-True   0.852941  0.843137  0.035888"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/src/arch.py:190: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.last_act(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: 2-2-8: 0.765 (0.882)\n",
      "-1: 2-3-8: 0.745 (0.804)\n",
      "-1: 2-2-16: 0.824 (0.882)\n",
      "-1: 2-3-16: 0.647 (0.804)\n",
      "-1: 3-2-16: 0.824 (0.882)\n",
      "-1: 4-2-16: 0.804 (0.863)\n",
      "-1: 3-3-16: 0.804 (0.824)\n",
      "-1: 2-2-32: 0.824 (0.863)\n",
      "-1: 2-2-64: 0.824 (0.843)\n",
      "-1: 2-2-128: 0.824 (0.882)\n",
      "-1: 2-2-256: 0.784 (0.824)\n",
      "-1: 2-3-32: 0.804 (0.824)\n",
      "-1: 2-3-50: 0.804 (0.843)\n",
      "-1: 2-3-75: 0.804 (0.863)\n",
      "-1: 2-3-100: 0.784 (0.824)\n",
      "-1: 3-2-32: 0.784 (0.882)\n",
      "-1: 3-2-50: 0.804 (0.863)\n",
      "-1: 3-3-50: 0.784 (0.863)\n",
      "-2: 2-2-8: 0.922 (0.922)\n",
      "-2: 2-3-8: 0.863 (0.902)\n",
      "-2: 2-2-16: 0.882 (0.922)\n",
      "-2: 2-3-16: 0.882 (0.902)\n",
      "-2: 3-2-16: 0.882 (0.922)\n",
      "-2: 4-2-16: 0.882 (0.922)\n",
      "-2: 3-3-16: 0.863 (0.882)\n",
      "-2: 2-2-32: 0.843 (0.922)\n",
      "-2: 2-2-64: 0.882 (0.902)\n",
      "-2: 2-2-128: 0.843 (0.922)\n",
      "-2: 2-2-256: 0.843 (0.922)\n",
      "-2: 2-3-32: 0.863 (0.902)\n",
      "-2: 2-3-50: 0.902 (0.922)\n",
      "-2: 2-3-75: 0.882 (0.882)\n",
      "-2: 2-3-100: 0.902 (0.922)\n",
      "-2: 3-2-32: 0.863 (0.922)\n",
      "-2: 3-2-50: 0.804 (0.922)\n",
      "-2: 3-3-50: 0.843 (0.882)\n",
      "-3: 2-2-8: 0.843 (0.882)\n",
      "-3: 2-3-8: 0.765 (0.804)\n",
      "-3: 2-2-16: 0.863 (0.922)\n",
      "-3: 2-3-16: 0.902 (0.941)\n",
      "-3: 3-2-16: 0.882 (0.922)\n",
      "-3: 4-2-16: 0.882 (0.882)\n",
      "-3: 3-3-16: 0.647 (0.784)\n",
      "-3: 2-2-32: 0.843 (0.922)\n",
      "-3: 2-2-64: 0.902 (0.922)\n",
      "-3: 2-2-128: 0.863 (0.922)\n",
      "-3: 2-2-256: 0.882 (0.902)\n",
      "-3: 2-3-32: 0.882 (0.922)\n",
      "-3: 2-3-50: 0.882 (0.922)\n",
      "-3: 2-3-75: 0.824 (0.824)\n",
      "-3: 2-3-100: 0.745 (0.863)\n",
      "-3: 3-2-32: 0.882 (0.941)\n",
      "-3: 3-2-50: 0.843 (0.941)\n",
      "-3: 3-3-50: 0.745 (0.824)\n",
      "-4: 2-2-8: 0.804 (0.882)\n",
      "-4: 2-3-8: 0.843 (0.843)\n",
      "-4: 2-2-16: 0.882 (0.922)\n",
      "-4: 2-3-16: 0.843 (0.882)\n",
      "-4: 3-2-16: 0.882 (0.922)\n",
      "-4: 4-2-16: 0.882 (0.902)\n",
      "-4: 3-3-16: 0.902 (0.922)\n",
      "-4: 2-2-32: 0.882 (0.941)\n",
      "-4: 2-2-64: 0.863 (0.961)\n",
      "-4: 2-2-128: 0.902 (0.941)\n",
      "-4: 2-2-256: 0.922 (0.941)\n",
      "-4: 2-3-32: 0.902 (0.941)\n",
      "-4: 2-3-50: 0.922 (0.922)\n",
      "-4: 2-3-75: 0.863 (0.882)\n",
      "-4: 2-3-100: 0.725 (0.863)\n",
      "-4: 3-2-32: 0.863 (0.922)\n",
      "-4: 3-2-50: 0.784 (0.922)\n",
      "-4: 3-3-50: 0.922 (0.961)\n",
      "-5: 2-2-8: 0.824 (0.941)\n",
      "-5: 2-3-8: 0.608 (0.686)\n",
      "-5: 2-2-16: 0.824 (0.902)\n",
      "-5: 2-3-16: 0.784 (0.922)\n",
      "-5: 3-2-16: 0.882 (0.902)\n",
      "-5: 4-2-16: 0.843 (0.902)\n",
      "-5: 3-3-16: 0.824 (0.902)\n",
      "-5: 2-2-32: 0.882 (0.922)\n",
      "-5: 2-2-64: 0.843 (0.922)\n",
      "-5: 2-2-128: 0.843 (0.941)\n",
      "-5: 2-2-256: 0.863 (0.922)\n",
      "-5: 2-3-32: 0.882 (0.902)\n",
      "-5: 2-3-50: 0.784 (0.922)\n",
      "-5: 2-3-75: 0.706 (0.725)\n",
      "-5: 2-3-100: 0.725 (0.882)\n",
      "-5: 3-2-32: 0.882 (0.922)\n",
      "-5: 3-2-50: 0.824 (0.922)\n",
      "-5: 3-3-50: 0.784 (0.882)\n",
      "-6: 2-2-8: 0.824 (0.863)\n",
      "-6: 2-3-8: 0.784 (0.804)\n",
      "-6: 2-2-16: 0.804 (0.863)\n",
      "-6: 2-3-16: 0.784 (0.843)\n",
      "-6: 3-2-16: 0.765 (0.882)\n",
      "-6: 4-2-16: 0.824 (0.863)\n",
      "-6: 3-3-16: 0.784 (0.824)\n",
      "-6: 2-2-32: 0.804 (0.882)\n",
      "-6: 2-2-64: 0.863 (0.902)\n",
      "-6: 2-2-128: 0.843 (0.882)\n",
      "-6: 2-2-256: 0.863 (0.902)\n",
      "-6: 2-3-32: 0.706 (0.784)\n",
      "-6: 2-3-50: 0.843 (0.882)\n",
      "-6: 2-3-75: 0.824 (0.882)\n",
      "-6: 2-3-100: 0.784 (0.882)\n",
      "-6: 3-2-32: 0.824 (0.882)\n",
      "-6: 3-2-50: 0.882 (0.902)\n",
      "-6: 3-3-50: 0.882 (0.902)\n",
      "-7: 2-2-8: 0.863 (0.882)\n",
      "-7: 2-3-8: 0.824 (0.882)\n",
      "-7: 2-2-16: 0.843 (0.902)\n",
      "-7: 2-3-16: 0.863 (0.882)\n",
      "-7: 3-2-16: 0.843 (0.902)\n",
      "-7: 4-2-16: 0.863 (0.922)\n",
      "-7: 3-3-16: 0.922 (0.922)\n",
      "-7: 2-2-32: 0.804 (0.882)\n",
      "-7: 2-2-64: 0.863 (0.882)\n",
      "-7: 2-2-128: 0.804 (0.882)\n",
      "-7: 2-2-256: 0.843 (0.882)\n",
      "-7: 2-3-32: 0.804 (0.882)\n",
      "-7: 2-3-50: 0.882 (0.882)\n",
      "-7: 2-3-75: 0.882 (0.902)\n",
      "-7: 2-3-100: 0.804 (0.843)\n",
      "-7: 3-2-32: 0.843 (0.902)\n",
      "-7: 3-2-50: 0.863 (0.902)\n",
      "-7: 3-3-50: 0.745 (0.843)\n",
      "-8: 2-2-8: 0.804 (0.824)\n",
      "-8: 2-3-8: 0.745 (0.765)\n",
      "-8: 2-2-16: 0.824 (0.863)\n",
      "-8: 2-3-16: 0.765 (0.843)\n",
      "-8: 3-2-16: 0.863 (0.863)\n",
      "-8: 4-2-16: 0.824 (0.863)\n",
      "-8: 3-3-16: 0.725 (0.804)\n",
      "-8: 2-2-32: 0.804 (0.843)\n",
      "-8: 2-2-64: 0.824 (0.902)\n",
      "-8: 2-2-128: 0.843 (0.863)\n",
      "-8: 2-2-256: 0.804 (0.843)\n",
      "-8: 2-3-32: 0.804 (0.843)\n",
      "-8: 2-3-50: 0.804 (0.882)\n",
      "-8: 2-3-75: 0.824 (0.843)\n",
      "-8: 2-3-100: 0.824 (0.843)\n",
      "-8: 3-2-32: 0.824 (0.843)\n",
      "-8: 3-2-50: 0.824 (0.882)\n",
      "-8: 3-3-50: 0.824 (0.882)\n",
      "-9: 2-2-8: 0.843 (0.882)\n",
      "-9: 2-3-8: 0.804 (0.863)\n",
      "-9: 2-2-16: 0.804 (0.882)\n",
      "-9: 2-3-16: 0.804 (0.863)\n",
      "-9: 3-2-16: 0.843 (0.882)\n",
      "-9: 4-2-16: 0.784 (0.882)\n",
      "-9: 3-3-16: 0.824 (0.843)\n",
      "-9: 2-2-32: 0.843 (0.882)\n",
      "-9: 2-2-64: 0.824 (0.882)\n",
      "-9: 2-2-128: 0.784 (0.863)\n",
      "-9: 2-2-256: 0.863 (0.863)\n",
      "-9: 2-3-32: 0.824 (0.843)\n",
      "-9: 2-3-50: 0.843 (0.863)\n",
      "-9: 2-3-75: 0.843 (0.843)\n",
      "-9: 2-3-100: 0.824 (0.843)\n",
      "-9: 3-2-32: 0.824 (0.882)\n",
      "-9: 3-2-50: 0.824 (0.863)\n",
      "-9: 3-3-50: 0.863 (0.882)\n",
      "-10: 2-2-8: 0.902 (0.902)\n",
      "-10: 2-3-8: 0.863 (0.863)\n",
      "-10: 2-2-16: 0.824 (0.922)\n",
      "-10: 2-3-16: 0.824 (0.882)\n",
      "-10: 3-2-16: 0.863 (0.902)\n",
      "-10: 4-2-16: 0.824 (0.902)\n",
      "-10: 3-3-16: 0.843 (0.863)\n",
      "-10: 2-2-32: 0.863 (0.941)\n",
      "-10: 2-2-64: 0.882 (0.922)\n",
      "-10: 2-2-128: 0.882 (0.922)\n",
      "-10: 2-2-256: 0.824 (0.922)\n",
      "-10: 2-3-32: 0.843 (0.902)\n",
      "-10: 2-3-50: 0.863 (0.902)\n",
      "-10: 2-3-75: 0.824 (0.882)\n",
      "-10: 2-3-100: 0.824 (0.902)\n",
      "-10: 3-2-32: 0.882 (0.922)\n",
      "-10: 3-2-50: 0.922 (0.922)\n",
      "-10: 3-3-50: 0.765 (0.843)\n",
      "-11: 2-2-8: 0.784 (0.824)\n",
      "-11: 2-3-8: 0.784 (0.843)\n",
      "-11: 2-2-16: 0.824 (0.882)\n",
      "-11: 2-3-16: 0.804 (0.863)\n",
      "-11: 3-2-16: 0.784 (0.882)\n",
      "-11: 4-2-16: 0.824 (0.843)\n",
      "-11: 3-3-16: 0.784 (0.843)\n",
      "-11: 2-2-32: 0.863 (0.882)\n",
      "-11: 2-2-64: 0.824 (0.863)\n",
      "-11: 2-2-128: 0.863 (0.863)\n",
      "-11: 2-2-256: 0.765 (0.843)\n",
      "-11: 2-3-32: 0.843 (0.843)\n",
      "-11: 2-3-50: 0.804 (0.824)\n",
      "-11: 2-3-75: 0.686 (0.784)\n",
      "-11: 2-3-100: 0.667 (0.824)\n",
      "-11: 3-2-32: 0.804 (0.863)\n",
      "-11: 3-2-50: 0.824 (0.843)\n",
      "-11: 3-3-50: 0.725 (0.765)\n",
      "-12: 2-2-8: 0.902 (0.941)\n",
      "-12: 2-3-8: 0.902 (0.922)\n",
      "-12: 2-2-16: 0.902 (0.941)\n",
      "-12: 2-3-16: 0.843 (0.922)\n",
      "-12: 3-2-16: 0.902 (0.922)\n",
      "-12: 4-2-16: 0.882 (0.941)\n",
      "-12: 3-3-16: 0.863 (0.922)\n",
      "-12: 2-2-32: 0.863 (0.922)\n",
      "-12: 2-2-64: 0.863 (0.922)\n",
      "-12: 2-2-128: 0.804 (0.922)\n",
      "-12: 2-2-256: 0.902 (0.941)\n",
      "-12: 2-3-32: 0.863 (0.922)\n",
      "-12: 2-3-50: 0.863 (0.922)\n",
      "-12: 2-3-75: 0.843 (0.961)\n",
      "-12: 2-3-100: 0.863 (0.882)\n",
      "-12: 3-2-32: 0.863 (0.922)\n",
      "-12: 3-2-50: 0.863 (0.922)\n",
      "-12: 3-3-50: 0.882 (0.941)\n",
      "-13: 2-2-8: 0.843 (0.882)\n",
      "-13: 2-3-8: 0.804 (0.882)\n",
      "-13: 2-2-16: 0.922 (0.941)\n",
      "-13: 2-3-16: 0.882 (0.902)\n",
      "-13: 3-2-16: 0.882 (0.922)\n",
      "-13: 4-2-16: 0.882 (0.902)\n",
      "-13: 3-3-16: 0.882 (0.922)\n",
      "-13: 2-2-32: 0.863 (0.922)\n",
      "-13: 2-2-64: 0.922 (0.922)\n",
      "-13: 2-2-128: 0.882 (0.922)\n",
      "-13: 2-2-256: 0.902 (0.922)\n",
      "-13: 2-3-32: 0.804 (0.882)\n",
      "-13: 2-3-50: 0.882 (0.922)\n",
      "-13: 2-3-75: 0.843 (0.902)\n",
      "-13: 2-3-100: 0.882 (0.922)\n",
      "-13: 3-2-32: 0.863 (0.922)\n",
      "-13: 3-2-50: 0.882 (0.941)\n",
      "-13: 3-3-50: 0.765 (0.804)\n",
      "-14: 2-2-8: 0.843 (0.922)\n",
      "-14: 2-3-8: 0.824 (0.961)\n",
      "-14: 2-2-16: 0.902 (0.922)\n",
      "-14: 2-3-16: 0.843 (0.922)\n",
      "-14: 3-2-16: 0.863 (0.882)\n",
      "-14: 4-2-16: 0.824 (0.922)\n",
      "-14: 3-3-16: 0.922 (0.961)\n",
      "-14: 2-2-32: 0.882 (0.941)\n",
      "-14: 2-2-64: 0.902 (0.941)\n",
      "-14: 2-2-128: 0.922 (0.941)\n",
      "-14: 2-2-256: 0.824 (0.941)\n",
      "-14: 2-3-32: 0.863 (0.961)\n",
      "-14: 2-3-50: 0.941 (0.961)\n",
      "-14: 2-3-75: 0.882 (0.941)\n",
      "-14: 2-3-100: 0.941 (0.961)\n",
      "-14: 3-2-32: 0.882 (0.941)\n",
      "-14: 3-2-50: 0.882 (0.941)\n",
      "-14: 3-3-50: 0.686 (0.765)\n",
      "-15: 2-2-8: 0.824 (0.902)\n",
      "-15: 2-3-8: 0.529 (0.843)\n",
      "-15: 2-2-16: 0.882 (0.922)\n",
      "-15: 2-3-16: 0.843 (0.902)\n",
      "-15: 3-2-16: 0.804 (0.882)\n",
      "-15: 4-2-16: 0.863 (0.922)\n",
      "-15: 3-3-16: 0.863 (0.882)\n",
      "-15: 2-2-32: 0.863 (0.941)\n",
      "-15: 2-2-64: 0.804 (0.922)\n",
      "-15: 2-2-128: 0.843 (0.902)\n",
      "-15: 2-2-256: 0.843 (0.922)\n",
      "-15: 2-3-32: 0.784 (0.843)\n",
      "-15: 2-3-50: 0.863 (0.902)\n",
      "-15: 2-3-75: 0.882 (0.922)\n",
      "-15: 2-3-100: 0.745 (0.902)\n",
      "-15: 3-2-32: 0.863 (0.922)\n",
      "-15: 3-2-50: 0.843 (0.941)\n",
      "-15: 3-3-50: 0.627 (0.784)\n",
      "-16: 2-2-8: 0.765 (0.824)\n",
      "-16: 2-3-8: 0.804 (0.824)\n",
      "-16: 2-2-16: 0.804 (0.902)\n",
      "-16: 2-3-16: 0.804 (0.882)\n",
      "-16: 3-2-16: 0.804 (0.843)\n",
      "-16: 4-2-16: 0.765 (0.843)\n",
      "-16: 3-3-16: 0.804 (0.824)\n",
      "-16: 2-2-32: 0.843 (0.902)\n",
      "-16: 2-2-64: 0.863 (0.902)\n",
      "-16: 2-2-128: 0.843 (0.863)\n",
      "-16: 2-2-256: 0.843 (0.863)\n",
      "-16: 2-3-32: 0.843 (0.863)\n",
      "-16: 2-3-50: 0.784 (0.902)\n",
      "-16: 2-3-75: 0.863 (0.882)\n",
      "-16: 2-3-100: 0.804 (0.902)\n",
      "-16: 3-2-32: 0.843 (0.902)\n",
      "-16: 3-2-50: 0.843 (0.902)\n",
      "-16: 3-3-50: 0.784 (0.882)\n",
      "-17: 2-2-8: 0.863 (0.902)\n",
      "-17: 2-3-8: 0.765 (0.902)\n",
      "-17: 2-2-16: 0.843 (0.882)\n",
      "-17: 2-3-16: 0.784 (0.843)\n",
      "-17: 3-2-16: 0.863 (0.902)\n",
      "-17: 4-2-16: 0.882 (0.902)\n",
      "-17: 3-3-16: 0.863 (0.902)\n",
      "-17: 2-2-32: 0.824 (0.882)\n",
      "-17: 2-2-64: 0.843 (0.902)\n",
      "-17: 2-2-128: 0.863 (0.902)\n",
      "-17: 2-2-256: 0.843 (0.882)\n",
      "-17: 2-3-32: 0.882 (0.882)\n",
      "-17: 2-3-50: 0.843 (0.882)\n",
      "-17: 2-3-75: 0.824 (0.902)\n",
      "-17: 2-3-100: 0.863 (0.902)\n",
      "-17: 3-2-32: 0.882 (0.902)\n",
      "-17: 3-2-50: 0.863 (0.902)\n",
      "-17: 3-3-50: 0.843 (0.902)\n",
      "-18: 2-2-8: 0.882 (0.882)\n",
      "-18: 2-3-8: 0.745 (0.804)\n",
      "-18: 2-2-16: 0.843 (0.863)\n",
      "-18: 2-3-16: 0.843 (0.902)\n",
      "-18: 3-2-16: 0.804 (0.882)\n",
      "-18: 4-2-16: 0.824 (0.902)\n",
      "-18: 3-3-16: 0.804 (0.843)\n",
      "-18: 2-2-32: 0.824 (0.863)\n",
      "-18: 2-2-64: 0.824 (0.882)\n",
      "-18: 2-2-128: 0.824 (0.863)\n",
      "-18: 2-2-256: 0.804 (0.863)\n",
      "-18: 2-3-32: 0.824 (0.882)\n",
      "-18: 2-3-50: 0.765 (0.804)\n",
      "-18: 2-3-75: 0.843 (0.843)\n",
      "-18: 2-3-100: 0.824 (0.843)\n",
      "-18: 3-2-32: 0.843 (0.902)\n",
      "-18: 3-2-50: 0.804 (0.882)\n",
      "-18: 3-3-50: 0.725 (0.824)\n",
      "-19: 2-2-8: 0.804 (0.882)\n",
      "-19: 2-3-8: 0.804 (0.804)\n",
      "-19: 2-2-16: 0.824 (0.882)\n",
      "-19: 2-3-16: 0.804 (0.863)\n",
      "-19: 3-2-16: 0.824 (0.863)\n",
      "-19: 4-2-16: 0.804 (0.863)\n",
      "-19: 3-3-16: 0.843 (0.843)\n",
      "-19: 2-2-32: 0.843 (0.882)\n",
      "-19: 2-2-64: 0.824 (0.882)\n",
      "-19: 2-2-128: 0.824 (0.863)\n",
      "-19: 2-2-256: 0.804 (0.882)\n",
      "-19: 2-3-32: 0.843 (0.843)\n",
      "-19: 2-3-50: 0.824 (0.863)\n",
      "-19: 2-3-75: 0.804 (0.863)\n",
      "-19: 2-3-100: 0.784 (0.824)\n",
      "-19: 3-2-32: 0.824 (0.882)\n",
      "-19: 3-2-50: 0.824 (0.863)\n",
      "-19: 3-3-50: 0.745 (0.784)\n",
      "-20: 2-2-8: 0.941 (0.941)\n",
      "-20: 2-3-8: 0.784 (0.824)\n",
      "-20: 2-2-16: 0.824 (0.882)\n",
      "-20: 2-3-16: 0.863 (0.882)\n",
      "-20: 3-2-16: 0.863 (0.902)\n",
      "-20: 4-2-16: 0.804 (0.882)\n",
      "-20: 3-3-16: 0.843 (0.882)\n",
      "-20: 2-2-32: 0.922 (0.922)\n",
      "-20: 2-2-64: 0.922 (0.922)\n",
      "-20: 2-2-128: 0.902 (0.902)\n",
      "-20: 2-2-256: 0.882 (0.902)\n",
      "-20: 2-3-32: 0.804 (0.863)\n",
      "-20: 2-3-50: 0.843 (0.902)\n",
      "-20: 2-3-75: 0.824 (0.882)\n",
      "-20: 2-3-100: 0.824 (0.882)\n",
      "-20: 3-2-32: 0.863 (0.922)\n",
      "-20: 3-2-50: 0.882 (0.922)\n",
      "-20: 3-3-50: 0.824 (0.863)\n",
      "----- 172.71 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'L': 2, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 16},\n",
    "        # {'L': 2, 'K': 4, 'hid_dim': 16},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 4, 'K': 2, 'hid_dim': 16},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 16},\n",
    "        # {'L': 4, 'K': 3, 'hid_dim': 16},\n",
    "\n",
    "        # {'L': 2, 'K': 2, 'hid_dim': 8},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 64},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 128},\n",
    "        {'L': 2, 'K': 2, 'hid_dim': 256},\n",
    "\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 32},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 50},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 75},\n",
    "        {'L': 2, 'K': 3, 'hid_dim': 100},\n",
    "\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 32},\n",
    "        {'L': 3, 'K': 2, 'hid_dim': 50},\n",
    "        {'L': 3, 'K': 3, 'hid_dim': 50},\n",
    "        ]\n",
    "\n",
    "best_accs3 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs3 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device, idx=i%10)\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN_Spows(IN_DIM, exp['hid_dim'], OUT_DIM, exp['L'], exp['K'], act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=NORM, dev=device)\n",
    "        S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  exp['K'], masks, LOSS_FN, device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD, epochs_h=EPOCHS_h, epochs_W=EPOCHS_W)\n",
    "\n",
    "        best_accs3[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs3[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}: {best_val_accs3[j,i]:.3f} ({best_accs3[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"L\"]}-{exp[\"K\"]}-{exp[\"hid_dim\"]}' for exp in EXPS]\n",
    "table_over3 = summary_table(best_accs3, index_name)\n",
    "table3 = summary_table(best_val_accs3, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2-2-8</th>\n",
       "      <td>0.842157</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.048219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-8</th>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.082230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-16</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.035403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-16</th>\n",
       "      <td>0.820588</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.054153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-16</th>\n",
       "      <td>0.846078</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.037345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2-16</th>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.036089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-16</th>\n",
       "      <td>0.830392</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.063317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-32</th>\n",
       "      <td>0.849020</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.029801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-64</th>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.034453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-128</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.034676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2-256</th>\n",
       "      <td>0.845098</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.040136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-32</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.043625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-50</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.046235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-75</th>\n",
       "      <td>0.828431</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.050706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-3-100</th>\n",
       "      <td>0.806863</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.064221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-32</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.027920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2-50</th>\n",
       "      <td>0.844118</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.034230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-3-50</th>\n",
       "      <td>0.788235</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.070860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean accs       med       std\n",
       "2-2-8     0.842157  0.843137  0.048219\n",
       "2-3-8     0.779412  0.794118  0.082230\n",
       "2-2-16    0.847059  0.833333  0.035403\n",
       "2-3-16    0.820588  0.833333  0.054153\n",
       "3-2-16    0.846078  0.862745  0.037345\n",
       "4-2-16    0.838235  0.823529  0.036089\n",
       "3-3-16    0.830392  0.843137  0.063317\n",
       "2-2-32    0.849020  0.843137  0.029801\n",
       "2-2-64    0.857843  0.862745  0.034453\n",
       "2-2-128   0.850000  0.843137  0.034676\n",
       "2-2-256   0.845098  0.843137  0.040136\n",
       "2-3-32    0.833333  0.843137  0.043625\n",
       "2-3-50    0.847059  0.843137  0.046235\n",
       "2-3-75    0.828431  0.833333  0.050706\n",
       "2-3-100   0.806863  0.813725  0.064221\n",
       "3-2-32    0.850000  0.862745  0.027920\n",
       "3-2-50    0.844118  0.843137  0.034230\n",
       "3-3-50    0.788235  0.784314  0.070860"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearities and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.863)\n",
      "-1: ReLU()-Softmax(dim=1)-NLLLoss(): 0.784 (0.863)\n",
      "-1: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.824 (0.882)\n",
      "-1: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.824 (0.882)\n",
      "-1: ReLU()-Identity()-CrossEntropyLoss(): 0.784 (0.863)\n",
      "-1: ReLU()-Identity()-NLLLoss(): 0.529 (0.529)\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.765 (0.863)\n",
      "-1: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.784 (0.863)\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.765 (0.863)\n",
      "-1: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.804 (0.882)\n",
      "-1: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.843)\n",
      "-1: Identity()-Softmax(dim=1)-NLLLoss(): 0.784 (0.843)\n",
      "-1: Identity()-Identity()-CrossEntropyLoss(): 0.725 (0.824)\n",
      "-2: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.941)\n",
      "-2: ReLU()-Softmax(dim=1)-NLLLoss(): 0.843 (0.922)\n",
      "-2: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-2: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.882 (0.922)\n",
      "-2: ReLU()-Identity()-CrossEntropyLoss(): 0.843 (0.941)\n",
      "-2: ReLU()-Identity()-NLLLoss(): 0.627 (0.627)\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.902)\n",
      "-2: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.863 (0.922)\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-2: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.902 (0.922)\n",
      "-2: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.902 (0.922)\n",
      "-2: Identity()-Softmax(dim=1)-NLLLoss(): 0.804 (0.922)\n",
      "-2: Identity()-Identity()-CrossEntropyLoss(): 0.804 (0.902)\n",
      "-3: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.941)\n",
      "-3: ReLU()-Softmax(dim=1)-NLLLoss(): 0.863 (0.922)\n",
      "-3: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-3: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.863 (0.941)\n",
      "-3: ReLU()-Identity()-CrossEntropyLoss(): 0.882 (0.941)\n",
      "-3: ReLU()-Identity()-NLLLoss(): 0.412 (0.471)\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.922)\n",
      "-3: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.902 (0.922)\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.922)\n",
      "-3: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.882 (0.941)\n",
      "-3: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.902 (0.922)\n",
      "-3: Identity()-Softmax(dim=1)-NLLLoss(): 0.804 (0.922)\n",
      "-3: Identity()-Identity()-CrossEntropyLoss(): 0.882 (0.941)\n",
      "-4: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.941)\n",
      "-4: ReLU()-Softmax(dim=1)-NLLLoss(): 0.882 (0.961)\n",
      "-4: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.902 (0.980)\n",
      "-4: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.843 (0.941)\n",
      "-4: ReLU()-Identity()-CrossEntropyLoss(): 0.902 (0.941)\n",
      "-4: ReLU()-Identity()-NLLLoss(): 0.431 (0.529)\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.922 (0.941)\n",
      "-4: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.882 (0.941)\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.902 (0.941)\n",
      "-4: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.765 (0.941)\n",
      "-4: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.922)\n",
      "-4: Identity()-Softmax(dim=1)-NLLLoss(): 0.843 (0.922)\n",
      "-4: Identity()-Identity()-CrossEntropyLoss(): 0.863 (0.941)\n",
      "-5: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.941)\n",
      "-5: ReLU()-Softmax(dim=1)-NLLLoss(): 0.882 (0.941)\n",
      "-5: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.824 (0.922)\n",
      "-5: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.843 (0.922)\n",
      "-5: ReLU()-Identity()-CrossEntropyLoss(): 0.882 (0.922)\n",
      "-5: ReLU()-Identity()-NLLLoss(): 0.392 (0.392)\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.922)\n",
      "-5: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.804 (0.941)\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.941)\n",
      "-5: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.804 (0.882)\n",
      "-5: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.902)\n",
      "-5: Identity()-Softmax(dim=1)-NLLLoss(): 0.824 (0.902)\n",
      "-5: Identity()-Identity()-CrossEntropyLoss(): 0.804 (0.882)\n",
      "-6: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.902)\n",
      "-6: ReLU()-Softmax(dim=1)-NLLLoss(): 0.882 (0.902)\n",
      "-6: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.863 (0.902)\n",
      "-6: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.882 (0.922)\n",
      "-6: ReLU()-Identity()-CrossEntropyLoss(): 0.824 (0.902)\n",
      "-6: ReLU()-Identity()-NLLLoss(): 0.608 (0.608)\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.922)\n",
      "-6: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.843 (0.902)\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.882)\n",
      "-6: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.745 (0.843)\n",
      "-6: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.784 (0.843)\n",
      "-6: Identity()-Softmax(dim=1)-NLLLoss(): 0.745 (0.882)\n",
      "-6: Identity()-Identity()-CrossEntropyLoss(): 0.843 (0.863)\n",
      "-7: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.882)\n",
      "-7: ReLU()-Softmax(dim=1)-NLLLoss(): 0.784 (0.922)\n",
      "-7: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.843 (0.902)\n",
      "-7: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.902 (0.902)\n",
      "-7: ReLU()-Identity()-CrossEntropyLoss(): 0.863 (0.882)\n",
      "-7: ReLU()-Identity()-NLLLoss(): 0.294 (0.353)\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.882)\n",
      "-7: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.863 (0.922)\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.922)\n",
      "-7: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.863 (0.902)\n",
      "-7: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.882)\n",
      "-7: Identity()-Softmax(dim=1)-NLLLoss(): 0.843 (0.882)\n",
      "-7: Identity()-Identity()-CrossEntropyLoss(): 0.843 (0.902)\n",
      "-8: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.882)\n",
      "-8: ReLU()-Softmax(dim=1)-NLLLoss(): 0.843 (0.902)\n",
      "-8: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.824 (0.902)\n",
      "-8: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.882 (0.882)\n",
      "-8: ReLU()-Identity()-CrossEntropyLoss(): 0.824 (0.882)\n",
      "-8: ReLU()-Identity()-NLLLoss(): 0.510 (0.510)\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.863)\n",
      "-8: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.824 (0.863)\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.863)\n",
      "-8: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.804 (0.882)\n",
      "-8: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.882)\n",
      "-8: Identity()-Softmax(dim=1)-NLLLoss(): 0.784 (0.902)\n",
      "-8: Identity()-Identity()-CrossEntropyLoss(): 0.804 (0.824)\n",
      "-9: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.882)\n",
      "-9: ReLU()-Softmax(dim=1)-NLLLoss(): 0.804 (0.882)\n",
      "-9: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.824 (0.902)\n",
      "-9: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.804 (0.882)\n",
      "-9: ReLU()-Identity()-CrossEntropyLoss(): 0.863 (0.902)\n",
      "-9: ReLU()-Identity()-NLLLoss(): 0.471 (0.471)\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.882)\n",
      "-9: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.863 (0.882)\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.902)\n",
      "-9: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.843 (0.843)\n",
      "-9: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.863)\n",
      "-9: Identity()-Softmax(dim=1)-NLLLoss(): 0.843 (0.882)\n",
      "-9: Identity()-Identity()-CrossEntropyLoss(): 0.784 (0.843)\n",
      "-10: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.902 (0.922)\n",
      "-10: ReLU()-Softmax(dim=1)-NLLLoss(): 0.902 (0.922)\n",
      "-10: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.882 (0.902)\n",
      "-10: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.922 (0.941)\n",
      "-10: ReLU()-Identity()-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-10: ReLU()-Identity()-NLLLoss(): 0.451 (0.451)\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.902)\n",
      "-10: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.882 (0.941)\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.922)\n",
      "-10: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.824 (0.902)\n",
      "-10: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.902 (0.922)\n",
      "-10: Identity()-Softmax(dim=1)-NLLLoss(): 0.902 (0.902)\n",
      "-10: Identity()-Identity()-CrossEntropyLoss(): 0.843 (0.902)\n",
      "-11: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.863)\n",
      "-11: ReLU()-Softmax(dim=1)-NLLLoss(): 0.804 (0.863)\n",
      "-11: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.745 (0.843)\n",
      "-11: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.804 (0.863)\n",
      "-11: ReLU()-Identity()-CrossEntropyLoss(): 0.784 (0.863)\n",
      "-11: ReLU()-Identity()-NLLLoss(): 0.510 (0.510)\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.863)\n",
      "-11: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.843 (0.863)\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.863)\n",
      "-11: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.824 (0.843)\n",
      "-11: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.706 (0.863)\n",
      "-11: Identity()-Softmax(dim=1)-NLLLoss(): 0.824 (0.843)\n",
      "-11: Identity()-Identity()-CrossEntropyLoss(): 0.784 (0.824)\n",
      "-12: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-12: ReLU()-Softmax(dim=1)-NLLLoss(): 0.863 (0.922)\n",
      "-12: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-12: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.824 (0.922)\n",
      "-12: ReLU()-Identity()-CrossEntropyLoss(): 0.784 (0.922)\n",
      "-12: ReLU()-Identity()-NLLLoss(): 0.275 (0.627)\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.941)\n",
      "-12: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.902 (0.922)\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-12: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.843 (0.922)\n",
      "-12: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.902)\n",
      "-12: Identity()-Softmax(dim=1)-NLLLoss(): 0.902 (0.922)\n",
      "-12: Identity()-Identity()-CrossEntropyLoss(): 0.882 (0.922)\n",
      "-13: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-13: ReLU()-Softmax(dim=1)-NLLLoss(): 0.902 (0.922)\n",
      "-13: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.922 (0.941)\n",
      "-13: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.824 (0.922)\n",
      "-13: ReLU()-Identity()-CrossEntropyLoss(): 0.863 (0.941)\n",
      "-13: ReLU()-Identity()-NLLLoss(): 0.412 (0.412)\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.922)\n",
      "-13: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.843 (0.922)\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.941)\n",
      "-13: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.863 (0.922)\n",
      "-13: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.941)\n",
      "-13: Identity()-Softmax(dim=1)-NLLLoss(): 0.882 (0.922)\n",
      "-13: Identity()-Identity()-CrossEntropyLoss(): 0.863 (0.922)\n",
      "-14: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.941)\n",
      "-14: ReLU()-Softmax(dim=1)-NLLLoss(): 0.882 (0.941)\n",
      "-14: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.902 (0.961)\n",
      "-14: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.941 (0.961)\n",
      "-14: ReLU()-Identity()-CrossEntropyLoss(): 0.882 (0.961)\n",
      "-14: ReLU()-Identity()-NLLLoss(): 0.431 (0.431)\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.941)\n",
      "-14: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.882 (0.941)\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.902 (0.941)\n",
      "-14: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.922 (0.961)\n",
      "-14: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.941 (0.961)\n",
      "-14: Identity()-Softmax(dim=1)-NLLLoss(): 0.706 (0.863)\n",
      "-14: Identity()-Identity()-CrossEntropyLoss(): 0.961 (0.961)\n",
      "-15: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.902)\n",
      "-15: ReLU()-Softmax(dim=1)-NLLLoss(): 0.804 (0.941)\n",
      "-15: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.863 (0.922)\n",
      "-15: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.804 (0.941)\n",
      "-15: ReLU()-Identity()-CrossEntropyLoss(): 0.863 (0.902)\n",
      "-15: ReLU()-Identity()-NLLLoss(): 0.392 (0.392)\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.922)\n",
      "-15: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.843 (0.941)\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.941)\n",
      "-15: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.804 (0.941)\n",
      "-15: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.922)\n",
      "-15: Identity()-Softmax(dim=1)-NLLLoss(): 0.784 (0.961)\n",
      "-15: Identity()-Identity()-CrossEntropyLoss(): 0.902 (0.922)\n",
      "-16: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.902)\n",
      "-16: ReLU()-Softmax(dim=1)-NLLLoss(): 0.824 (0.902)\n",
      "-16: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.843 (0.902)\n",
      "-16: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.843 (0.902)\n",
      "-16: ReLU()-Identity()-CrossEntropyLoss(): 0.804 (0.902)\n",
      "-16: ReLU()-Identity()-NLLLoss(): 0.314 (0.353)\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.902)\n",
      "-16: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.863 (0.902)\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.765 (0.843)\n",
      "-16: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.824 (0.902)\n",
      "-16: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.922)\n",
      "-16: Identity()-Softmax(dim=1)-NLLLoss(): 0.843 (0.902)\n",
      "-16: Identity()-Identity()-CrossEntropyLoss(): 0.882 (0.882)\n",
      "-17: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.882)\n",
      "-17: ReLU()-Softmax(dim=1)-NLLLoss(): 0.882 (0.902)\n",
      "-17: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.843 (0.902)\n",
      "-17: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.863 (0.922)\n",
      "-17: ReLU()-Identity()-CrossEntropyLoss(): 0.863 (0.902)\n",
      "-17: ReLU()-Identity()-NLLLoss(): 0.471 (0.490)\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-17: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.882 (0.922)\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.902)\n",
      "-17: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.863 (0.922)\n",
      "-17: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-17: Identity()-Softmax(dim=1)-NLLLoss(): 0.804 (0.882)\n",
      "-17: Identity()-Identity()-CrossEntropyLoss(): 0.882 (0.882)\n",
      "-18: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.922)\n",
      "-18: ReLU()-Softmax(dim=1)-NLLLoss(): 0.824 (0.882)\n",
      "-18: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.804 (0.882)\n",
      "-18: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.863 (0.882)\n",
      "-18: ReLU()-Identity()-CrossEntropyLoss(): 0.863 (0.902)\n",
      "-18: ReLU()-Identity()-NLLLoss(): 0.431 (0.431)\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.882)\n",
      "-18: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.863 (0.863)\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.902)\n",
      "-18: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.824 (0.863)\n",
      "-18: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.863)\n",
      "-18: Identity()-Softmax(dim=1)-NLLLoss(): 0.784 (0.902)\n",
      "-18: Identity()-Identity()-CrossEntropyLoss(): 0.843 (0.902)\n",
      "-19: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.882)\n",
      "-19: ReLU()-Softmax(dim=1)-NLLLoss(): 0.824 (0.902)\n",
      "-19: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.843 (0.882)\n",
      "-19: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.804 (0.882)\n",
      "-19: ReLU()-Identity()-CrossEntropyLoss(): 0.843 (0.882)\n",
      "-19: ReLU()-Identity()-NLLLoss(): 0.451 (0.451)\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.863)\n",
      "-19: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.843 (0.863)\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.824 (0.882)\n",
      "-19: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.824 (0.882)\n",
      "-19: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.804 (0.843)\n",
      "-19: Identity()-Softmax(dim=1)-NLLLoss(): 0.784 (0.882)\n",
      "-19: Identity()-Identity()-CrossEntropyLoss(): 0.843 (0.863)\n",
      "-20: ReLU()-Softmax(dim=1)-CrossEntropyLoss(): 0.843 (0.922)\n",
      "-20: ReLU()-Softmax(dim=1)-NLLLoss(): 0.882 (0.922)\n",
      "-20: ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss(): 0.882 (0.922)\n",
      "-20: ReLU()-LogSoftmax(dim=1)-NLLLoss(): 0.863 (0.902)\n",
      "-20: ReLU()-Identity()-CrossEntropyLoss(): 0.902 (0.922)\n",
      "-20: ReLU()-Identity()-NLLLoss(): 0.392 (0.451)\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.922)\n",
      "-20: ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss(): 0.882 (0.922)\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss(): 0.882 (0.902)\n",
      "-20: LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss(): 0.843 (0.902)\n",
      "-20: Identity()-Softmax(dim=1)-CrossEntropyLoss(): 0.863 (0.902)\n",
      "-20: Identity()-Softmax(dim=1)-NLLLoss(): 0.863 (0.902)\n",
      "-20: Identity()-Identity()-CrossEntropyLoss(): 0.882 (0.922)\n",
      "----- 146.21 mins -----\n"
     ]
    }
   ],
   "source": [
    "# layers, filter order, weightd\n",
    "EXPS = [{'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.LogSoftmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ReLU(), 'lact': nn.Identity(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.ELU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.LeakyReLU(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.CrossEntropyLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Softmax(dim=1), 'loss': nn.NLLLoss()},\n",
    "        {'act': nn.Identity(), 'lact': nn.Identity(dim=1), 'loss': nn.CrossEntropyLoss()},]\n",
    "\n",
    "best_accs4 = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs4 = np.zeros((len(EXPS), N_RUNS))\n",
    "t_i = time.time()\n",
    "for i in range(N_RUNS):\n",
    "    A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device, idx=i%10)\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=exp['act'], last_act=exp['lact'],\n",
    "                           dropout=DROPOUT, norm=NORM, dev=device)\n",
    "        S = torch.Tensor(A).to(device)\n",
    "\n",
    "        model = GF_NodeClassModel(arch, S,  K, masks, exp['loss'], device=device)\n",
    "        _, acc = model.train(feat, labels, N_EPOCHS, LR, WD, epochs_h=EPOCHS_h, epochs_W=EPOCHS_W)\n",
    "\n",
    "        best_accs4[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs4[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'-{i+1}: {exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}: {best_val_accs4[j,i]:.3f} ({best_accs4[j,i]:.3f})')\n",
    "\n",
    "ellapsed_t = (time.time()-t_i)/60\n",
    "print(f'----- {ellapsed_t:.2f} mins -----')\n",
    "\n",
    "# Get table with results\n",
    "index_name = [f'{exp[\"act\"]}-{exp[\"lact\"]}-{exp[\"loss\"]}' for exp in EXPS]\n",
    "table_over4 = summary_table(best_accs4, index_name)\n",
    "table4 = summary_table(best_val_accs4, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.031173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.038160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.038160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-LogSoftmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.853922</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.038957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.848039</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.036089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU()-Identity()-NLLLoss()</th>\n",
       "      <td>0.440196</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.088447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.841176</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.036630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.029656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.849020</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.039265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.041363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-CrossEntropyLoss()</th>\n",
       "      <td>0.849020</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.049643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Softmax(dim=1)-NLLLoss()</th>\n",
       "      <td>0.817647</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.048467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Identity()-Identity()-CrossEntropyLoss()</th>\n",
       "      <td>0.846078</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.050478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean accs       med  \\\n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()             0.850000  0.843137   \n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                      0.848039  0.852941   \n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()          0.848039  0.843137   \n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                   0.853922  0.852941   \n",
       "ReLU()-Identity()-CrossEntropyLoss()                 0.848039  0.862745   \n",
       "ReLU()-Identity()-NLLLoss()                          0.440196  0.431373   \n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()     0.841176  0.843137   \n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()              0.857843  0.862745   \n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...   0.849020  0.843137   \n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...   0.833333  0.823529   \n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()         0.849020  0.852941   \n",
       "Identity()-Softmax(dim=1)-NLLLoss()                  0.817647  0.813725   \n",
       "Identity()-Identity()-CrossEntropyLoss()             0.846078  0.843137   \n",
       "\n",
       "                                                         std  \n",
       "ReLU()-Softmax(dim=1)-CrossEntropyLoss()            0.031173  \n",
       "ReLU()-Softmax(dim=1)-NLLLoss()                     0.038160  \n",
       "ReLU()-LogSoftmax(dim=1)-CrossEntropyLoss()         0.038160  \n",
       "ReLU()-LogSoftmax(dim=1)-NLLLoss()                  0.038957  \n",
       "ReLU()-Identity()-CrossEntropyLoss()                0.036089  \n",
       "ReLU()-Identity()-NLLLoss()                         0.088447  \n",
       "ELU(alpha=1.0)-Softmax(dim=1)-CrossEntropyLoss()    0.036630  \n",
       "ELU(alpha=1.0)-Softmax(dim=1)-NLLLoss()             0.029656  \n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-C...  0.039265  \n",
       "LeakyReLU(negative_slope=0.01)-Softmax(dim=1)-N...  0.041363  \n",
       "Identity()-Softmax(dim=1)-CrossEntropyLoss()        0.049643  \n",
       "Identity()-Softmax(dim=1)-NLLLoss()                 0.048467  \n",
       "Identity()-Identity()-CrossEntropyLoss()            0.050478  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPS = [\n",
    "        {'name': 'Kipf', 'norm': 'none'},\n",
    "        {'name': 'Kipf', 'norm': 'both'},\n",
    "\n",
    "        {'name': 'A-GCNN', 'norm': False},\n",
    "        {'name': 'A-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'H-GCNN', 'norm': False},\n",
    "        {'name': 'H-GCNN', 'norm': True},\n",
    "\n",
    "        {'name': 'W-GCN-A', 'norm': False},\n",
    "        {'name': 'W-GCN-A', 'norm': True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RUN: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/baselines_archs.py:65: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.last_act(h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKipf-none: acc = 0.549  -  acc2 = 0.569  -  acc (over) = 0.608\n",
      "\tKipf-both: acc = 0.608  -  acc2 = 0.569  -  acc (over) = 0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/src/arch.py:152: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.last_act(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tA-GCNN-False: acc = 0.843  -  acc2 = 0.863  -  acc (over) = 0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/gsp_utils/data.py:44: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  D_inv = np.diag(np.where(np.isclose(deg_vec, 0), 0, 1/deg_vec))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tA-GCNN-True: acc = 0.824  -  acc2 = 0.765  -  acc (over) = 0.882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srey/Investigacion/robust_minmax_gnn/src/arch.py:190: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.last_act(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tH-GCNN-False: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.882\n",
      "\tH-GCNN-True: acc = 0.784  -  acc2 = 0.804  -  acc (over) = 0.882\n",
      "\tW-GCN-A-False: acc = 0.706  -  acc2 = 0.706  -  acc (over) = 0.706\n",
      "\tW-GCN-A-True: acc = 0.765  -  acc2 = 0.745  -  acc (over) = 0.863\n",
      "- RUN: 2\n",
      "\tKipf-none: acc = 0.216  -  acc2 = 0.216  -  acc (over) = 0.294\n",
      "\tKipf-both: acc = 0.588  -  acc2 = 0.588  -  acc (over) = 0.608\n",
      "\tA-GCNN-False: acc = 0.863  -  acc2 = 0.863  -  acc (over) = 0.941\n",
      "\tA-GCNN-True: acc = 0.765  -  acc2 = 0.863  -  acc (over) = 0.902\n",
      "\tH-GCNN-False: acc = 0.843  -  acc2 = 0.902  -  acc (over) = 0.922\n",
      "\tH-GCNN-True: acc = 0.863  -  acc2 = 0.863  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.824  -  acc2 = 0.824  -  acc (over) = 0.863\n",
      "\tW-GCN-A-True: acc = 0.824  -  acc2 = 0.863  -  acc (over) = 0.902\n",
      "- RUN: 3\n",
      "\tKipf-none: acc = 0.490  -  acc2 = 0.529  -  acc (over) = 0.588\n",
      "\tKipf-both: acc = 0.608  -  acc2 = 0.529  -  acc (over) = 0.647\n",
      "\tA-GCNN-False: acc = 0.843  -  acc2 = 0.882  -  acc (over) = 0.922\n",
      "\tA-GCNN-True: acc = 0.882  -  acc2 = 0.824  -  acc (over) = 0.941\n",
      "\tH-GCNN-False: acc = 0.882  -  acc2 = 0.882  -  acc (over) = 0.922\n",
      "\tH-GCNN-True: acc = 0.882  -  acc2 = 0.882  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.725  -  acc2 = 0.686  -  acc (over) = 0.765\n",
      "\tW-GCN-A-True: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.882\n",
      "- RUN: 4\n",
      "\tKipf-none: acc = 0.608  -  acc2 = 0.608  -  acc (over) = 0.647\n",
      "\tKipf-both: acc = 0.549  -  acc2 = 0.451  -  acc (over) = 0.588\n",
      "\tA-GCNN-False: acc = 0.863  -  acc2 = 0.922  -  acc (over) = 0.961\n",
      "\tA-GCNN-True: acc = 0.843  -  acc2 = 0.922  -  acc (over) = 0.941\n",
      "\tH-GCNN-False: acc = 0.882  -  acc2 = 0.922  -  acc (over) = 0.941\n",
      "\tH-GCNN-True: acc = 0.882  -  acc2 = 0.882  -  acc (over) = 0.941\n",
      "\tW-GCN-A-False: acc = 0.745  -  acc2 = 0.745  -  acc (over) = 0.765\n",
      "\tW-GCN-A-True: acc = 0.784  -  acc2 = 0.765  -  acc (over) = 0.902\n",
      "- RUN: 5\n",
      "\tKipf-none: acc = 0.392  -  acc2 = 0.392  -  acc (over) = 0.392\n",
      "\tKipf-both: acc = 0.549  -  acc2 = 0.431  -  acc (over) = 0.647\n",
      "\tA-GCNN-False: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.922\n",
      "\tA-GCNN-True: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.941\n",
      "\tH-GCNN-False: acc = 0.863  -  acc2 = 0.804  -  acc (over) = 0.941\n",
      "\tH-GCNN-True: acc = 0.902  -  acc2 = 0.902  -  acc (over) = 0.941\n",
      "\tW-GCN-A-False: acc = 0.706  -  acc2 = 0.686  -  acc (over) = 0.765\n",
      "\tW-GCN-A-True: acc = 0.804  -  acc2 = 0.765  -  acc (over) = 0.882\n",
      "- RUN: 6\n",
      "\tKipf-none: acc = 0.529  -  acc2 = 0.529  -  acc (over) = 0.529\n",
      "\tKipf-both: acc = 0.529  -  acc2 = 0.490  -  acc (over) = 0.608\n",
      "\tA-GCNN-False: acc = 0.804  -  acc2 = 0.804  -  acc (over) = 0.902\n",
      "\tA-GCNN-True: acc = 0.824  -  acc2 = 0.824  -  acc (over) = 0.902\n",
      "\tH-GCNN-False: acc = 0.824  -  acc2 = 0.902  -  acc (over) = 0.922\n",
      "\tH-GCNN-True: acc = 0.745  -  acc2 = 0.824  -  acc (over) = 0.882\n",
      "\tW-GCN-A-False: acc = 0.647  -  acc2 = 0.647  -  acc (over) = 0.725\n",
      "\tW-GCN-A-True: acc = 0.804  -  acc2 = 0.765  -  acc (over) = 0.804\n",
      "- RUN: 7\n",
      "\tKipf-none: acc = 0.627  -  acc2 = 0.627  -  acc (over) = 0.667\n",
      "\tKipf-both: acc = 0.588  -  acc2 = 0.588  -  acc (over) = 0.667\n",
      "\tA-GCNN-False: acc = 0.824  -  acc2 = 0.863  -  acc (over) = 0.922\n",
      "\tA-GCNN-True: acc = 0.843  -  acc2 = 0.863  -  acc (over) = 0.922\n",
      "\tH-GCNN-False: acc = 0.863  -  acc2 = 0.863  -  acc (over) = 0.902\n",
      "\tH-GCNN-True: acc = 0.843  -  acc2 = 0.824  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.784  -  acc2 = 0.765  -  acc (over) = 0.863\n",
      "\tW-GCN-A-True: acc = 0.824  -  acc2 = 0.824  -  acc (over) = 0.843\n",
      "- RUN: 8\n",
      "\tKipf-none: acc = 0.608  -  acc2 = 0.608  -  acc (over) = 0.627\n",
      "\tKipf-both: acc = 0.627  -  acc2 = 0.667  -  acc (over) = 0.706\n",
      "\tA-GCNN-False: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.902\n",
      "\tA-GCNN-True: acc = 0.824  -  acc2 = 0.804  -  acc (over) = 0.902\n",
      "\tH-GCNN-False: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.902\n",
      "\tH-GCNN-True: acc = 0.824  -  acc2 = 0.863  -  acc (over) = 0.902\n",
      "\tW-GCN-A-False: acc = 0.765  -  acc2 = 0.765  -  acc (over) = 0.804\n",
      "\tW-GCN-A-True: acc = 0.804  -  acc2 = 0.824  -  acc (over) = 0.863\n",
      "- RUN: 9\n",
      "\tKipf-none: acc = 0.431  -  acc2 = 0.451  -  acc (over) = 0.451\n",
      "\tKipf-both: acc = 0.510  -  acc2 = 0.529  -  acc (over) = 0.588\n",
      "\tA-GCNN-False: acc = 0.804  -  acc2 = 0.804  -  acc (over) = 0.922\n",
      "\tA-GCNN-True: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.902\n",
      "\tH-GCNN-False: acc = 0.843  -  acc2 = 0.824  -  acc (over) = 0.902\n",
      "\tH-GCNN-True: acc = 0.824  -  acc2 = 0.824  -  acc (over) = 0.882\n",
      "\tW-GCN-A-False: acc = 0.706  -  acc2 = 0.706  -  acc (over) = 0.765\n",
      "\tW-GCN-A-True: acc = 0.765  -  acc2 = 0.765  -  acc (over) = 0.824\n",
      "- RUN: 10\n",
      "\tKipf-none: acc = 0.373  -  acc2 = 0.373  -  acc (over) = 0.373\n",
      "\tKipf-both: acc = 0.490  -  acc2 = 0.490  -  acc (over) = 0.569\n",
      "\tA-GCNN-False: acc = 0.902  -  acc2 = 0.902  -  acc (over) = 0.941\n",
      "\tA-GCNN-True: acc = 0.882  -  acc2 = 0.941  -  acc (over) = 0.941\n",
      "\tH-GCNN-False: acc = 0.922  -  acc2 = 0.902  -  acc (over) = 0.941\n",
      "\tH-GCNN-True: acc = 0.882  -  acc2 = 0.863  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.745  -  acc2 = 0.824  -  acc (over) = 0.843\n",
      "\tW-GCN-A-True: acc = 0.784  -  acc2 = 0.804  -  acc (over) = 0.882\n",
      "- RUN: 11\n",
      "\tKipf-none: acc = 0.569  -  acc2 = 0.569  -  acc (over) = 0.588\n",
      "\tKipf-both: acc = 0.608  -  acc2 = 0.569  -  acc (over) = 0.608\n",
      "\tA-GCNN-False: acc = 0.843  -  acc2 = 0.804  -  acc (over) = 0.882\n",
      "\tA-GCNN-True: acc = 0.804  -  acc2 = 0.804  -  acc (over) = 0.882\n",
      "\tH-GCNN-False: acc = 0.863  -  acc2 = 0.804  -  acc (over) = 0.882\n",
      "\tH-GCNN-True: acc = 0.824  -  acc2 = 0.804  -  acc (over) = 0.863\n",
      "\tW-GCN-A-False: acc = 0.686  -  acc2 = 0.667  -  acc (over) = 0.745\n",
      "\tW-GCN-A-True: acc = 0.784  -  acc2 = 0.745  -  acc (over) = 0.882\n",
      "- RUN: 12\n",
      "\tKipf-none: acc = 0.569  -  acc2 = 0.569  -  acc (over) = 0.627\n",
      "\tKipf-both: acc = 0.588  -  acc2 = 0.588  -  acc (over) = 0.686\n",
      "\tA-GCNN-False: acc = 0.902  -  acc2 = 0.765  -  acc (over) = 0.922\n",
      "\tA-GCNN-True: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.902\n",
      "\tH-GCNN-False: acc = 0.902  -  acc2 = 0.843  -  acc (over) = 0.922\n",
      "\tH-GCNN-True: acc = 0.863  -  acc2 = 0.863  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.804  -  acc2 = 0.863  -  acc (over) = 0.863\n",
      "\tW-GCN-A-True: acc = 0.863  -  acc2 = 0.902  -  acc (over) = 0.902\n",
      "- RUN: 13\n",
      "\tKipf-none: acc = 0.608  -  acc2 = 0.608  -  acc (over) = 0.608\n",
      "\tKipf-both: acc = 0.608  -  acc2 = 0.608  -  acc (over) = 0.647\n",
      "\tA-GCNN-False: acc = 0.882  -  acc2 = 0.902  -  acc (over) = 0.941\n",
      "\tA-GCNN-True: acc = 0.882  -  acc2 = 0.922  -  acc (over) = 0.922\n",
      "\tH-GCNN-False: acc = 0.922  -  acc2 = 0.922  -  acc (over) = 0.922\n",
      "\tH-GCNN-True: acc = 0.882  -  acc2 = 0.882  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.765  -  acc2 = 0.745  -  acc (over) = 0.804\n",
      "\tW-GCN-A-True: acc = 0.843  -  acc2 = 0.804  -  acc (over) = 0.882\n",
      "- RUN: 14\n",
      "\tKipf-none: acc = 0.471  -  acc2 = 0.471  -  acc (over) = 0.471\n",
      "\tKipf-both: acc = 0.529  -  acc2 = 0.529  -  acc (over) = 0.588\n",
      "\tA-GCNN-False: acc = 0.922  -  acc2 = 0.882  -  acc (over) = 0.961\n",
      "\tA-GCNN-True: acc = 0.863  -  acc2 = 0.863  -  acc (over) = 0.961\n",
      "\tH-GCNN-False: acc = 0.902  -  acc2 = 0.843  -  acc (over) = 0.961\n",
      "\tH-GCNN-True: acc = 0.902  -  acc2 = 0.902  -  acc (over) = 0.941\n",
      "\tW-GCN-A-False: acc = 0.784  -  acc2 = 0.784  -  acc (over) = 0.824\n",
      "\tW-GCN-A-True: acc = 0.765  -  acc2 = 0.824  -  acc (over) = 0.882\n",
      "- RUN: 15\n",
      "\tKipf-none: acc = 0.451  -  acc2 = 0.451  -  acc (over) = 0.451\n",
      "\tKipf-both: acc = 0.510  -  acc2 = 0.373  -  acc (over) = 0.588\n",
      "\tA-GCNN-False: acc = 0.882  -  acc2 = 0.843  -  acc (over) = 0.941\n",
      "\tA-GCNN-True: acc = 0.863  -  acc2 = 0.863  -  acc (over) = 0.941\n",
      "\tH-GCNN-False: acc = 0.882  -  acc2 = 0.882  -  acc (over) = 0.961\n",
      "\tH-GCNN-True: acc = 0.765  -  acc2 = 0.765  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.725  -  acc2 = 0.725  -  acc (over) = 0.745\n",
      "\tW-GCN-A-True: acc = 0.824  -  acc2 = 0.745  -  acc (over) = 0.922\n",
      "- RUN: 16\n",
      "\tKipf-none: acc = 0.529  -  acc2 = 0.529  -  acc (over) = 0.529\n",
      "\tKipf-both: acc = 0.569  -  acc2 = 0.647  -  acc (over) = 0.647\n",
      "\tA-GCNN-False: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.902\n",
      "\tA-GCNN-True: acc = 0.863  -  acc2 = 0.863  -  acc (over) = 0.922\n",
      "\tH-GCNN-False: acc = 0.902  -  acc2 = 0.882  -  acc (over) = 0.902\n",
      "\tH-GCNN-True: acc = 0.784  -  acc2 = 0.824  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.588  -  acc2 = 0.647  -  acc (over) = 0.706\n",
      "\tW-GCN-A-True: acc = 0.804  -  acc2 = 0.824  -  acc (over) = 0.843\n",
      "- RUN: 17\n",
      "\tKipf-none: acc = 0.588  -  acc2 = 0.588  -  acc (over) = 0.627\n",
      "\tKipf-both: acc = 0.569  -  acc2 = 0.608  -  acc (over) = 0.627\n",
      "\tA-GCNN-False: acc = 0.902  -  acc2 = 0.902  -  acc (over) = 0.922\n",
      "\tA-GCNN-True: acc = 0.902  -  acc2 = 0.863  -  acc (over) = 0.922\n",
      "\tH-GCNN-False: acc = 0.863  -  acc2 = 0.863  -  acc (over) = 0.922\n",
      "\tH-GCNN-True: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.765  -  acc2 = 0.667  -  acc (over) = 0.843\n",
      "\tW-GCN-A-True: acc = 0.824  -  acc2 = 0.843  -  acc (over) = 0.863\n",
      "- RUN: 18\n",
      "\tKipf-none: acc = 0.608  -  acc2 = 0.608  -  acc (over) = 0.706\n",
      "\tKipf-both: acc = 0.647  -  acc2 = 0.647  -  acc (over) = 0.706\n",
      "\tA-GCNN-False: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.902\n",
      "\tA-GCNN-True: acc = 0.824  -  acc2 = 0.804  -  acc (over) = 0.902\n",
      "\tH-GCNN-False: acc = 0.804  -  acc2 = 0.882  -  acc (over) = 0.902\n",
      "\tH-GCNN-True: acc = 0.843  -  acc2 = 0.843  -  acc (over) = 0.902\n",
      "\tW-GCN-A-False: acc = 0.725  -  acc2 = 0.725  -  acc (over) = 0.804\n",
      "\tW-GCN-A-True: acc = 0.784  -  acc2 = 0.824  -  acc (over) = 0.863\n",
      "- RUN: 19\n",
      "\tKipf-none: acc = 0.451  -  acc2 = 0.451  -  acc (over) = 0.451\n",
      "\tKipf-both: acc = 0.471  -  acc2 = 0.490  -  acc (over) = 0.588\n",
      "\tA-GCNN-False: acc = 0.804  -  acc2 = 0.824  -  acc (over) = 0.902\n",
      "\tA-GCNN-True: acc = 0.804  -  acc2 = 0.804  -  acc (over) = 0.882\n",
      "\tH-GCNN-False: acc = 0.824  -  acc2 = 0.784  -  acc (over) = 0.882\n",
      "\tH-GCNN-True: acc = 0.824  -  acc2 = 0.824  -  acc (over) = 0.882\n",
      "\tW-GCN-A-False: acc = 0.745  -  acc2 = 0.745  -  acc (over) = 0.765\n",
      "\tW-GCN-A-True: acc = 0.745  -  acc2 = 0.745  -  acc (over) = 0.843\n",
      "- RUN: 20\n",
      "\tKipf-none: acc = 0.549  -  acc2 = 0.549  -  acc (over) = 0.588\n",
      "\tKipf-both: acc = 0.549  -  acc2 = 0.510  -  acc (over) = 0.549\n",
      "\tA-GCNN-False: acc = 0.922  -  acc2 = 0.922  -  acc (over) = 0.922\n",
      "\tA-GCNN-True: acc = 0.922  -  acc2 = 0.882  -  acc (over) = 0.941\n",
      "\tH-GCNN-False: acc = 0.922  -  acc2 = 0.922  -  acc (over) = 0.941\n",
      "\tH-GCNN-True: acc = 0.922  -  acc2 = 0.922  -  acc (over) = 0.922\n",
      "\tW-GCN-A-False: acc = 0.784  -  acc2 = 0.784  -  acc (over) = 0.784\n",
      "\tW-GCN-A-True: acc = 0.882  -  acc2 = 0.882  -  acc (over) = 0.922\n"
     ]
    }
   ],
   "source": [
    "N_RUNS = 20\n",
    "\n",
    "best_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs = np.zeros((len(EXPS), N_RUNS))\n",
    "best_val_accs2 = np.zeros((len(EXPS), N_RUNS))\n",
    "for i in range(N_RUNS):\n",
    "    A, feat, labels, n_class, masks = utils.get_data_dgl(dataset_name, dev=device, idx=i%10)\n",
    "    print(f'- RUN: {i+1}')\n",
    "    for j, exp in enumerate(EXPS):\n",
    "        # t_i = time.time()\n",
    "        if exp['name'] == 'Kipf':\n",
    "            arch = GCNN_2L(IN_DIM, HID_DIM, OUT_DIM, act=ACT, last_act=LAST_ACT,\n",
    "                           dropout=DROPOUT, norm=exp['norm'])\n",
    "            S = dgl.from_networkx(nx.from_numpy_array(A)).add_self_loop().to(device)\n",
    "            \n",
    "        elif exp['name'] == 'A-GCNN':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "            dropout=DROPOUT, diff_layer=GFGCNLayer, init_h0=1)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'H-GCNN':\n",
    "            arch = GFGCN_Spows(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                               dropout=DROPOUT, norm=exp['norm'], dev=device)\n",
    "            S = torch.Tensor(A).to(device)\n",
    "\n",
    "        elif exp['name'] == 'W-GCN-A':\n",
    "            arch = GFGCN(IN_DIM, HID_DIM, OUT_DIM, N_LAYERS, K, act=ACT, last_act=LAST_ACT,\n",
    "                         dropout=DROPOUT, diff_layer=GFGCN_noh_Layer)\n",
    "            if exp['norm']:\n",
    "                S = torch.Tensor(normalize_gso(A, 'both')).to(device)\n",
    "            else:\n",
    "                S = torch.Tensor(A).to(device)  \n",
    "            \n",
    "        else:\n",
    "            raise Exception(f'ERROR: Unknown architecture: {exp[\"name\"]}')\n",
    "\n",
    "        if exp['name'] in ['Kipf', 'W-GCN-A']:\n",
    "            model = NodeClassModel(arch, S, masks, LOSS_FN, device=device)\n",
    "            loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD)\n",
    "        else:\n",
    "            model = GF_NodeClassModel(arch, S, K, masks, LOSS_FN, device=device)\n",
    "            loss, acc = model.train(feat, labels, N_EPOCHS, LR, WD, epochs_h=EPOCHS_h,\n",
    "                                    epochs_W=EPOCHS_W)\n",
    "        \n",
    "\n",
    "        best_accs[j,i] = np.max(acc[\"test\"])\n",
    "        best_val_accs[j,i] = model.test(feat, model.S, labels, masks['test'])\n",
    "        best_val_accs2[j,i] = acc[\"test\"][np.argmax(acc[\"val\"])]\n",
    "\n",
    "        print(f'\\t{exp[\"name\"]}-{exp[\"norm\"]}: acc = {best_val_accs[j,i]:.3f}  -  acc2 = {best_val_accs2[j,i]:.3f}  -  acc (over) = {best_accs[j,i]:.3f}')\n",
    "\n",
    "# Print results\n",
    "index_name = [f'{exp[\"name\"]}-{exp[\"norm\"]}' for exp in EXPS]\n",
    "table_comp_over = summary_table(best_accs, index_name)\n",
    "table_comp = summary_table(best_val_accs, index_name)\n",
    "table_comp2 = summary_table(best_val_accs2, index_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean accs</th>\n",
       "      <th>med</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kipf-none</th>\n",
       "      <td>0.510784</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.100838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kipf-both</th>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.046649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-False</th>\n",
       "      <td>0.858824</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.036473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A-GCNN-True</th>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.035942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-False</th>\n",
       "      <td>0.869608</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.034117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H-GCNN-True</th>\n",
       "      <td>0.844118</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.047008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-False</th>\n",
       "      <td>0.736275</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.053510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W-GCN-A-True</th>\n",
       "      <td>0.805882</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.034467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean accs       med       std\n",
       "Kipf-none       0.510784  0.539216  0.100838\n",
       "Kipf-both       0.564706  0.568627  0.046649\n",
       "A-GCNN-False    0.858824  0.843137  0.036473\n",
       "A-GCNN-True     0.847059  0.843137  0.035942\n",
       "H-GCNN-False    0.869608  0.862745  0.034117\n",
       "H-GCNN-True     0.844118  0.843137  0.047008\n",
       "W-GCN-A-False   0.736275  0.745098  0.053510\n",
       "W-GCN-A-True    0.805882  0.803922  0.034467"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_comp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
